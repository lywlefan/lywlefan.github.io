[{"title":"Hive中导入csv数据","date":"2020-03-29T16:00:00.000Z","path":"2020/03/30/后端/大数据/存储/hive/Hive中导入csv数据/","text":"Hive中导入csv数据常规表导入数据在hive中创建表通过查看csv的数据结构,在hive中创建一个对应的表,建表语句(以下创建的是内部表,也可以创建外部表)如下: 123456789101112create table if not exists wdc_user_01(id string,number string,type string,name String,archiveNumber string,vehicleType string,licenceOrgan string,status string,totalDockPoints string,licenseDate timestamp,row format delimited fields terminated by &apos;,&apos;; 导入数据1hive&gt; load data local inpath &apos;/tmp/certificate.csv&apos; overwrite into table open_user; 查看数据查看数据总条数 1select count(*) from open_user; 查看数据情况 1select * from open_user limit 100; 分区表数据导入按身份证最后一位进行分区前期准备工作先通过常规表数据的导入方式,把csv的数据导入到certificate表中。 分区方式动态分区 创建分区表12345678910111213hive&gt; create table if not exists wdc_user_03(id string,number string,type string,name String,archiveNumber string,vehicleType string,licenceOrgan string,status string,totalDockPoints string,licenseDate timestamp)PARTITIONED BY (code string)row format delimited fields terminated by &apos;,&apos;; 相关设置关闭严格分区模式1hive&gt; set hive.exec.dynamic.partition.mode=nonstrict 开启动态分区1hive&gt; set hive.exec.dynamic.partition=true 设置最大动态分区数1hive&gt; set hive.exec.max.dynamic.partitions=1000 //最大动态分区数,默认1000 导入数据12hive&gt; insert overwrite table wdc_user_03 partition (code) select id,number,type,name ,archiveNumber,vehicleType,licenceOrgan,status,totalDockPoints,licenseDate,SUBSTRING(number ,0,4) as code from default.certificate; certificate是数据的原始表,从原始表获取数据后,插入wdc_user_03分区表,在插入数据的时候会根据code进行动态的分区。 按年和月分区 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"Hive语法详解","date":"2020-03-29T16:00:00.000Z","path":"2020/03/30/后端/大数据/存储/hive/Hive语法详解/","text":"基础语法建表内部表特点 未被external修饰的是内部表（managed table） 内部表数据由Hive自身管理，外部表数据由HDFS管理 内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse） 删除内部表会直接删除元数据（metadata）及存储数据 脚本1234567891011create table t1( id int ,name string ,hobby array&lt;string&gt; ,add map&lt;String,string&gt;)row format delimitedfields terminated by &apos;,&apos;collection items terminated by &apos;-&apos;map keys terminated by &apos;:&apos;; 查看表的描述: 1$ desc t1; 查看表的详细描述 1$ desc formatted table_name; 外部表特点 被external修饰的为外部表（external table） 外部表数据由HDFS管理 外部表数据的存储位置由自己制定（如果没有LOCATION，Hive将在HDFS上的/user/hive/warehouse文件夹下以外部表的表名创建一个文件夹，并将属于这个表的数据存放在这里）； 删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除； 脚本123456789101112create external table t2( id int ,name string ,hobby array&lt;string&gt; ,add map&lt;String,string&gt;)row format delimitedfields terminated by &apos;,&apos;collection items terminated by &apos;-&apos;map keys terminated by &apos;:&apos;location &apos;/user/t2&apos;; 分区表特点脚本12345678CREATE TABLE par_table(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT &apos;IP Address of the User&apos;)COMMENT &apos;This is the page view table&apos;PARTITIONED BY(date STRING, pos STRING)ROW FORMAT DELIMITED ‘\\t’ FIELDS TERMINATED BY &apos;\\n&apos;STORED AS SEQUENCEFILE; 常用脚本显示表分区1hive&gt; show partitions table_name; 根据分区查询数据1hive&gt; select * from table_name where partition_date=&apos;2018-04-10&apos; ; 添加分区1hive&gt; alter table employees add partition (country=&quot;china&quot;,state=&quot;Asia&quot;); 把一个分区打包成一个har包1hive&gt; alter table employees archive partition (country=&quot;china&quot;,state=&quot;Asia&quot;) 把一个分区har包还原成原来的分区1hive&gt; alter table employees unarchive partition (country=&quot;china&quot;,state=&quot;Asia&quot;) 保护分区防止被删除1hive&gt; alter table employees partition (country=&quot;china&quot;,state=&quot;Asia&quot;) enable no_drop 保护分区防止被查询1hive&gt; alter table employees partition (country=&quot;china&quot;,state=&quot;Asia&quot;) enable offline 允许分区删除和查询12hive&gt; alter table employees partition (country=&quot;china&quot;,state=&quot;Asia&quot;) disable no_drophive&gt; alter table employees partition (country=&quot;china&quot;,state=&quot;Asia&quot;) disable offline 插入数据12345格式:hive&gt; INSERT INTO TABLE tablename [PARTITION (partcol1[=val1], partcol2[=val2] ...)] hive&gt; VALUES values_row [, values_row …]; 格式2：（推荐使用）hive&gt; load data local inpath &apos;/home/had/data1.txt&apos; into table employees partition (country =china,state=Asia) case语句和like1234创建表，携带数据create table employees1 as select * from employees1创建表，携带表结构create table employees2 like employees Bucket表特点 bucket table(桶表)是对数据进行哈希取值，然后放到不同文件中存储 。 脚本123456789CREATE TABLE par_table(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT &apos;IP Address of the User&apos;)COMMENT &apos;This is the page view table&apos;PARTITIONED BY(date STRING, pos STRING)CLUSTERED BY(userid) SORTED BY(viewTime) INTO 32 BUCKETSROW FORMAT DELIMITED ‘\\t’ FIELDS TERMINATED BY &apos;\\n&apos;STORED AS SEQUENCEFILE; 注: \\t 代表的是字段之间是通过tab进行分割的，\\n指的是行之间是断行。 装载数据insert into 一般很少用insert （不是insert overwrite）语句，因为就算就算插入一条数据，也会调用MapReduce，这里我们选择Load Data的方式。 load data 1hive&gt; load data local inpath &apos;/home/hadoop/Desktop/data&apos; overwrite into table t2; Bucket表注意事项①执行insert前不要忘记设置 1set hive.enforce.bucketing = true; 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"Hive的配置文件学习","date":"2020-03-27T16:00:00.000Z","path":"2020/03/28/后端/大数据/存储/hive/Hive的配置文件学习/","text":"hive-site.xml配置文件数据库配置配置数据库地址 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"ES的Mapping学习总结","date":"2020-03-25T16:00:00.000Z","path":"2020/03/26/后端/搜索引擎/es/ES的Mapping学习总结/","text":"参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】elasticsearch官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"https://lywlefan.github.io/tags/搜索引擎/"},{"name":"es","slug":"es","permalink":"https://lywlefan.github.io/tags/es/"}]},{"title":"Hive的安装","date":"2020-03-24T16:00:00.000Z","path":"2020/03/25/后端/大数据/存储/hive/Hive的安装/","text":"Hive下载安装下载地址下载地址 安装步骤解压hive到指定文件夹1$ tar -xzvf apache-hive-3.1.2-bin.tar.gz 在/conf文件夹下配置hive-site.xml12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://192.168.118.8:23306/hive_test&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123456&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 如果没有该文件,直接新建即可!该配置文件主要配置了mysql 的连接地址! 导入mysql驱动到lib文件夹导入mysql-connector-java-5.1.20.jar到hive的lib文件夹下。 初始化hive在mysql中的表1$ schematool -dbType mysql -initSchema 启动停止hive进入hive客户端1$ hive 启动hiveServer1$ hiveserver2 &amp; hiveServer是hive提供的jdbc连接hive的一种方式 测试在hive中创建一个库1231 hive&gt; create database hive_1;2 OK3 Time taken: 1.432 seconds 查看hive中的库1231 hive&gt; create database hive_1;2 OK3 Time taken: 1.432 seconds 切换到创建的库上1231 hive&gt; create database hive_1;2 OK3 Time taken: 1.432 seconds 在当前库创建一张表1231 hive&gt; create database hive_1;2 OK3 Time taken: 1.432 seconds 查看当前库里面所有的表1234hive&gt; show tables;OKhive_01Time taken: 0.107 seconds, Fetched: 1 row(s) 通过mysql查询创建的表1select * from TBLS; 通过hsfs的web界面查看我们创建的表 1585207863239 以上就是hive 的安装步骤!!! 遇到问题启动hive报错报错详情123456789101112131415161718192021SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/opt/software/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/opt/software/hadoop/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357) at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338) at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:518) at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:536) at org.apache.hadoop.mapred.JobConf.&lt;init&gt;(JobConf.java:430) at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:5141) at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:5104) at org.apache.hive.beeline.HiveSchemaTool.&lt;init&gt;(HiveSchemaTool.java:96) at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1473) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:318) at org.apache.hadoop.util.RunJar.main(RunJar.java:232) 错误原因guava版本太低造成的。 错误解决提升版本，删除lib文件夹下的guava原jar包，然后去maven仓库下载最新jar包放入即可！ 创建库报错错误详情1FAILED: HiveException java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient 错误原因hive数据库格式化失败错误详情123456789101112SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/opt/software/hive/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/opt/software/hadoop/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Metastore connection URL: jdbc:mysql://219.145.62.237:23306/hive_testMetastore Connection Driver : com.MySQL.jdbc.DriverMetastore connection User: rootorg.apache.hadoop.hive.metastore.HiveMetaException: Failed to load driverUnderlying cause: java.lang.ClassNotFoundException : com.MySQL.jdbc.DriverUse --verbose for detailed stacktrace.*** schemaTool failed *** 错误原因hive/lib文件夹下面没有导入mysql 的驱动。 还有可能是配置文件错误了。 错误解决导入mysql驱动，用官方的配置文件，不要在网上乱粘！！！ HiveServer2启动报错错误详情1234567891011121314151617181920212223java.lang.NoClassDefFoundError: org/apache/tez/dag/api/TezConfiguration at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolSession$AbstractTriggerValidator.startTriggerValidator(TezSessionPoolSession.java:74) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.initTriggers(TezSessionPoolManager.java:207) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.startPool(TezSessionPoolManager.java:114) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.initAndStartTezSessionPoolManager(HiveServer2.java:839) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.startOrReconnectTezSessions(HiveServer2.java:822) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.start(HiveServer2.java:745) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:1037) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.access$1600(HiveServer2.java:140) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2$StartOptionExecutor.execute(HiveServer2.java:1305) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:1149) [hive-service-3.1.2.jar:3.1.2] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_212] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_212] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_212] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_212] at org.apache.hadoop.util.RunJar.run(RunJar.java:318) [hadoop-common-3.1.3.jar:?] at org.apache.hadoop.util.RunJar.main(RunJar.java:232) [hadoop-common-3.1.3.jar:?]Caused by: java.lang.ClassNotFoundException: org.apache.tez.dag.api.TezConfiguration at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[?:1.8.0_212] at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[?:1.8.0_212] at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) ~[?:1.8.0_212] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[?:1.8.0_212] ... 16 more 错误原因这种问题是从机上运行的Container试图使用过多的内存，而被NodeManager kill掉了。 错误解决关掉虚拟内存检查,修改yarn-site.xml文件（添加相关代码）！！ 12cd /opt/module/hadoop/etc/hadoopvim yarn-site.xml 关掉虚拟机内存检查！！ 1234&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt; 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"大数据","slug":"大数据","permalink":"https://lywlefan.github.io/tags/大数据/"},{"name":"hive","slug":"hive","permalink":"https://lywlefan.github.io/tags/hive/"}]},{"title":"java类初始化","date":"2019-12-05T16:00:00.000Z","path":"2019/12/06/后端/基础巩固/java/jvm/java类初始化/","text":"【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"vue中是如何自定义组件的.","date":"2019-12-05T16:00:00.000Z","path":"2019/12/06/前端/vue/vue中是如何自定义组件的/","text":"如何自定义组件??父子组件之间是如何交互的?? 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"vue","slug":"vue","permalink":"https://lywlefan.github.io/tags/vue/"}]},{"title":"初始Knative","date":"2019-11-26T16:00:00.000Z","path":"2019/11/27/后端/容器管理/Knative/初始Knative/","text":"函数即服务（FaaS） 平台即服务（PaaS） 无服务器架构（serverless） 路由（routing） 事件（eventing） build（构建） 什么是Knative??Knative的目标 Knative 的目标是在基于 Kubernetes 之上为整个开发生命周期提供帮助 。 具体实现 作为开发人员能够以你想要的语言和以你想要的方式来编写代码 其次帮助你构建和打包应用程序 最后帮助你运行和伸缩应用程序 关键组件 build（构建）你的应用程序 1通过灵活的插件化的构建系统将用户源代码构建成容器。目前已经支持多个构建系统，比如 Google 的 Kaniko，它无需运行 Docker daemon 就可以在 Kubernetes 集群上构建容器镜像。 serving（服务）为其提供流量 1基于负载自动伸缩，包括在没有负载时缩减到零。允许你为多个修订版本（revision）应用创建流量策略，从而能够通过 URL 轻松路由到目标应用程序。 event（事件）确保应用程序能够轻松地生产和消费。 1使得生产和消费事件变得容易。抽象出事件源，并允许操作人员使用自己选择的消息传递层。 综上所述:Knative是一个可以让Kubernetes更好用,扩展性更好的轮子。 一些新的概念无服务器架构(serverless)划重点 以前需要编写大型/单一应用程序,现在只需要编写通过事件来调用小型/单一用途的函数即可。 对于托管服务来说,意味着只需要为活跃期间的计算付费,而不是一台7×24小时运行的虚拟机付费。 代码在需要时就运行,不需要时就停止。 Kubernetes遇到的问题 如何保证一致性 谁负责给所有东西打补丁 如何根据需求伸缩 如何实现零停机部署 如何管理多个事件类型一致性 如何定义事件源和目标 Knative 构建在 Kubernetes 的基础上，并为构建和部署无服务器架构（serverless）和基于事件驱动的应用程序提供了一致的标准模式。Knative 减少了这种新的软件开发方法所产生的开销，同时还把路由（routing）和事件（eventing）的复杂性抽象出来。 Knative组件学习Serving（服务） 【1】简书主页·share猿 【2】掘金主页·share猿 【3】Knative入门——构建基于 Kubernetes 的现代化Serverless应用 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"容器管理","slug":"容器管理","permalink":"https://lywlefan.github.io/tags/容器管理/"},{"name":"Knative","slug":"Knative","permalink":"https://lywlefan.github.io/tags/Knative/"}]},{"title":"jpa参数为空查询报错问题","date":"2019-11-24T16:00:00.000Z","path":"2019/11/25/后端/框架/java/hibernate/jpa参数为空查询报错问题/","text":"遇到问题在使用jpa的时候发现,通过@Query自定义的sql,参数不能传空,传空就报错: 在使用jpa的时候发现,通过@Query自定义的 12345678910111213@Query(value = \"select new com.winstar.vo.OilCouponVo(t.oilId,s.phone,s.certNo,t.couponCode,t.orderNumber,t.couponAmt,t.couponName,t.useState,t.gasStationId,t.gasStationName,t.useDate,t.createdAt,t.updatedAt,t.status) from OilCoupon t left join Account s on t.userId = s.id \" + \"where (t.createdAt between ?1 and ?2) and t.useDate = ?3 and t.couponCode like ?4 and t.orderNumber like ?5 and t.appId = ?6 and s.phone = ?7 and s.certNo = ?8\", countQuery = \"select count(t.id) from OilCoupon t left join Account s on t.userId = s.id \" + \"where (t.createdAt between ?1 and ?2) and t.useDate = ?3 and t.couponCode like ?4 and t.orderNumber like ?5 and t.appId = ?6 and s.phone = ?7 and s.certNo = ?8\") Page&lt;OilCouponVo&gt; getOilPage(Date startTime, Date endTime, String useState, String couponCode, String orderNumber, String appId, String phone, String certNo, Pageable pageable); 解决办法原生sql解决办法如下:123@Query(value = \"select * from xxx where if(?1 !='',x1=?1,1=1) and if(?2 !='',x2=?2,1=1)\" + \"and if(?3 !='',x3=?3,1=1) \",nativeQuery = true) List&lt;XXX&gt; find(String X1,String X2,String X3); 非原生sql解决办法如下12345678@Query(value = \"select new com.winstar.vo.OilCouponVo(t.oilId,s.phone,s.certNo,t.couponCode,t.orderNumber,t.couponAmt,t.couponName,t.useState,t.gasStationId,t.gasStationName,t.useDate,t.createdAt,t.updatedAt,t.status) from OilCoupon t left join Account s on t.userId = s.id \" + \"where (t.createdAt between ?1 and ?2) and (?3 is null or ?3 = '' or t.useState = ?3) and (?4 is null or ?4 = '' or t.couponCode like ?4)\" + \" and (?5 is null or ?5 = '' or t.orderNumber = ?5) and (?6 is null or ?6 = '' or t.appId = ?6)\" + \" and (?7 is null or ?7 = '' or s.phone = ?7) and (?8 is null or ?8 = '' or s.certNo like ?8)\", countQuery = \"select count(t.id) from OilCoupon t left join Account s on t.userId = s.id \" + \"where (t.createdAt between ?1 and ?2) and (?3 is null or ?3 = '' or t.useState = ?3) and (?4 is null or ?4 = '' or t.couponCode like ?4)\" + \" and (?5 is null or ?5 = '' or t.orderNumber = ?5) and (?6 is null or ?6 = '' or t.appId = ?6)\" + \" and (?7 is null or ?7 = '' or s.phone = ?7) and (?8 is null or ?8 = '' or s.certNo like ?8)\") 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"},{"name":"hibernate","slug":"hibernate","permalink":"https://lywlefan.github.io/tags/hibernate/"}]},{"title":"自定义枚举类型校验","date":"2019-11-17T16:00:00.000Z","path":"2019/11/18/后端/框架/java/hibernate/自定义枚举类型校验/","text":"需求自定义了如下枚举类型,需要对其vo进行校验: 123456789101112131415161718192021222324252627public interface ValidateEnum &#123; /** * 证件类型 */ @Getter @AllArgsConstructor enum CertTypeEnum implements ValidateEnum &#123; CERT_TYPE(\"身份证\",\"0\"), PROTECTION_TYPE(\"护照\",\"1\"), OFFICER_TYPE(\"军官证\",\"2\"), SOLDIERS_TYPE(\"士兵证\",\"3\"), REENTRY_PERMIT_TYPE(\"回乡证\",\"4\"), INTERIM_IDENTITY_CARD_TYPE(\"临时身份证\",\"5\"), RESIDENCE_BOOKLET_TYPE(\"户口簿\",\"6\"), POLICE_OFFICER_TYPE(\"警官证\",\"7\"), TAIWAN_COMPATRIOTS_TYPE(\"台胞证\",\"8\"), BUSINESS_LICENSE_TYPE(\"营业执照\",\"9\"), OTHERS_TYPE(\"其他证件\",\"10\"), HONG_KONG_TYPE(\"港澳台居民来往内地通行证\",\"11\"), TAIWAN_TYPE(\"台湾居民来往大陆通行证\",\"12\"); private String name; private String value; &#125;&#125; 实现自定义枚举校验注解12345678910111213@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.FIELD, ElementType.METHOD&#125;)@Constraint(validatedBy = EnumValidatorClass.class)public @interface EnumValidator &#123; Class&lt;?&gt; value(); String message() default \"入参值不在正确枚举中\"; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125; 枚举注解处理类1234567891011121314151617181920212223242526272829303132333435public class EnumValidatorClass implements ConstraintValidator&lt;EnumValidator, Object&gt;, Annotation &#123; private Logger log = LoggerFactory.getLogger(this.getClass()); private List&lt;Object&gt; values = new ArrayList&lt;&gt;(); @Override public void initialize(EnumValidator enumValidator) &#123; Class&lt;?&gt; clz = enumValidator.value(); Object[] ojects = clz.getEnumConstants(); try &#123; Method method = clz.getMethod(\"getValue\"); if (Objects.isNull(method)) &#123; throw new Exception(String.format(\"枚举对象&#123;&#125;缺少字段名为value的字段\", clz.getName())); &#125; Object value = null; for (Object obj : ojects) &#123; value = method.invoke(obj); values.add(value); &#125; &#125; catch (Exception e) &#123; log.error(\"[处理枚举校验异常]\", e); &#125; &#125; @Override public Class&lt;? extends Annotation&gt; annotationType() &#123; return null; &#125; @Override public boolean isValid(Object value, ConstraintValidatorContext constraintValidatorContext) &#123; return Objects.isNull(value) || values.contains(value) ? true : false; &#125;&#125; 定义枚举类型接口123456789101112131415161718192021222324252627public interface ValidateEnum &#123; /** * 证件类型 */ @Getter @AllArgsConstructor enum CertTypeEnum implements ValidateEnum &#123; CERT_TYPE(&quot;身份证&quot;,&quot;0&quot;), PROTECTION_TYPE(&quot;护照&quot;,&quot;1&quot;), OFFICER_TYPE(&quot;军官证&quot;,&quot;2&quot;), SOLDIERS_TYPE(&quot;士兵证&quot;,&quot;3&quot;), REENTRY_PERMIT_TYPE(&quot;回乡证&quot;,&quot;4&quot;), INTERIM_IDENTITY_CARD_TYPE(&quot;临时身份证&quot;,&quot;5&quot;), RESIDENCE_BOOKLET_TYPE(&quot;户口簿&quot;,&quot;6&quot;), POLICE_OFFICER_TYPE(&quot;警官证&quot;,&quot;7&quot;), TAIWAN_COMPATRIOTS_TYPE(&quot;台胞证&quot;,&quot;8&quot;), BUSINESS_LICENSE_TYPE(&quot;营业执照&quot;,&quot;9&quot;), OTHERS_TYPE(&quot;其他证件&quot;,&quot;10&quot;), HONG_KONG_TYPE(&quot;港澳台居民来往内地通行证&quot;,&quot;11&quot;), TAIWAN_TYPE(&quot;台湾居民来往大陆通行证&quot;,&quot;12&quot;); private String name; private String value; &#125;&#125; 使用枚举校验注解12345/** * 证件类型(0:身份证, 1:护照, 2:军官证, 3:士兵证, 4:回乡证, 5:临时身份证, 6:户口簿, 7:警官证, 8:台胞证, 9:营业执照, 10:其他证件, 11:港澳台居民来往内地通行证, 12:台湾居民来往大陆通行证) */@EnumValidator(message = &quot;证件类型不在指定类型中&quot;, value = ValidateEnum.CertTypeEnum.class)private String certType; 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"},{"name":"hibernate","slug":"hibernate","permalink":"https://lywlefan.github.io/tags/hibernate/"}]},{"title":"去中心化应用","date":"2019-11-04T16:00:00.000Z","path":"2019/11/05/前沿技术/区块链/应用/去中心化应用/","text":"去中心化应用 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"应用","slug":"应用","permalink":"https://lywlefan.github.io/tags/应用/"}]},{"title":"如何和别人进行合作协调","date":"2019-11-04T16:00:00.000Z","path":"2019/11/05/管理/读书笔记/横向领导力/如何和别人进行合作协调/","text":"合作中常见的问题合作不佳找不到一个人解决问题改善团队表现需要解决的三个问题个人技能有限的问题打铁还得自身硬，要想领导团队自身能力要硬，要有好的德行。要有解决解决复杂问题的能力和思维，要有带领团队克服困难的勇气，要积极向上，做好团队的能量石，也做好团队的敲打棒。 对一个好的合作缺乏清晰的认识要对好的团队有清晰的认识，团队要有清晰的目标，领导人要划分清晰的职责，及时处理团队的矛盾，团队成员共同成长，相互提升，把相互teview当做团队的一种文化，团队协作形成一些标准的规范。领导人要为团队争取更多的福利。 大多数人都不知道怎么影响别人 自我成长 德行 清晰目标 职责分配清晰 及时沟通，当面表扬，私下批评 积极争取福利 团队协作的方法培养、锻炼自己独立工作的自己独立工作的能力，有计划，有目标，有方向，有解决问题思维方式，有处理问题的策略。 对共同工作的战略目标有清晰的认识深刻理解目标，对目标有清晰的认识。 学习一些领导方法参与式领导方法 提问 说出自己的想法邀请别人接受、运用或者修改想法 想法付诸实践，然后改进 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"横向领导力","slug":"横向领导力","permalink":"https://lywlefan.github.io/tags/横向领导力/"}]},{"title":"fabric架构","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/前沿技术/区块链/fabric/fabric架构/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"fabric","slug":"fabric","permalink":"https://lywlefan.github.io/tags/fabric/"}]},{"title":"初始corda","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/前沿技术/区块链/corda/初始corda/","text":"什么是corda??是什么?corda是一个分布式账本平台。 基本概念corda网络账本每个节点验证过交易的集合,账本是各个节点自有的。 每个节点维护一个已知事实的分离数据库。 没有一个节点知道整个账本。 身份身份有两种:组织的法律身份、网络服务身份。 法律身份用于交易的当事人,如:现金拥有者。 网络服务身份用于提供与交易相关的服务,如公证服务或oracle服务。服务身份基于混合KEY。 身份证明的X.509证书由看门人或其他众所周知的身份签发。身份是众所周知的还是机密的,取决于X.509证书是否公开。 应用节点看门人看门人服务可以理解为一个身份准入管理服务加上一个业务许可管理服务,它要求节点提供必要的信息,以及在接受进入网络前必须进行的了解客户的过程。 要想加入corda网络,节点必须联系看门人并提供必要的信息。看门人许可通过,会颁发TLS许可证书。 cordaDappsAMPQ/1.0协议公证节点公证节点保证账本更新的唯一性、可行性、正确性。 每个公证服务可以运行在一个节点或一组节点上。 状态状态是表示账本上的事实,是一个不可变的对象,表示在特定时刻由一个或多个Corda节点所知的事实。 状态序列状态的生命周期 合约每个状态指向一个合约。 合约以交易作为输入,并根据合约的规则说明交易是否被认为有效。 交易只有在合约的每个输入和输出状态被确认为有效的情况下才有效。 合约代码可以用任意的JVM语言进行编写。 一个不被合约认可的交易不会作为更新账本的有效提案。 合约沙箱预言机女巫攻击 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"corda","slug":"corda","permalink":"https://lywlefan.github.io/tags/corda/"}]},{"title":"企业在落地区块链时要考虑的点","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/前沿技术/区块链/应用/企业在落地区块链时要考虑的点/","text":"业务人才团队建设业务场景选择业务流程化应用开发模式可视化与分析数据模块管理技术技术方案选型平台设计实施高可用与灾备安全合规治理平台应用运维运营市场营销宣传生态系统参与 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"应用","slug":"应用","permalink":"https://lywlefan.github.io/tags/应用/"}]},{"title":"redis基础总结","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/后端/缓存/redis/redis基础总结/","text":"redis附加功能 “附加功能”部分介绍了Redis在数据结构的基础上为用户提供的额外功能，包括管理数据结构的数据库管理功能和自动过期功能，将数据结构持久化至硬盘从而避免数据丢失的持久化功能，提高多条命令执行效率的流水线功能，保证命令安全性的事务和Lua脚本功能，以及扩展服务器特性的模块功能等。 Redis的PING命令接受一条可选的消息作为参数，这个命令通常用于测试客户端和服务器之间的连接是否正常: 连接正常的情况下，将向客户端返回PONG 如果服务器与客户端的连接不正常，那么客户端将返回一个错误 123-- 客户端未能连接服务器，返回一个连接错误 127.0.0.1:6379&gt; PING Could not connect to Redis at 127.0.0.1:6379: Connection refused 更换端口号: Redis服务器默认使用6379作为端口号，但如果你想使用10086而不是6379作为端口号，那么可以在启动Redis服务器时通过设定port可选项来指定想要的端口号： 1$ redis-server --port 10086 第二种方法是在启动Redis服务器的时候为其提供配置文件，并将想要修改的配置选项写在配置文件中 1$ redis-server /path/to/your/file 例如，为了将Redis服务器的端口号改为12345，我们可以在当前文件夹中创建配置文件myredis.conf，并在文件中包含以下内容： 1port 12345 然后在启动Redis服务器时向其提供该配置文件： 1$ redis-server myredis.conf 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"缓存","slug":"缓存","permalink":"https://lywlefan.github.io/tags/缓存/"}]},{"title":"企业在落地区块链时要考虑的点","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/前沿技术/区块链/fabric/Hyperledger Composer学习总结/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"fabric","slug":"fabric","permalink":"https://lywlefan.github.io/tags/fabric/"}]},{"title":"初始corda","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/前沿技术/区块链/corda/cord中的基本概念总结/","text":"什么是corda??是什么?corda是一个分布式账本平台。 基本概念corda网络账本每个节点验证过交易的集合,账本是各个节点自有的。 每个节点维护一个已知事实的分离数据库。 没有一个节点知道整个账本。 身份身份有两种:组织的法律身份、网络服务身份。 法律身份用于交易的当事人,如:现金拥有者。 网络服务身份用于提供与交易相关的服务,如公证服务或oracle服务。服务身份基于混合KEY。 身份证明的X.509证书由看门人或其他众所周知的身份签发。身份是众所周知的还是机密的,取决于X.509证书是否公开。 应用节点看门人看门人服务可以理解为一个身份准入管理服务加上一个业务许可管理服务,它要求节点提供必要的信息,以及在接受进入网络前必须进行的了解客户的过程。 要想加入corda网络,节点必须联系看门人并提供必要的信息。看门人许可通过,会颁发TLS许可证书。 cordaDappsAMPQ/1.0协议公证节点公证节点保证账本更新的唯一性、可行性、正确性。 每个公证服务可以运行在一个节点或一组节点上。 状态状态是表示账本上的事实,是一个不可变的对象,表示在特定时刻由一个或多个Corda节点所知的事实。 状态序列状态的生命周期 合约每个状态指向一个合约。 合约以交易作为输入,并根据合约的规则说明交易是否被认为有效。 交易只有在合约的每个输入和输出状态被确认为有效的情况下才有效。 合约代码可以用任意的JVM语言进行编写。 一个不被合约认可的交易不会作为更新账本的有效提案。 合约沙箱预言机女巫攻击 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"corda","slug":"corda","permalink":"https://lywlefan.github.io/tags/corda/"}]},{"title":"corda基础架构","date":"2019-10-29T16:00:00.000Z","path":"2019/10/30/前沿技术/区块链/corda/corda基础架构/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"区块链","slug":"区块链","permalink":"https://lywlefan.github.io/tags/区块链/"},{"name":"corda","slug":"corda","permalink":"https://lywlefan.github.io/tags/corda/"}]},{"title":"抓包工具学习","date":"2019-10-23T16:00:00.000Z","path":"2019/10/24/前端/idea/fiddler/抓包工具学习/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"idea","slug":"idea","permalink":"https://lywlefan.github.io/tags/idea/"},{"name":"fiddler","slug":"fiddler","permalink":"https://lywlefan.github.io/tags/fiddler/"}]},{"title":"Vue基础","date":"2019-10-23T16:00:00.000Z","path":"2019/10/24/前端/vue/vue基础/","text":"基础简介什么是Vue？？开发web界面的前端库 vue特性 具有响应式编程（保持状态和视图同步） 组件化 轻量级 易上手 MVC：MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。 MVP：MVP是Model-View-Presenter的简称，即模型-视图-表现层的缩写。MVP是由MVC模式进化而来的，MVP改进了MVC中的控制器过于臃肿的问题。 MVC MVP Model 业务逻辑和实体模型 Model 业务逻辑和实体模型 View 对应布局文件 View 对应Activity，负责view的绘制与用户交互 Controller 对应Activity等 Presenter 负责完成view与model的交互，处理程序逻辑 MVVM： MVM： 理念一切都是组件！ 为什么用vue 轻量，易上手 阿里支持，开源weex 抛弃IE8支持 Android支持到4.2+ ios支持到7+ 适用前后端分离项目 压缩后仅有18KB，不依赖其他 前端框架基本逻辑 模板渲染 事件绑定 用户交互处理 实例及选项一个Vue实例相当于一个MVVM模式中的ViewModel，实例化的时候传入一个选项对象（包括数据、模板、挂载元素、方法、生命周期钩子等） 模板el为实例提供挂载元素，类型为字符串。在初始化指定el，实例将立即进入编译过程。 template配置挂载 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"vue","slug":"vue","permalink":"https://lywlefan.github.io/tags/vue/"}]},{"title":"在Ubuntu下安装webstorm","date":"2019-10-23T16:00:00.000Z","path":"2019/10/24/前端/idea/webstorm/在Ubuntu下安装webstorm/","text":"扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"idea","slug":"idea","permalink":"https://lywlefan.github.io/tags/idea/"},{"name":"webstorm","slug":"webstorm","permalink":"https://lywlefan.github.io/tags/webstorm/"}]},{"title":"jpa原生sql分页","date":"2019-10-17T16:00:00.000Z","path":"2019/10/18/后端/框架/java/hibernate/jpa原生sql分页/","text":"需求其实需求很简单,就是通过查询一个表得到数据列表,然后再对这个数据列表进行分页,自定义sql如下: 1234567891011121314151617181920212223SELECT t.order_number AS orderNumber, sum(t.coupon_amt) AS sum, sum( CASE WHEN t.use_state = 'NOT_USE' THEN t.coupon_amt ELSE 0 END ) AS balanceFROM open_oil_coupon tWHERE t.user_id = ? 1AND t.app_id = ? 2GROUP BY t.order_idHAVING balance = 0ORDER BY t.created_at DESC, balance DESC 解决办法方法一:通过jpa的原生sql分页查询Repository1234567public interface OilCouponRepository extends JpaRepository&lt;OilCoupon,Long&gt;,JpaSpecificationExecutor&lt;OilCoupon&gt; &#123; @Query(value = \"SELECT t.order_number AS orderNumber, sum(t.coupon_amt) AS sum, sum(CASE WHEN t.use_state = 'NOT_USE' THEN t.coupon_amt ELSE 0 END ) AS balance FROM open_oil_coupon t WHERE t.user_id = ?1 AND t.app_id = ?2 GROUP BY t.order_number HAVING balance &gt; 0\",nativeQuery = true, countQuery = \"SELECT count(*) FROM (SELECT t.order_number AS orderNumber, sum(t.coupon_amt) AS sum, sum(CASE WHEN t.use_state = 'NOT_USE' THEN t.coupon_amt ELSE 0 END ) AS balance FROM open_oil_coupon t WHERE t.user_id = ?1 AND t.app_id = ?2 GROUP BY t.order_number HAVING balance = 0) T\")Page&lt;Map&gt; getAllCouponsUsed(Long userId, String appId, Pageable pageable);&#125; 注意:countQuery如果带有having等语句最好的办法是把@Query的sql复制一份把他查出来的结果当成表,然后对其进行count(*)查询。 Service123456789101112public OpenPage&lt;CouponsVo&gt; getCouponsByOrderId(String appId, Long userId, CouponPageVo couponPageVo)&#123; Pageable pageable = new PageRequest(couponPageVo.getPageNum(), couponPageVo.getPageSize(), Sort.Direction.DESC, \"order_number\"); OpenPage&lt;CouponsVo&gt; pages = new OpenPage(); Page page2 = oilCouponRepository.getAllCouponsUsed(userId,appId,pageable); List&lt;CouponsVo&gt; couponsVos = JSON.parseArray(JSON.toJSONString(page2.getContent()),CouponsVo.class); pages.setContent(couponsVos); pages.setPageNum(page2.getNumber()); pages.setPageSize(page2.getSize()); pages.setTotalElements(page2.getTotalElements()); pages.setTotalPages(page2.getTotalPages()); return pages; &#125; 注意:排序的字段要用跟数据库里面一样的字段名称 方法二:通过jdbc原生sql拼接的方法进行分页抽象的jdbc分页类型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153package com.winstar.config;import com.winstar.util.OpenPage;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.util.Assert;import javax.persistence.EntityManager;import java.io.Serializable;import java.lang.reflect.Field;import java.lang.reflect.ParameterizedType;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 包:com.winstar.manager.repository * 类描述: jdbc父Dao封装 * 创建人:shareyuan * 创建时间:2018/12/26 11:52 * 版本:v1.0 */@SuppressWarnings(\"unchecked\")public class AbstractServerRepository&lt;T, PK extends Serializable&gt;&#123; @Autowired protected JdbcTemplate jdbcTemplate; @Autowired EntityManager entityManager; protected Class&lt;T&gt; entityClass; private static final String EMPYT_STR = \"\"; private Map&lt;String, String&gt; fieldClassNames = null; public AbstractServerRepository() &#123; this.entityClass = (Class&lt;T&gt;) ((ParameterizedType) getClass() .getGenericSuperclass()).getActualTypeArguments()[0]; this.initEntityFieldsClassNames(); &#125; private void initEntityFieldsClassNames() &#123; Field[] fields = this.entityClass.getDeclaredFields(); this.fieldClassNames = new HashMap&lt;&gt;(); for (Field field : fields) &#123; fieldClassNames.put(field.getName(), field.getType().getName()); &#125; &#125; /** * Description: 根据SQL查询数据并返回一个List&lt;Map&lt;String,Object&gt;&gt;,将其封装为 Page * Param: sql,pageNo,pageSize,values * return: Page * Author: shareyuan * Date: 2018/12/27 */ public OpenPage findPageBySqlForListMap(final String sql, final int pageNo, final int pageSize, final Object... values) &#123; final String countSql = \"SELECT count(1) FROM (\"+ removeOrders(sql) + \") T\"; final long totalCount = this.getCountBySql(countSql, values); if (totalCount &lt; 1) &#123; return new OpenPage(); &#125; else &#123; final int startIndex = OpenPage.getStartOfPage(pageNo, pageSize); final String querySql =getString( sql,\" limit \", startIndex,\",\", pageSize); List&lt;Map&lt;String,Object&gt;&gt; list = this.jdbcTemplate.queryForList(querySql,values); return new OpenPage(pageNo,pageSize, list,Integer.parseInt(String.valueOf(totalCount))); &#125; &#125; /** * Description: 根据id获取唯一对象 * Param: id * return: T * Author: shareyuan * Date: 2018/12/27 */ public T findOne(final PK id)&#123; return entityManager.find(entityClass,id); &#125; /** * Description: 根据sql查询数据总数 * Param: sql,values * return: Long * Author: shareyuan * Date: 2018/12/26 */ private Long getCountBySql(final String sql, final Object... values) &#123; return jdbcTemplate.queryForObject(sql, Long.class, values); &#125; /** * Description: 组合传入字符串数组 * Param: objs * return: String * Author: shareyuan * Date: 2018/12/26 */ private String getString(Object... objs) &#123; if(objs != null &amp;&amp; objs.length &gt; 0) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; objs.length; i++) &#123; sb.append(objs[i] == null ? EMPYT_STR : objs[i].toString()); &#125; return sb.toString(); &#125; return EMPYT_STR; &#125; /** * Description: 去除sql的orderby 子句，用于分页查询 * Param: sql * return: String * Author: shareyuan * Date: 2018/12/27 */ private String removeOrders(String sql) &#123; Pattern p = Pattern.compile(\"order\\\\s*by[\\\\w|\\\\W|\\\\s|\\\\S]*\", Pattern.CASE_INSENSITIVE); Matcher m = p.matcher(sql); StringBuffer sb = new StringBuffer(); while (m.find()) &#123; m.appendReplacement(sb, \"\"); &#125; m.appendTail(sb); return sb.toString(); &#125; /** * Description: 去除sql的select 子句，未考虑union的情况 * Param: sql * return: String * Author: shareyuan * Date: 2018/12/27 */ private String removeSelect(String sql) &#123; int beginPos = sql.toLowerCase().indexOf(\"from \"); Assert.isTrue(beginPos != -1, \" hql : \" + sql + \" must has a keyword 'from'\"); return sql.substring(beginPos); &#125;&#125; Repository1234@Repository(\"oilCouponJdbcRepository\")public class OilCouponJdbcRepository extends AbstractServerRepository&lt;OilCoupon,Long&gt; &#123;&#125; Service123456789101112131415161718192021 public OpenPage&lt;Map&gt; getPage(String appId, Long userId, CouponPageVo couponPageVo) &#123; StringBuffer sql = new StringBuffer(\"SELECT t.order_number AS orderNumber, sum(t.coupon_amt) AS sum, sum(CASE WHEN t.use_state = 'NOT_USE' THEN t.coupon_amt ELSE 0 END ) AS balance FROM open_oil_coupon t\"); List params = new ArrayList&lt;&gt;(); if (StringUtils.isNotEmpty(appId))&#123; sql.append(\" WHERE t.user_id = ? \"); params.add(userId); &#125; if (StringUtils.isNotEmpty(appId))&#123; sql.append(\" AND t.app_id = ? \"); params.add(appId); &#125; sql.append(\" GROUP BY t.order_number\"); if (StringUtils.equals(couponPageVo.getUseState(),CommonEnum.USED.getValue()))&#123; sql.append(\" HAVING balance = 0\"); &#125;else if (StringUtils.equals(couponPageVo.getUseState(),CommonEnum.NOT_USE.getValue()))&#123; sql.append(\" HAVING balance &gt; 0\"); &#125; sql.append(\" ORDER BY t.created_at DESC,balance \"); log.info(\"分页sql为:&#123;&#125;,分页请求参数为:&#123;&#125;\",sql,params.toArray()); return oilCouponJdbcRepository.findPageBySqlForListMap(sql.toString(),couponPageVo.getPageNum(),couponPageVo.getPageSize(),params.toArray());&#125; 说明:jdbc分页的好处就是可以多表进行联查自定义sql,相对来说比较灵活,对于复杂sql,我个人感觉可读性要比jpa的自定义sql要好一些。 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"},{"name":"hibernate","slug":"hibernate","permalink":"https://lywlefan.github.io/tags/hibernate/"}]},{"title":"如何设计一个秒杀系统读书笔记","date":"2019-10-16T16:00:00.000Z","path":"2019/10/17/后端/高并发/java/书籍/如何设计一个秒杀系统-许令波/如何设计一个秒杀系统读书笔记/","text":"阅读笔记秒杀系统关键点①我觉得作为一个程序员,你首先需要从高维度出发,从整体上思考问题。 1G:对整体要有高屋建瓴，要站在最高处俯瞰，在落实的时候要把握好细节，下绣花针功夫。 ②秒杀其实主要解决两个问题,一个是并发读,一个是并发写。并发读的核心优化理念是尽量减少用户到服务来“读”数据,或者让他们读更少的数据;并发写的处理原则也一样,它要求我们在数据库层面独立出来一个库,做特殊的处理。另外,我们还要针对秒杀系统做一些保护,针对意料之外的情况设计兜底方案,以防止最坏的情况发生。 1G：两个疑问，见疑问区域 ③从浏览器到服务端我们要遵循几个原则： 请求数据尽量少 请求数尽量少 路径尽量短 依赖尽量少 不要有单点 ④整体架构概括为几个字：稳、准、快 稳（高性能）：流量超出预期要保证稳定 准（一致性）：秒杀多少个商品就是多少个，一台也不能多，一台也不能少 快（高可用）：支撑大的流量，性能要好 设计秒杀系统注意的5个架构原则①“4要1不要” 数据尽量少：上传的数据和返回的数据 请求尽量少： 合并CSS和JavaScript文件，多个合成一个 在 URL 中用逗号隔开 (https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js)。 这种方式在服务端仍然是单个文件各自存放,只是服务端会有一个组件解析这个 URL,然后动态把这些文件合并起来一起返回。 路径尽量短 缩短请求不仅可以增加可用性而且可以有效提升性能 要缩短访问路径有一种办法,就是多个相互强依赖的应用合并部署在一起,把远程过程调用(RPC)变成JVM内部之间的调用。 依赖尽量少 系统分级（0级、1级、2级等等） 不要单点 应用无状态化 服务无状态化 架构是一种平衡的艺术,而最好的架构一旦脱离了它所适应的场景,一切都将是空谈。 二八原则:有正对性的处理好系统的热点数据把少部分访问速度高的数据隔离拆分出来做单独的处理,让大多数的请求正常运行。 流量削峰削峰的存在，一是可以让服务端处理变得更加平稳，二是可以节省服务器的资源成本。 它遵从“请求数要尽量少”的原则。 影响性能的因素有哪些？又该如何提高系统的性能？疑问如何减少用户来服务端读数据？？什么是兜底方案？？如何设计兜底？？什么是无状态化？？？什么是”热点数据”???热点数据就是一个系统中,用户访问量最大的数据,比如:热点商品。热点数据又分为:静态热点数据和动态热点数据。 如何分析发现热点数据??静态热点数据的发现 提前通过统计这些数据,比如:热卖商品,我们可以通过TOP排行榜进行统计,秒杀商品可以让商家进行报名,提前对这些数据做好缓存和预处理。 动态数据的发现 构建热点发现系统,用于在短时间内发现热点商品,从而做出相应的处理策略。 构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点 Key，如 Nginx、缓存、RPC 服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。 建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上 Nginx 模块统计的热点 URL。 将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。 1G:热点分析平台:它存在的主要作用就是从各个可能收集热点数据的地方(每台机器上的Agen把日志汇总)收集到热点数据,然后对这些数据进行分析(分析集群),把分析到的热点数据进行发布,相关服务订阅到热点数据后,提前对这些热点数据做好处理(填充到 Cache等手段)。 热点分析系统构建注意事项: 这个热点服务后台抓取热点数据日志最好采用异步方式，因为“异步”一方面便于保证通用性，另一方面又不影响业务系统和中间件产品的主流程。 热点服务发现和中间件自身的热点保护模块并存，每个中间件和应用还需要保护自己。热点服务台提供热点数据的收集和订阅服务，便于把各个系统的热点数据透明出来。 热点发现要做到接近实时（3s 内完成热点数据的发现），因为只有做到接近实时，动态发现才有意义，才能实时地对下游系统提供保护。 总结热点数据发现的方法: 人工标识 大数据统计计算 以及实时热点发现方案 发现热点数据后如何处理热点数据?优化 LRU淘汰算法实时缓存热点数据 1LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 限制 限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。 隔离 不要让 1% 的请求影响到另外的 99%，隔离出来后也更方便对这 1% 的请求做针对性的优化。 具体到“秒杀”业务，我们可以在以下几个层次实现隔离: 业务隔离。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。 系统隔离。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。 数据隔离。秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01% 的数据有机会影响 99.99% 数据。 你可以按照用户来区分，给不同的用户分配不同的 Cookie，在接入层，路由到不同的服务接口中； 你还可以在接入层针对 URL 中的不同 Path 来设置限流策略。 服务层调用不同的服务接口，以及数据层通过给数据打标来区分等等这些措施，其目的都是把已经识别出来的热点请求和普通的请求区分开。 流量削峰什么是流量削峰???在秒杀的过程中,就某一个时间来说请求实非常大的,我们的服务监控会看到一根非常直的线,因为所有请求都汇聚在这个时间点,对流量产生瞬时的消耗。 而流量削峰就是避免这种情况的发生,让并发请延缓,过滤掉无效的请求,让秒杀请求不在瞬时爆发,避免压垮服务器情况的发生。 为什么要削峰???秒杀就像大家去买早餐,早餐是有限的,买早餐的人可能非常多,大家为了买到早餐都往早餐店冲,这样的结果就是挤爆早餐店,大家谁也买不到早餐。 把请求当做买早餐的人,把早餐当成秒杀的商品是一样的道理.所以,削峰的意义就在于让服务器正常处理请求,避免服务器资源的浪费,保质保量完成请求任务。 如何进行流量削峰???无损的解决方案 答题 排队 分层过滤 有损的解决方案 限流 负载保护 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"java并发编程实战-王宝令","slug":"java并发编程实战-王宝令","permalink":"https://lywlefan.github.io/tags/java并发编程实战-王宝令/"}]},{"title":"后端导航","date":"2019-10-14T16:00:00.000Z","path":"2019/10/15/前沿技术/区块链/区块链导航/","text":"企业区块链官方大企业导航壹账链·平安 ) 趣链科技 学习资料收集CONTENTS INTRO 介绍 TUTORIAL 教程 PROJECT 项目 DOCUMENT 资料 APPLICATION 应用 INTRO 介绍Started 入门 （一）简单易懂地介绍什么是区块链 比特币区块链关键词讲解 （二）简单易懂地介绍什么是区块链（技术篇） 比特币区块链技术图解 一文看懂区块链：一步一步发明比特币 一步一步学区块链 按步骤的实际操作入门指南 区块链技术指南 区块链领域比较系统的入门资料 理解区块链 区块链关键技术要点讲解 一文看懂区块链架构设计 从技术分层解构架构 共识算法与如何解决拜占庭将军问题 Ethereum 以太坊进阶 区块链技术-智能合约-以太坊 以太坊智能合约入门概念 以太坊白皮书 The Ethereum Wiki (English) 以太坊设计原理 以太坊Dapp开发入门 以太坊Gas使用 Calculating Costs in Ethereum Contracts (English) 以太坊代码剖析 以太坊源码阅读 Merkle Tree学习 以太坊的指南针 Fabric 联盟链进阶 Blockchain区块链架构设计之一：成员管理 Blockchain区块链架构设计之二：分布式账本技术对比 Blockchain区块链架构设计之三：Hyperledger Fabric介绍 Blockchain区块链架构设计之四：Fabric多通道和下一代账本设计 Blockchain区块链架构设计之五：让DLT产生协作，对Corda和GSL的思考 Blockchain区块链架构设计之六：Fabric 1.0账本设计（1） Blockchain区块链架构设计之七：Fabric 1.0 Endorse背书策略 Hyperledger架构解读：Hyperledger Fabric1.0架构概览 TUTORIAL 教程BitCoin 比特币 Bitcoin and Cryptocurrency Technologies Cousera上的比特币教程 (English) Ethereum 以太坊 以太坊从零开始入门 以太坊开发入门经验 mac配置以太坊本地开发环境 以太坊智能合约编程之菜鸟教程 以太坊常见问题FAQ 区块链语言Solidity校验椭圆曲线加密数字签名（附实例） Create your own crypto-currency 来自以太坊官方的代币创建教程 (English) ETHEREUM PET SHOP Truffle框架逐步案例教程 (English) ROBUST SMART CONTRACTS WITH OPENZEPPELIN OpenZeppelin集成Truffle编写健壮安全的合约 (English) Truffle3.0案例教程 集成NodeJS并完全跑通，附详细实例和可能的错误 (English) 以太坊开发入门教程 Fabric 联盟链 Fabric Basics 使用Docker Toolbox来搭建Fabric的开发环境 (English) Learn Chaincode Fabric Chaincode入门 (English) Marbles Project Tutorial: Part One 官方Chaincode案例教程第一部分 (English) Marbles Project Tutorial: Part Two 官方Chaincode案例教程第二部分 (English) Hyperledger Fabric V1.0– 开发者快速入门 这个是基于baseos 0.2.2 的 搭建运行Fabric V1.0-alpha版本 针对Fabric1.0版本的开发环境搭建指引 Fabric v1.0-alpha 开发镜像编译 使用Fabric源码编译v1.0-alpha版本的Docker镜像指引 Hyperledger Composer使用入门 官方Fabric应用开发工具Hyperledger Composer入门 Fabric-CA-1.0-Alpha小结 Videos 视频 Building Ethereum DApps using Solidity 视频教程 (English) Devcon 0 (Berlin, 2014) talks and videos (English) Devcon 1 (London, 2015) talks and videos (English) Devcon 2 (Shanghai, 2016) talks and videos (English) Devcon 3 (Cancún, 2017) website and registration (English) PROJECT 项目Chain 区块链底层 Metaverse 原界链源码 EOS EOS链源码 BYTOM 比原链源码 NEO NEO链源码 CITA cita联盟链的底层源码 Nervos 公链 Nervos CKB 的底层源码 比特币0.1 最原始的比特币代码 Quorum 来自JP Morgan基于Go-Ethereum数据隐私加强的以太坊实现 FISCO-BCOS 来自金链盟的聚焦金融行业的区块链底层平台 Presto-Ethereum 以太坊增加Presto的SQL访问能力 IPFS IPFS的GO语言实现 原理 SDK 工具包 Remix 在线以太坊编译器 Truffle 以太坊Dapp开发脚手架 Zeppelin 用于编写安全的以太坊合约框架 Web3j 以太坊官方Web3轻量级java SDK Embark 以太坊Dapp开发框架，支持IPFS、Whisper及Orbit调用 Web3Swift 一个Web3的swift SDK Porosity 反编译以太坊智能合约工具 Solidity-Coverage 检测Solidity代码覆盖 Caliper hyperledger区块链性能测试工具 Composer 官方可视化Fabric应用开发框架 Cakeshop 来自JP Morgan的以太坊可视化管理工具 Research 最新研究 eWASM 让以太坊支持WebAssembly FSolidM 可视化智能合约生成工具 源码 Maian 以太坊智能合约漏洞查找工具 Oyente 以太坊智能合约分析工具 Blockbench 区块链性能测试工具 Zokrates 以太坊使用zkSNARKS工具包(实验用) libsnark zkSNARKS C++库 DOCUMENT 资料BitCoin 比特币 精通比特币 精通比特币开发Oreilly开源书 中文翻译版 blockchaindev.org 区块链创业公司维优CTO的专栏 区块链研习社 比特币源码解读 Ethereum 以太坊 Mastering Ethereum 精通以太坊开发Oreilly开源书 区块链技术博客 关注以太坊 以太坊系列教程 solidity语言学习 Solidity语言文档 语言中文手册 Web3.JS接口文档 接口中文手册 Truffle框架文档 框架中文手册 Open Zeppelin框架文档 框架中文手册 Ethplorer接口 Ethplorer接口文档 Ethereum Smart Contract Security Best Practices (english) 以太坊常见问题FAQ EthList 以太坊开发相关学习资料收集 Fabric 联盟链 Fabric Official Docs Fabric官方最新文档 浮白 Fabric开发环境搭建与codechain入门 yeasy的专栏 IBM fabric核心开发者yeasy的专栏 菜鸟的博客 fabric0.6及1.0源码分析 jiang_xinxing的博客 fabric0.6源码分析 APPLICATION 应用Explorer 链浏览 Blockchain 比特币区块链浏览器 Etherscan 以太坊区块链浏览器 Ethplorer 以太坊区块链浏览器，提供API调用 Eth Gas Station 以太坊Gas目前定价 Etherscope 以太坊区块链浏览器 Wallet 钱包 My Ether Wallet 网页版以太坊钱包 源码 MetaMask Chrome Extension浏览器插件版 Multi-platform Jaxx Wallet 同时兼容以太坊和比特币钱包 Mist Wallet 官方版轻量级钱包 Parity Wallet Harmony Wallet imToken 移动App版钱包 Trust iOS / Android 原生钱包 + DApp 浏览器 Cipher iOS / Android 钱包 + DApp 浏览器 Ledger Nano S 硬件钱包 Trezor 硬件钱包 Exchange 交易所 0x 0x交易所平台 源码 IDEX IDEX交易所，目前最活跃 源码 ethdelf etherdelta交易所 源码 forkdelta forkdelta交易所,较活跃 源码 kyber kyber交易所 源码 Dmarket dmarket交易所 源码 augur 对赌交易所 源码 melonport 数字资产交易所 源码 Game 游戏 CryptoKitties 以太猫 Etheremon 以太神奇宝贝 Edgeless 虚拟币在线赌场 源码 IM 通信 status-im status.im项目开源代码 Social 社会 Oraclize 第三方信息提供 Aragon 公司业务 源码 dharma 第三方增信 源码 Chronobank 共享机制 slockit 租借智能设备 源码 DAO DAO提案 Cross Chain 跨链 Cosmos cosmos跨链交易，包括BTC到ETH 源码 polkadot polkadot跨链，实现了一个轻量级以太坊客户端 源码 Token 代币 ERC20 以太坊的ICO代币标准 Token Sale 代币销售模型 maker Dai代币 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"导航","slug":"导航","permalink":"https://lywlefan.github.io/tags/导航/"}]},{"title":"后端导航","date":"2019-10-14T16:00:00.000Z","path":"2019/10/15/后端/后端导航/","text":"官网导航java前沿技术人工智能技术人工智能图片补全 博客汇总团队博客美团技术团队&emsp;滴滴技术团队&emsp;阿里中间件团队博客 &emsp;阿里云系统组技术博客&emsp; 腾讯云+社区 Qcon 极客邦&emsp; 个人博客必看博主酷壳 阮一峰的网络日志 敖小剑的博客 领域博主区块链领域万维链博客 其他领域 技匠社 &emsp;少数派&emsp;李学凯&emsp;程序员DD &emsp;周立|Spring Cloud &emsp;泥瓦匠BYSocket的博客 &emsp;KL博客 Edison Xu’s Blog &emsp;梁桂钊的博客 &emsp;城南往事 &emsp;Any-Video 钿畑的博客&emsp; chenssy &emsp;徐靖峰|个人博客 &emsp;猿天地 crossoverjie&emsp; 芋道源码 &emsp;Pure White &emsp;小柒&emsp; 汤雪华的博客&emsp; kafka核心技术讲解作者·huxihx &emsp;黄小斜 黄小斜github&emsp;张逸的博客(ThoughtWorks架构师)&emsp;神经网络与深度学习·邱锡鹏&emsp; 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"导航","slug":"导航","permalink":"https://lywlefan.github.io/tags/导航/"}]},{"title":"如何把订单均匀分布到分片表里面","date":"2019-09-28T16:00:00.000Z","path":"2019/09/29/后端/中间件/分库分表/sharding-jdbc/如何把订单均匀分布到分片表里面/","text":"这几天学习了数据库的中间件—-sharding-jdbc, 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"分库分表","slug":"分库分表","permalink":"https://lywlefan.github.io/tags/分库分表/"},{"name":"sharding-jdbc","slug":"sharding-jdbc","permalink":"https://lywlefan.github.io/tags/sharding-jdbc/"}]},{"title":"初始Sharding-jdbc.md","date":"2019-09-26T16:00:00.000Z","path":"2019/09/27/后端/中间件/分库分表/sharding-jdbc/初始Sharding-jdbc/","text":"让我们一起来学习数据库中间件shardingsphere,shareding-jdbc是他其中的一个产品. what什么是shardingsphere?shardingsphere是一个数据库中间件, 参考文档 官方文档 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"分库分表","slug":"分库分表","permalink":"https://lywlefan.github.io/tags/分库分表/"},{"name":"sharding-jdbc","slug":"sharding-jdbc","permalink":"https://lywlefan.github.io/tags/sharding-jdbc/"}]},{"title":"try-with-resources和multiple catch的学习","date":"2019-09-02T16:00:00.000Z","path":"2019/09/03/后端/基础巩固/java/异常/try-with-resources和multiple catch的学习/","text":"万丈高楼平地起的前提是地基好. try-with-resources是什么?在Java编程过程中，如果打开了外部资源（文件、数据库连接、网络连接等），我们必须在这些外部资源使用完毕后，手动关闭它们。因为外部资源不由JVM管理，无法享用JVM的垃圾回收机制，如果我们不在编程时确保在正确的时机关闭外部资源，就会导致外部资源泄露，紧接着就会出现文件被异常占用，数据库连接过多导致连接池溢出等诸多很严重的问题。 为了确保外部资源一定要被关闭，通常关闭代码被写入finally代码块中，当然我们还必须注意到关闭资源时可能抛出的异常，于是变有了下面的经典代码： 1234567891011121314151617public static void main(String[] args) &#123; FileInputStream inputStream = null; try &#123; inputStream = new FileInputStream(new File(\"test\")); System.out.println(inputStream.read()); &#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; &#125; &#125;&#125; multiple catch是什么? 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"AOT,JIT学习总结","date":"2019-09-02T16:00:00.000Z","path":"2019/09/03/后端/基础巩固/java/jvm/AOT,JIT学习/","text":"万丈高楼平地起的前提是地基好. 是什么?JIT，即Just-in-time,动态(即时)编译，边运行边编译；AOT，Ahead Of Time，指运行前编译，是两种程序的编译方式 区别这两种编译方式的主要区别在于是否在“运行时”进行编译 JIT优点 可以根据当前硬件情况实时编译生成最优机器指令（ps. AOT也可以做到，在用户使用是使用字节码根据机器情况在做一次编译） 可以根据当前程序的运行情况生成最优的机器指令序列 当程序需要支持动态链接时，只能使用JIT 可以根据进程中内存的实际情况调整代码，使内存能够更充分的利用 缺点 编译需要占用运行时资源，会导致进程卡顿 由于编译时间需要占用运行时间，对于某些代码的编译优化不能完全支持，需要在程序流畅和编译时间之间做权衡 在编译准备和识别频繁使用的方法需要占用时间，使得初始编译不能达到最高性能 AOT优点 在程序运行前编译，可以避免在运行时的编译性能消耗和内存消耗 可以在程序运行初期就达到最高性能 可以显著的加快程序的启动 缺点 在程序运行前编译会使程序安装的时间增加 牺牲Java的一致性 将提前编译的内容保存会占用更多的外 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"02.redis的线程IO和通讯协议","date":"2019-08-12T16:00:00.000Z","path":"2019/08/13/后端/数据存储/NOSQL/redis/03.redis的线程IO和通讯协议/","text":"redis的线程IO 线程IO Redis是个单线程程序!但是他有高并发特性,单个节点可以支持10w的QPS。除了redis是单线程,Nginx也是单线程的。单线程为什么如此之快?单线程有如何处理多并发的客户端连接?下面让我们带着这些问题一起深究redis的线程IO。 5种IO模型学习 阻塞IO模型 非阻塞IO模型 IO复用模型 信号驱动的IO模型 异步IO模型 阻塞IO模型进程发起IO系统调用后，进程被阻塞，转到内核空间处理，整个IO处理完毕后返回进程。操作成功则进程获取到数据。 类比老李去火车站买票，排队三天买到一张退票。 耗费：在车站吃喝拉撒睡 3天，其他事一件没干。 典型应用 阻塞socket java BIO 特点 进程阻塞挂起不消耗CPU资源，及时响应每个操作； 实现难度低、开发应用较容易； 适用并发量小的网络应用开发； 不适用并发量大的应用：因为一个请求IO会阻塞进程，所以，得为每请求分配一个处理进程（线程）以及时响应，系统开销大。 非阻塞IO模型进程发起IO系统调用后，如果内核缓冲区没有数据，需要到IO设备中读取，进程返回一个错误而不会被阻塞；进程发起IO系统调用后，如果内核缓冲区有数据，内核就会把数据返回进程。 类比 老李去火车站买票，隔12小时去火车站问有没有退票，三天后买到一张票。 耗费：往返车站6次，路上6小时，其他时间做了好多事。 典型应用 socket是非阻塞的方式（设置为NONBLOCK） 特点 进程轮询（重复）调用，消耗CPU的资源； 实现难度低、开发应用相对阻塞IO模式较难； 适用并发量较小、且不需要及时响应的网络应用开发； IO复用模型多个的进程的IO可以注册到一个复用器（select）上，然后用一个进程调用该select， select会监听所有注册进来的IO； 如果select没有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞；而当任一IO在内核缓冲区中有可数据时，select调用就会返回； 而后select调用进程可以自己或通知另外的进程（注册进程）来再次发起读取IO，读取内核中准备好的数据。 可以看到，多个进程注册IO后，只有另一个select调用进程被阻塞。 类比是找一个宿管大妈来帮你监视下楼的女生, 这个期间你可以些其他的事情. 例如可以顺便看看其他妹子,玩玩王者荣耀, 上个厕所等等. IO复用又包括 select, poll, epoll 模式. 那么它们的区别是什么? select 每一个女生下楼, select大妈都不知道这个是不是你的女神, 她需要一个一个询问, 并且select大妈能力还有限, 最多一次帮你监视1024个妹子 poll 不限制盯着女生的数量, 只要是经过宿舍楼门口的女生, 都会帮你去问是不是你女神 epoll 不限制盯着女生的数量, 并且也不需要一个一个去问. 那么如何做呢? epoll大妈会为每个进宿舍楼的女生脸上贴上一个大字条,上面写上女生自己的名字, 只要女生下楼了, epoll大妈就知道这个是不是你女神了, 然后大妈再通知你. 典型应用 select poll epoll三种方案 nginx都可以选择使用这三个方案 Java NIO; 特点 专一进程解决多个进程IO的阻塞问题，性能好；Reactor模式; 实现、开发应用难度较大； 适用高并发服务应用开发：一个进程（线程）响应多个请求 形成原因如果一个I/O流进来，我们就开启一个进程处理这个I/O流。那么假设现在有一百万个I/O流进来，那我们就需要开启一百万个进程一一对应处理这些I/O流（——这就是传统意义下的多进程并发处理）。思考一下，一百万个进程，你的CPU占有率会多高，这个实现方式及其的不合理。所以人们提出了I/O多路复用这个模型，一个线程，通过记录I/O流的状态来同时管理多个I/O，可以提高服务器的吞吐能力。 信号驱动的IO模型当进程发起一个IO操作，会向内核注册一个信号处理函数，然后进程返回不阻塞；当内核数据就绪时会发送一个信号给进程，进程便在信号处理函数中调用IO读取数据。 特点 回调机制，实现、开发应用难度大； 异步IO模型当进程发起一个IO操作，进程返回（不阻塞），但也不能返回果结；内核把整个IO处理完后，会通知进程结果。如果IO操作成功则进程直接获取到数据。 特点 不阻塞，数据一步到位；Proactor模式； 需要操作系统的底层支持，LINUX 2.5 版本内核首现，2.6 版本产品的内核标准特性； 实现、开发应用难度大； 非常适合高性能高并发应用 典型 JAVA7 AIO 高性能服务器应用 通过学习5种IO模型,我们知道了Redis就是使用的IO复用模型里面的select。 指令队列Redis 会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。 也就是说指令的请求顺序是通过队列来进行约束的。 响应队列每个客户端关联一个响应队列。然后服务端通过响应队列将数据返回给客户端。 定时任务服务器处理要响应 IO 事件外，还要处理其它事情。比如定时任务就是非常重要的一件事。如果线程阻塞在 select 系统调用上，定时任务将无法得到准时调度。那 Redis 是如何解决这个问题的呢？ 如果面试官问到这个问题我肯定是处于懵逼状态。老钱书中写到,redis会把定时任务记录到一个叫最小堆的数据结构中,每个周期循环redis会立即处理堆最上面的数据。 redis的通讯协议 通讯协议 RESP协议简介Redis 的客户端和服务端之间采取了一种独立名为 RESP(REdis Serialization Protocol) 的协议，作者主要考虑了以下几个点： 容易实现 解析快 人类可读 注意：RESP 虽然是为 Redis 设计的，但是同样也可以用于其他 C/S 的软件。 数据类型及示例RESP 主要可以序列化以下几种类型：整数，单行回复(简单字符串)，数组，错误信息，多行字符串。Redis 客户端向服务端发送的是一组由执行的命令组成的字符串数组，服务端根据不同的命令回复不同类型的数据，但协议的每部分都是以 “\\r\\n” (CRLF) 结尾的。另外 RESP 是二进制安全的，不需要处理从一个进程到另一个进程的传输，因为它使用了前缀长度进行传输。 在 RESP 中, 一些数据的类型通过它的第一个字节进行判断： 单行回复：回复的第一个字节是 “+” 错误信息：回复的第一个字节是 “-” 整形数字：回复的第一个字节是 “:” 多行字符串：回复的第一个字节是 “\\$” 数组：回复的第一个字节是 “*” RESP 协议还是相对易于理解的，另外理解了协议也方便对 Redis 一些问题的定位及客户端的实现。 Redis 协议里有大量冗余的回车换行符，但是这不影响它成为互联网技术领域非常受欢迎的一个文本协议。有很多开源项目使用 RESP 作为它的通讯协议。在技术领域性能并不总是一切，还有简单性、易理解性和易实现性，这些都需要进行适当权衡。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"内功修炼-算法02","date":"2019-08-12T16:00:00.000Z","path":"2019/08/13/算法/算法基础/力扣/内功修炼-算法02/","text":"万丈高楼平地起的前提是地基好. 题目:无重复字符的最长子串题目描述给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。 示例 1: 123456789101112131415输入: &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。示例 2:输入: &quot;bbbbb&quot;输出: 1解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。示例 3:输入: &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。 题目分析关键点 不含有重复字符的最大字符串长度 思路梳理我的解题思路 1.把字符串转换为字符数组 2.把字符串逐个放入set集合(set),同时记录放入集合的数量(j) 2.如果set集合长度和放入数量不符,记录该长度(l),清空set集合,把j设置为0,放入刚才放入的值,继续循环 3.如果继续出现上述清空,和上面记录的长度进行对比,小于清空继续,大于更新记录长度 总结:上述解题思路忽略了空格字符串的情况,存在问题. 正确的解题思路:滑动窗口 时间窗移动原理 1.定义一个map集合(map)，用于存储字符值和位置，key为字符，value为字符位置加1 2.定义一个变量ans,用于记录时间窗最大长度 3.定义时间窗起点start和时间窗结束点end 4.然后把end向右滑动,最大长度为（end-start+1），如果map集合中存在该元素,说明遇到了重复的元素 4.1.记录时间窗最大值ans 4.2.移动时间窗start到重复元素第一个之后的位置 5.继续滑动,直到j=字符串长度 题目解答我的解答123456789101112131415161718192021222324252627282930313233/** * 思路一: * * 1.把字符串转换为字符数组 * 2.把字符串逐个放入set集合(set),同时记录放入集合的数量(j) * 2.如果set集合长度和放入数量不符,记录该长度(l),清空set集合,把j设置为0,放入刚才放入的值,继续循环 * 3.如果继续出现上述清空,和上面记录的长度进行对比,小于清空继续,大于更新记录长度 * * 时间复杂度:T(N) 空间复杂度:O(1) * * 测试情况:不通过 * * 总结分析: * * 1.没有考虑到空格字符串的情况 */public int lengthOfLongestSubstring1(String s) &#123; char [] chars = s.toCharArray(); Set set = new HashSet(); int l=0; for (int i=0,j=0;i&lt;chars.length;i++)&#123; set.add(chars[i]); j++; if (set.size()&lt;j)&#123; l = Math.max(set.size(),l); set.clear(); j = 1; set.add(chars[i]); &#125; &#125; return l;&#125; 正确的解答1234567891011121314151617181920212223242526/** * 思路二: 滑动窗口 * * 1.定义一个map集合(map)，用于存储字符值和位置，key为字符，value为字符位置加1 * 2.定义一个变量ans,用于记录时间窗最大长度 * 3.定义时间窗起点start和时间窗结束点end * 4.然后把end向右滑动,最大长度为（end-start+1），如果map集合中存在该元素,说明遇到了重复的元素 * 4.1.记录时间窗最大值ans * 4.2.移动时间窗start到重复元素第一个之后的位置 * 5.继续滑动,直到j=字符串长度 * */public int lengthOfLongestSubstring2(String s) &#123; int n = s.length(), ans = 0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); for (int end = 0, start = 0; end &lt; n; end++) &#123; char alpha = s.charAt(end); if (map.containsKey(alpha)) &#123; start = Math.max(map.get(alpha), start); &#125; ans = Math.max(ans, end - start + 1); map.put(s.charAt(end), end + 1); &#125; return ans;&#125; 题目总结在做这道题目的过程中,没有考虑到空格字符串的情况,这是基础不扎实导致的,null/“”/“ “,这三个还是有很大的区别的,如果大家也遇到和我一样的问题,可以当做是一个教训。 还有就是滑动窗口,这个理解比较麻烦,最好可以看我上面画的那种图,或者你可以自己画一个出来,滑动窗口是一个常用的办法,我们要深入理解。记得在有一次做限流的时候也用到了滑动窗口的概念。 问题讨论 假如让你用滑动窗口实现一个简单的限流,如何实现?(加入星球看答案哦!里面有更多精彩内容!) 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"力扣","slug":"力扣","permalink":"https://lywlefan.github.io/tags/力扣/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"21.合并两个有序的链表","date":"2019-08-05T16:00:00.000Z","path":"2019/08/06/算法/算法基础/力扣/21.合并两个有序的链表/","text":"万丈高楼平地起的前提是地基好. 题目介绍将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例 1: 12输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 题目解答思路梳理题目实现java12 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"力扣","slug":"力扣","permalink":"https://lywlefan.github.io/tags/力扣/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"22.括号的生成","date":"2019-08-04T16:00:00.000Z","path":"2019/08/05/算法/算法基础/力扣/22.括号的生成/","text":"万丈高楼平地起的前提是地基好. 题目介绍给出 n 代表生成括号的对数，请你写出一个函数，使其能够生成所有可能的并且有效的括号组合。 例如，给出 n = 3，生成结果为： 12345678[ &quot;((()))&quot;, &quot;(()())&quot;, &quot;(())()&quot;, &quot;()(())&quot;, &quot;()()()&quot;] 思路梳理关键点 生成括号对数 生成括号不同对数 生成的括号必须要闭合 生成括号的类型要用大括号包住 如何实现哪??我的思路:分类法 (X) 第一种情况:括号中括号 第二种情况:括号中多个括号 第三种情况:分割括号,然后括号中括号(左右) 第四种情况:括号独立类型 官方思路:题目实现我的实现分析代码最优解实现分析代码 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"力扣","slug":"力扣","permalink":"https://lywlefan.github.io/tags/力扣/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"20.有效的括号","date":"2019-08-01T16:00:00.000Z","path":"2019/08/02/算法/算法基础/力扣/20.有效的括号/","text":"万丈高楼平地起的前提是地基好. 题目介绍给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。左括号必须以正确的顺序闭合。注意空字符串可被认为是有效字符串。 示例 1: 1234567891011输入: &quot;()&quot;输出: true示例 2:输入: &quot;()[]&#123;&#125;&quot;输出: true示例 3:输入: &quot;(]&quot;输出: false 题目解答思路梳理哪些情况括号不闭合 第一种:[(]) 第二种:[) 第三种:[]( 如何判断括号没有闭合 注意：只包括括号，这是条件要注意！ 1.获取每种类型左括号的第一次出现的位置 2.然后再找到每种类型右括号第一次出现的位置 3.如果存在以下情况则括号没有闭合 a.类型左括号位置小于另一种类型括号右括号的位置,则括号没有闭合 b.任意类型括号不存在左括号或者右括号,则括号没有闭合 最优解 1.把左括号压入栈中 2.如果遇到右括号,取出栈最上面的元素去对应的值,判断和循环的元素是否相等,相等继续循环,否则返回false 3.循环结束,栈里面的元素依次被取出,说明括号串没啥问题,是闭合的. 题目实现java123456789101112131415161718192021222324static Map&lt;Character, Character&gt; map = new HashMap();static &#123; map.put('(', ')'); map.put('&#123;', '&#125;'); map.put('[', ']');&#125;/** * 方法一 */public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack = new Stack(); for (char in : s.toCharArray()) &#123; //左括号直接入栈 if (map.keySet().contains(in)) &#123; stack.push(in); continue; &#125; if (!stack.isEmpty() &amp;&amp; in == map.get(stack.pop())) continue; return false; &#125; return stack.isEmpty();&#125; 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"力扣","slug":"力扣","permalink":"https://lywlefan.github.io/tags/力扣/"},{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"}]},{"title":"算法导航","date":"2019-07-31T16:00:00.000Z","path":"2019/08/01/算法/算法导航/","text":"万丈高楼平地起的前提是地基好. 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】leetcode算法指南 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"导航","slug":"导航","permalink":"https://lywlefan.github.io/tags/导航/"}]},{"title":"ab.exe压测工具的使用","date":"2019-07-30T16:00:00.000Z","path":"2019/07/31/测试/压力测试/ab.exe压测工具的使用/","text":"工欲善其事，必先利器！ ad.exe介绍ab.exe是一个性能检测工具，是apache server中的一个小组件，使用简单，方便 ad.exe下载下载地址 ad.exe使用步骤打开cmd进入ab.exe所在的路径（默认放在d盘根目录下）命令示例 1234567 #介绍ab的命令ab help#ab命令请求（一共请求10次,10个并发同时请求）ab -n 10 -c 10 http://www.cnblogs.com/#ab命令超时请求（一共请求50次,50个并发同时请求，超时时间设为100秒， 当出现timeout时，可以设置超时时间）ab -n 50 -c 50 -t 100 http://www.cnblogs.com/ ab命令使用场景 可以测试网关的限流 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"压力测试","slug":"压力测试","permalink":"https://lywlefan.github.io/tags/压力测试/"}]},{"title":"02.redis的应用--布隆过滤器","date":"2019-07-29T16:00:00.000Z","path":"2019/07/30/后端/数据存储/NOSQL/redis/02.redis的应用--布隆过滤器/","text":"布隆过滤器思维导图 布隆过滤器 布隆过滤器应用新闻推送去重垃圾邮件去重插件安装下载插件点击该地址选择合适的版本 1234567#下载wget https://github.com/RedisLabsModules/rebloom/archive/v1.1.1.tar.gz#解压tar zxvf v1.1.1.tar.gzcd rebloom-1.1.1# 编译make 配置插件在redis配置文件(redis.conf)中加入该模块即可 1loadmodule /usr/local/web/redis/RedisBloom-1.1.1/rebloom.so 或者启动的时候加载进去： 1redis-server /etc/redis/redis.conf --loadmodule /opt/redis/RedisBloom-2.0.1/src/rebloom.so INITIAL_SIZE 10000000 ERROR_RATE 0.0001 执行相关命令测试 以上就是我安装的步骤，但是安装完成后还是出现了问题，记录下来，后续慢慢解决。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 【4】布隆过滤器插件下载地址 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"01.初始redis","date":"2019-07-29T16:00:00.000Z","path":"2019/07/30/后端/数据存储/NOSQL/redis/01.初始redis/","text":"redis是什么?redis是一个内存型数据(in-memory data structure store)。Redis是用ANSI C编写的。 官网对redis关键词描述 开源内存数据库 可以进行缓存和消息代理 支持的数据类型有：字符串/hash/list/set/bitmaps/hyperloglogs 可以对集合进行排序 地理位置范围半径查询 支持流 内置复制功能 支持lua脚本 LRU缓存淘汰算法 磁盘级的持久化 redis集群 redis支持什么数据类型字符类型(strings)哈希类型(hashes)list集合类型(lists)set集合类型(sets) 不允许重复 无序 sorted set集合类型(sorted sets) 不允许重复 有序(通过设置分数进行排序) 位图(bitmaps) 按位进行标识 适合某个时间段状态只有两种的场景 比如:签到,每天签到,状态就是签了或者没签 占用内存小 hyperloglogs Redis 在 2.8.9 版本添加了 HyperLogLog 结构 Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 HyperLogLog是一种算法，并非redis独有 目的是做基数统计，故不是集合，不会保存元数据，只记录数量而不是数值。 耗空间极小，支持输入非常体积的数据量 核心是基数估算算法，主要表现为计算时内存的使用和数据合并的处理。最终数值存在一定误差 redis中每个hyperloglog key占用了12K的内存用于标记基数（官方文档） pfadd命令并不会一次性分配12k内存，而是随着基数的增加而逐渐增加内存分配；而pfmerge操作则会将sourcekey合并后存储在12k大小的key中，这由hyperloglog合并操作的原理（两个hyperloglog合并时需要单独比较每个桶的值）可以很容易理解。 误差说明：基数估计的结果是一个带有 0.81% 标准错误（standard error）的近似值。是可接受的范围 Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间 数据结构描述特征 基数统计(不允许重复的数据) 占用12k空间 适用场景 统计注册 IP 数 统计每日访问 IP 数 统计页面实时 UV 数 统计在线用户数 统计用户每天搜索不同词条的个数 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"MPP(大规模并行处理)简介","date":"2019-07-18T16:00:00.000Z","path":"2019/07/19/后端/数据存储/MBPP数据库/MPP(大规模并行处理)简介/","text":"&emsp;&emsp;实践一门技术的最好方式就是深入理解它的思想，然后造一个出来！ 1、 什么是MPP？MPP (Massively Parallel Processing)，即大规模并行处理，在数据库非共享集群中，每个节点都有独立的磁盘存储系统和内存系统，业务数据根据数据库模型和应用特点划分到各个节点上，每台数据节点通过专用网络或者商业通用网络互相连接，彼此协同计算，作为整体提供数据库服务。非共享数据库集群有完全的可伸缩性、高可用、高性能、优秀的性价比、资源共享等优势。 简单来说，MPP是将任务并行的分散到多个服务器和节点上，在每个节点上计算完成后，将各自部分的结果汇总在一起得到最终的结果(与Hadoop相似)。 2、MPP(大规模并行处理)架构 (MPP架构) 3、 MPP架构特征● 任务并行执行; ● 数据分布式存储(本地化); ● 分布式计算; ● 私有资源; ● 横向扩展; ● Shared Nothing架构。 4、 MPP服务器架构它由多个SMP服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。其基本特征是由多个SMP服务器(每个SMP服务器称节点)通过节点互联网络连接而成，每个节点只访问自己的本地资源(内存、存储等)，是一种完全无共享(Share Nothing)结构，因而扩展能力最好，理论上其扩展无限制。 5、MPPDBMPPDB是一款 Shared Nothing 架构的分布式并行结构化数据库集群，具备高性能、高可用、高扩展特性，可以为超大规模数据管理提供高性价比的通用计算平台，并广泛地用于支撑各类数据仓库系统、BI 系统和决策支持系统 6、MPPDB架构MPP 采用完全并行的MPP + Shared Nothing 的分布式扁平架构，这种架构中的每一个节点（node）都是独立的、自给的、节点之间对等，而且整个系统中不存在单点瓶颈，具有非常强的扩展性。 7、 MPPDB特征MPP 具备以下技术特征： 1) 低硬件成本：完全使用 x86 架构的 PC Server，不需要昂贵的 Unix 服务器和磁盘阵列； 2) 集群架构与部署：完全并行的 MPP + Shared Nothing 的分布式架构，采用 Non-Master 部署，节点对等的扁平结构； 3) 海量数据分布压缩存储：可处理 PB 级别以上的结构化数据，采用 hash分布、random 存储策略进行数据存储；同时采用先进的压缩算法，减少存储数据所需的空间，可以将所用空间减少 1~20 倍，并相应地提高 I/O 性能； 4) 数据加载高效性：基于策略的数据加载模式，集群整体加载速度可达2TB/h； 5) 高扩展、高可靠：支持集群节点的扩容和缩容，支持全量、增量的备份/恢复; 6) 高可用、易维护：数据通过副本提供冗余保护，自动故障探测和管理，自动同步元数据和业务数据。提供图形化工具，以简化管理员对数据库的管理工作； 7) 高并发：读写不互斥，支持数据的边加载边查询，单个节点并发能力大于 300 用户； 8) 行列混合存储：提供行列混合存储方案，从而提高了列存数据库特殊查询场景的查询响应耗时； 9) 标准化：支持SQL92 标准，支持 C API、ODBC、JDBC、ADO.NET 等接口规范。 8、 常见MPPDB● GREENPLUM(EMC) ● Asterdata(Teradata) ● Nettezza(IBM) ● Vertica(HP) ● GBase 8a MPP cluster(南大通用) 9、 MPPDB、Hadoop与传统数据库技术对比与适用场景MPPDB与Hadoop都是将运算分布到节点中独立运算后进行结果合并(分布式计算)，但由于依据的理论和采用的技术路线不同而有各自的优缺点和适用范围。两种技术以及传统数据库技术的对比如下： 综合而言，Hadoop和MPP两种技术的特定和适用场景为： ● Hadoop在处理非结构化和半结构化数据上具备优势，尤其适合海量数据批处理等应用要求。 ● MPP适合替代现有关系数据机构下的大数据处理，具有较高的效率。 MPP适合多维度数据自助分析、数据集市等；Hadoop适合海量数据存储查询、批量数据ETL、非机构化数据分析(日志分析、文本分析)等。 由上述对比可预见未来大数据存储与处理趋势：MPPDB+Hadoop混搭使用，用MPP处理PB级别的、高质量的结构化数据，同时为应用提供丰富的SQL和事物支持能力；用Hadoop实现半结构化、非结构化数据处理。这样可以同时满足结构化、半结构化和非结构化数据的高效处理需求。 【1】简书主页·share猿 【2】掘金主页·share猿 — 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"MBPP数据库","slug":"MBPP数据库","permalink":"https://lywlefan.github.io/tags/MBPP数据库/"}]},{"title":"理财书籍收集","date":"2019-07-17T16:00:00.000Z","path":"2019/07/18/读书看报/书单/理财书籍收集/理财书籍收集/","text":"多读书，多看报，少吃零食，少睡觉！ 理财书籍汇集未读 《谁动了我的奶酪》 《小狗钱钱》 《富爸爸，穷爸爸》，《财务自由之路》和《投资指南》 《一分钟百万富翁》 《怎样启迪你头脑中的金融意识》 《财源滚滚》 《钻石就在你家后院》 《我的百万富翁兄弟》 已读 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"书单","slug":"书单","permalink":"https://lywlefan.github.io/tags/书单/"},{"name":"理财","slug":"理财","permalink":"https://lywlefan.github.io/tags/理财/"}]},{"title":"财务词汇","date":"2019-07-10T16:00:00.000Z","path":"2019/07/11/读书看报/词汇/财务/财务词汇/","text":"先有词汇量,然后再能好好说话,好好做事。 重要 不重要 理解 未理解 2019年7月份词汇重要理解词汇 资产 G:如何获得资产？a.加杠杆购买资产，产生源源不断的现金流b.花时间创造资产 负债 现值 是在给定的利率水平下，未来的资金折现到现在时刻的价值。 现金流 经营性现金流 投资性现金流 融资性现金流 资产负债表 损益表 所有者权益变动表 财务报表附注 审查报表 预算盈余 净现值法（NPV） 净现值 未来资金流现值与未来资金流出现值差额。 折现率 折现率是指将未来有限期预期收益折算成现值的比率。 内部收益率（IRR） 不重要理解词汇 直线法折旧 双倍余额递减法折旧（年折旧率=2÷预计的折旧年限×100％） 重要不理解词汇不重要不理解词汇 借款人 信贷人员 银行流水 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"词汇","slug":"词汇","permalink":"https://lywlefan.github.io/tags/词汇/"},{"name":"财务","slug":"财务","permalink":"https://lywlefan.github.io/tags/财务/"}]},{"title":"软件中未知词汇收集","date":"2019-07-10T16:00:00.000Z","path":"2019/07/11/读书看报/词汇/软件/软件中未知词汇收集/","text":"先有词汇量,然后再能好好说话,好好做事。 2019年词汇7月词汇二方库 一方库：本工程中的各模块的相互依赖 二方库：公司内部的依赖库，一般指公司内部的其他项目发布的jar包 三方库：公司之外的开源库， 比如apache、ibm、google等发布的依赖 mock数据在前后端分离开发过程中，后端为前端请求制造的模拟数据。常见制造模拟数据的方法有如下几种： easymock Mock.js server-mock SOA面向服务架构（Service-Oriented Architecture，SOA）又称“面向服务的体系结构”，是Gartner于2O世纪9O年代中期提出的面向服务架构的概念。 打tag说白了就是给你的项目打个标签，立个里程碑，这样就可以去方便的回溯每个版本的代码了。如何打tag，命令如下： 123456# 打tag -a 后面是tag名称 -m 后面是注释（这里我们可以写我们这个版本做了什么？）git tag -a v3.2.1 -m &apos;线上版本&apos;# 将标签提交到远程仓库git push origin v3.2.1 qps每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。 吞吐量 吞吐量是指系统在单位时间内处理请求的数量。 并发用户数 并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。 IO线程VisualVMVisualVM是JDK自带的一款全能型性能监控和故障分析工具,包括对CPU使用、JVM堆内存消耗、线程、类加载的实时监控,内存dump文件分析,垃圾回收运行情况的可视化分析等,对故障排查和性能调优很有帮助。 包装类包装类（Wrapper Class）： Java是一个面向对象的编程语言，但是Java中的八种基本数据类型却是不面向对象的，为了使用方便和解决这个不足，在设计类时为每个基本数据类型设计了一个对应的类进行代表，这样八种基本数据类型对应的类统称为包装类(Wrapper Class)，包装类均位于java.lang包。 栈栈就像枪的梭子一样,先进后出. 8月词汇TDDTDD是测试驱动开发（Test-Driven Development）的英文简称，是敏捷开发中的一项核心实践和技术，也是一种设计方法论。 时间复杂度一个算法中的所有语句执行次数之和称为语句频度或时间频度,记为T(n)。 空间复杂度如果算法执行所需要的临时空间不随着某个变量n的大小而变化，即此算法空间复杂度为一个常量，可表示为 O(1) 哑结点说白了就是无用的节点,一般处在链表的头部.是一个被人为创建的节点，虽然其内容为NULL，但是它在堆中有占有一定的空间。哑节点的使用可以避免边界问题的处理，达到简化代码与减少代码出错可能性的目的。 10月词汇QPSQuery Per Second，每秒请求数 IOPSInput/Output Operations Per Second，即每秒进行读写操作的次数 RT响应时间 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"软件","slug":"软件","permalink":"https://lywlefan.github.io/tags/软件/"},{"name":"新词","slug":"新词","permalink":"https://lywlefan.github.io/tags/新词/"}]},{"title":"研发英文词汇收集","date":"2019-07-10T16:00:00.000Z","path":"2019/07/11/读书看报/词汇/软件/研发英文词汇收集/","text":"先有词汇量,然后再能好好说话,好好做事。 java相关词汇框架存储关系型非关系型newSqlredis相关词汇 内存数据库:in-memory data structure store 消息代理:message broker 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"软件","slug":"软件","permalink":"https://lywlefan.github.io/tags/软件/"},{"name":"英文","slug":"英文","permalink":"https://lywlefan.github.io/tags/英文/"}]},{"title":"02.Java内存模型：看Java如何解决可见性和有序性问题","date":"2019-07-02T16:00:00.000Z","path":"2019/07/03/后端/高并发/java/书籍/java并发编程实战-王宝令/02.Java内存模型：看Java如何解决可见性和有序性问题 /","text":"阅读笔记 java内存模型 volatile Happens-Before规则 什么是java内存模型？java内存模型说的直白一点就是java程序使用内存的规范，让java语言在各种系统和平台中能保持数据的一致性。 Happens-Before规则（6项规则）前一个操作对后一个操作是可见的。假如有一个公有变量，a方法先引用然后b方法再引用，那么我们称a方法的操作对b方法可见。 程序顺序性规则假如有一个公有变量，a方法先引用然后b方法再引用，那么我们称a方法的操作对b方法可见。 volatile变量规则volatile变量的写操作对volatile变量读操作可见。说白了读之前，我要知道是谁写的，不然我不读。 传递性如果A对B可见，B对C可见，那么A对C可见。 管程中锁的规则管程是一种通用的同步原语，在java中指的是synchronized,synchronized是java里对管程的实现。 对变量进行加锁，执行完再继续。 线程smart()规则它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。 G:说白了就是主线程要优于子线程。 线程join()规则关键词解析volatile这个关键词可以禁用cpu缓存。禁用了cpu缓存，那么我们的变量只能从内存中进行读写。 Happens-Before规则Happens-Before规则说白了就是定义java内存模型的一种约束或者规则。 推荐书单 -《Java并发编程实战》作者阵容可谓大师云集，也包括Doug Lea -《Java并发编程的艺术》讲解并发包内部实现原理，能读明白，内功大增 -《图解Java多线程设计模式》并发编程设计模式方面的经典书籍 -《操作系统：精髓与设计原理》经典操作系统教材 http://ifeve.com 国内专业并发编程网站 http://www.cs.umd.edu/~pugh/java/memoryModel/ 很多并发编程的早期资料都在这里 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"java并发编程实战-王宝令","slug":"java并发编程实战-王宝令","permalink":"https://lywlefan.github.io/tags/java并发编程实战-王宝令/"}]},{"title":"学习攻略.如何才能学好并发编程？","date":"2019-07-01T16:00:00.000Z","path":"2019/07/02/后端/高并发/java/书籍/java并发编程实战-王宝令/学习攻略.如何才能学好并发编程？/","text":"阅读笔记并发是一门独立学科也是一门综合科学，从两个方面突破并发编程： 跳出来，看全景 钻进去，看本质 跳出来，看全景学习最忌讳的就是“盲人摸象”，只看到局部，没有全局。从单一知识点跳出来，高屋建瓴看并发编程，首要之事就是建立一张全景图。 并发核心问题分工像做项目的分工一样，不同的工作分给不同的人，实现工作效率最大化。 在学习抽象的东西的时候要多与现实生活中的场景进行类比。 Java SDK 并发包里的 Executor、Fork/Join、Future本质上都是一种分工的方式。 并发编程领域还总结了一些设计模式，基本上都是和分工方法相关的，例如生产者 - 消费者、Message、Worker Thread 模式等。 同步同步就相当于项目中的沟通协调，什么时间干什么工作。 放到软件程序中就是一个线程执行完，通知下一个线程执行而已。例如，用 Future 可以发起一个异步调用，当主线程通过 get() 方法取结果时，主线程就会等待，当异步执行的结果返回时，get() 方法就自动返回了，这就解决了我们主从线程的协作。 Java SDK 里提供的 CountDownLatch、CyclicBarrierr、Phaser、Exchanger 也都是用来解决线程协作问题的。 还有很多场景，是需要你自己来处理线程之间的协作。 在java并发编程领域，解决协作问题的核心就是管程，上面提到的所有线程协作技术底层都是利用管程解决的。管程是一种解决并发问题的通用模型，除了能解决线程协助问题，还能解决下面我们将要介绍的互斥问题。可以这么说，管程是解决并发问题的万能钥匙。 关键是理解管程模型，学好它就可以解决所有问题。 其次是了解java JDK并发包提供的几个线程协作的工具类场景，用好它们可以妥妥地提高你的工作效率。 互斥分工/同步主要强调性能，但是并发程序里还有一部分是关于正确性，用专业术语叫“线程安全”。 可见性问题 有序性问题 原子性问题 为了解决以上三个问题，java语言引入了内存模型，内存模型提供了一系列的规则，利用这些规则，我们可以避免以上问题。 所谓互斥，指的是同一时刻，只允许一个线程访问共享变量。 实现互斥的核心技术是锁，java语言里synchronized、SDK里各种Lock都能解决互斥问题。 虽说锁解决了安全性问题，但同时也带来了性能问题，那如何保证安全性的同时又尽量提高性能那？分场景优化： Java SDK 里提供的 ReadWriteLock、StampedLock 就可以优化读多写少场景下锁的性能。 还可以使用无锁的数据结构，例如 Java SDK 里提供的原子类都是基于无锁技术实现的。 除此之外，还有一些其他的方案，原理是不共享变量或者变量只允许许读。这方面，Java 提供了Thread Local 和 final 关键字，还有一种 Copy-on-write 的模式。 使用锁除了要注意性能问题外，还需要注意死锁问题。 这部分内容比较复杂，往往还是跨领域的，例如要理解可见性，就需要了解一些 CPU 和缓存的知识； 很多无锁算法的实现往往也需要理解 CPU 缓存。 这部分内容的学习，需要博览群书，在大脑里建立起 CPU、内存、I/O 执行的模拟器。 全景图 钻进去，看本质深入理解，找到本质。 多分析这些概念和结论是怎么来的？？ 它们是用来解决什么问题的？ 知其然知其所以然。 工程上解决问题，一定要有理论做基础。 总结 推荐书单 -《Java并发编程实战》作者阵容可谓大师云集，也包括Doug Lea -《Java并发编程的艺术》讲解并发包内部实现原理，能读明白，内功大增 -《图解Java多线程设计模式》并发编程设计模式方面的经典书籍 -《操作系统：精髓与设计原理》经典操作系统教材 http://ifeve.com 国内专业并发编程网站 http://www.cs.umd.edu/~pugh/java/memoryModel/ 很多并发编程的早期资料都在这里 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"java并发编程实战-王宝令","slug":"java并发编程实战-王宝令","permalink":"https://lywlefan.github.io/tags/java并发编程实战-王宝令/"}]},{"title":"12.客户端都有哪些不常见但是很高级的功能？","date":"2019-07-01T16:00:00.000Z","path":"2019/07/02/后端/中间件/消息中间件/kafka/读书笔记/kafka核心技术与实战-胡夕/12.客户端都有哪些不常见但是很高级的功能？/","text":"阅读笔记kafka 拦截器拦截器的原理和spring的拦截器的原理类似，可以做消息处理前后多个点的动态植入不同的处理逻辑。比如消息发送前或者在消息消费后。 kafka拦截器分为生产者拦截器和消费者拦截器。 生产拦截器允许你在发送消息前以及消息提交后植入你的拦截器逻辑； 消费拦截器支持在消费消息前以及提交位移后编写特定逻辑。 两种拦截器都支持链的方式，kafka会按序执行拦截器逻辑。 ###如何编写拦截器？ 生产者拦截器继承接口ProducerInterceptor onSend：消息调用前被调用 onAcknowledgement：消息提交成功或发送失败后被调用。这个方法要早于callback。这个方法和onSend不是在同一个线程里面调用，因此在两个方法调用过程中调用了某个共享变量，一定要保证线程安全。这个方法处在Producer发送的主路径中，所以我们不要放一些太重逻辑进去，负责你会发现Producer的TPS直线下降。 消费者拦截器实现ConsumerInterceptor接口 onConsume：在消息返回给Consumer 程序之前调用。也就是在消息开始处理前拦截一道。 onCommit：Consumer 在提交位移之后调用该方法。通常你可以在该方法做一些记账类的动作，比如：日志打印。 注意的问题 指定拦截器要指定它们全限定名，说的直白一点就是要把包名加上 典型使用场景 客户端监控 kafka默认提供的监控指标都是针对单个客户端或Broker的，你很难从具体消息维度去追踪群间消息的流转路径。同时如何监控一条消息从生产到最后消费的端到端延时也是很多kafka用户需要解决的问题。 从技术上讲，我们可以在客户端增加这样的逻辑，但是监控一般是不跟业务代码耦合的，因为耦合会影响业务代码性能。 基于以上的考虑，我们可以把监控的逻辑加到拦截器里面，这样做的好处可以实现可插拔，不耦合。 端到端性能检测 同上。 消息审计 所谓消息审计就是可以随时查看消息的去向，什么时间发布的？被什么业务消费了？我们就可以借用kafka的拦截器实现这个场景。 案例分享 处理端到端的延时 统计Producer到Consumer消费时间总时长，我们消费拦截器就可以按如下来写 1234567891011121314151617181920212223242526public class AvgLatencyProducerInterceptor implements ProducerInterceptor&lt;String, String&gt; &#123; private Jedis jedis; // 省略 Jedis 初始化 @Override public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123; jedis.incr(\"totalSentMessage\"); return record; &#125; @Override public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123; &#125; @Override public void close() &#123; &#125; @Override public void configure(Map&lt;java.lang.String, ?&gt; configs) &#123; &#125; 下面是消费端代码：123456789101112131415161718192021222324252627282930313233public class AvgLatencyConsumerInterceptor implements ConsumerInterceptor&lt;String, String&gt; &#123; private Jedis jedis; // 省略 Jedis 初始化 @Override public ConsumerRecords&lt;String, String&gt; onConsume(ConsumerRecords&lt;String, String&gt; records) &#123; long lantency = 0L; for (ConsumerRecord&lt;String, String&gt; record : records) &#123; lantency += (System.currentTimeMillis() - record.timestamp()); &#125; jedis.incrBy(\"totalLatency\", lantency); long totalLatency = Long.parseLong(jedis.get(\"totalLatency\")); long totalSentMsgs = Long.parseLong(jedis.get(\"totalSentMessage\")); jedis.set(\"avgLatency\", String.valueOf(totalLatency / totalSentMsgs)); return records; &#125; @Override public void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets) &#123; &#125; @Override public void close() &#123; &#125; @Override public void configure(Map&lt;String, ?&gt; configs) &#123;&#125; 这里我们可以用redis记录消息消费的时间,到redis中我们就可以很好的进行统计了,可以很好的统计到从producer到consumer的时间了。 小结 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"kafka核心技术与实战-胡夕","slug":"kafka核心技术与实战-胡夕","permalink":"https://lywlefan.github.io/tags/kafka核心技术与实战-胡夕/"}]},{"title":"01.可见性、原子性和有序性问题：并发编程Bug的源头","date":"2019-07-01T16:00:00.000Z","path":"2019/07/02/后端/高并发/java/书籍/java并发编程实战-王宝令/01.可见性、原子性和有序性问题：并发编程Bug的源头 /","text":"阅读笔记 可见性 原子性 有序性 并发幕后的故事这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个核心矛盾一直存在，就是这三者的速度差异。 CPU和内存速度差异可以形象描述:CPU是天上一天，内存是地上一年。内存和I/O设备速度差异就更大了，内存是天山一天，I/O设备是地上十年。 大部分程序是需要访问内存，有些还要访问I/O,所以单方面提高CPU性能是无效的。 为了合理利用CPU高性能，平衡三者的速度差异，计算机体系/操作系统/编译程序都做了很大的贡献，主要体现在以下几点： CPU增加了缓存，以均衡速度差异 操作系统增加了进程/线程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异； 编译程序优化指令执行次序，使得缓存能够更加合理的利用。 源头之一：缓存导致的可见性问题单核时代单核时代，所有线程在一颗CPU上执行，CPU缓存与内存的数据一致性容易解决。 一个线程对CPU的操作，其他线程都是可见的。 如下图所示，线程A和线程B都是操作同一个CPU里面的缓存，线程A操作CPU变量V之后，线程B再访问就一定可以得到最新值： 一个线程对共享变量的修改，另外一个线程立刻看到，我们称为可见性。 多核时代多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了。 当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的CPU。 线程 A 操作的是 CPU-1 上的缓存，而线程B操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。 多核 CPU 的缓存与内存关系图 下面我们再用一段代码来验证一下多核场景下的可见性问题。下面的代码，每执行一次 add10K() 方法，都会循环 10000 次 count+=1 操作。在 calc() 方法中我们创建了两个线程，每个线程调用一次 add10K() 方法，我们来想一想执行 calc() 方法得到的结果应该是多少呢？ 1234567891011121314151617181920212223242526public class Test &#123; private long count = 0; private void add10K() &#123; int idx = 0; while(idx++ &lt; 10000) &#123; count += 1; &#125; &#125; public static long calc() &#123; final Test test = new Test(); // 创建两个线程，执行 add() 操作 Thread th1 = new Thread(()-&gt;&#123; test.add10K(); &#125;); Thread th2 = new Thread(()-&gt;&#123; test.add10K(); &#125;); // 启动两个线程 th1.start(); th2.start(); // 等待两个线程执行结束 th1.join(); th2.join(); return count; &#125;&#125; 直觉可能告诉你应该是20000，但实际结果确实10000到20000之间的随机数。为什么那？因为两个线程在两cpu的核之间不断切换才导致的。 G:所谓可见性问题，说白了可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值同时可以操作这个值。 源头之二：线程切换带来的原子性问题 关键词： 线程切换 时间片 多进程 unix操作系统支持多进程分时复用而名噪天下 内存映射 一个进程创建的所有线程共享同一个内存空间 提到的“任务切换”都是指“线程切换” 高级语句里一条语句需要多条CPU指令来完成 比如：count + =1，需要以下几个指令来完成 指令一：把count从内存加载到cpu寄存器中 指令二：在寄存器执行+1操作 指令三：最后，将结果写入内存（缓存机制导致可能写入的是CPU缓存而不是内存） 重点语句 我们把一个或多个操作在CPU执行的过程中不被中断的特性称为原子性。 源头之三：编译优化带来的有序性问题 关键词 - 关键语句 有序性：代码按先后顺序执行 案例分析 利用双重检查创建单例对象 123456789101112public class Singleton &#123; static Singleton instance; static Singleton getInstance()&#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 上面的代码，假设有两个线程同时判断instance为null—&gt;此时A和B任意一个线程加锁成功（假设是A）,另外一个线程处于等待状态（假设是B）—&gt;线程A创建实例释放锁，然后唤醒B —&gt; B继续加锁，结果实力不为空，B不创建实例 以上逻辑看似无懈可击，但实际并不完美，问题出在哪里？？ 出在new操作上 我们以为的new操作： 1.分配一块内存M 2.在内存M上初始化Singleton对象 3.然后M的地址赋值给instance对象 实际优化后如下： 1.分配一块内存M 2.将M的地址赋值给instanc变量 3.最后在M上初始化Singleton对象 优化后会导致什么问题那？假设A先执行getInstance()方法，当执行完指令2后恰好发生了线程切换，切换到线程B上；如果此时线程B也执行getInstance方法，那么线程B在执行第一个判断时会发现instance！=null，所以直接返回instance，而此时的instance是没有初始化过的，如果这个时候访问instance的成员变量就可能触发空指针异常。 总结 要想写好并发，就要知道并发问题出在哪里 只要我们能够深刻理解可见性/原子性/有序性在并发场景下的原理，很多并发bug都可以理解，可以诊断。 缓存导致可见性问题 线程切换带来的原子性问题 编译优化带来的有序性问题 在采用一项技术的时候一定要清楚它带来的问题是啥，以及如何规避 思考 1.常听人说，在 32 位的机器上对 long 型变量进行加减操操作存在并发隐患，到底是不是这样呢？ long类型64位，所以在32位的机器上，对long类型的数据操作通常需要多条指令组合出来，无法保证原子性，所以并发的时候会出问题 疑问：什么是32位机器？指的是啥？ cpu运算的数据都是由内存提供的，内存与cpu的通信速度靠的是外部频率（所谓外频指的是cpu与外部组件进行数据传输/运算是的速度，倍频则是cpu内部用来加速工作性能的一个倍数，两者相乘才是cpu的频率），每次工作可以传输的数据量大小是由总线决定的。一般主板芯片组分为北桥与南桥，北桥的总线称为系统总线，因为是内存传输的主要信道，所以速度较快；南桥就是所谓的输入输出（I/O）总线，主要用于联系硬盘、usb、网卡等接口设备。 北桥所支持的频率我们称之为前端总线速度（Front Side Bus,FSB），而每次传输的位数则是总线宽度。所以总线频宽 = FSB x 总线宽度，也就是每秒钟可传送的最大数据量，目前常见的总线宽度有32为和64位。 例如前端总线的最高速度可达1600MHZ。我们看到内存和北桥的频宽为12.8GB/S，也就是1600MHZ x 64Bit =1600MHZ x 8Bytes = 12800MHZ = 12.8GB/S。 与总线宽度相似，cpu每次能处理的数据量称为字组大小，字组大小依据cpu的设计而有32位与64位。我们现在所称的计算机是32位或64位主要依据cpu解析的字组大小而来的！早期的32位cpu中，因为cpu每次能够解析的数据量有限，因此由内存传来的数据量就有所限制了。这也导致32位的cpu最多只能支持最大到4GB的内存。 ​ 推荐书单 -《Java并发编程实战》作者阵容可谓大师云集，也包括Doug Lea -《Java并发编程的艺术》讲解并发包内部实现原理，能读明白，内功大增 -《图解Java多线程设计模式》并发编程设计模式方面的经典书籍 -《操作系统：精髓与设计原理》经典操作系统教材 http://ifeve.com 国内专业并发编程网站 http://www.cs.umd.edu/~pugh/java/memoryModel/ 很多并发编程的早期资料都在这里 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"java并发编程实战-王宝令","slug":"java并发编程实战-王宝令","permalink":"https://lywlefan.github.io/tags/java并发编程实战-王宝令/"}]},{"title":"11.无消息丢失配置怎么实现？","date":"2019-06-30T16:00:00.000Z","path":"2019/07/01/后端/中间件/消息中间件/kafka/读书笔记/kafka核心技术与实战-胡夕/11.无消息丢失配置怎么实现？/","text":"阅读笔记 kafka中什么算消息丢失 什么情况下能保证kafka消息不丢失 一句话概括,Kafka只对”已提交”的消息做有限度的持久化保证。 什么是已提交的消息?当kafka的若干个Broker成功的接收到一条消息并写入到日志文件之后,它们就会告诉生产者程序这条消息已成功提交。此时,这条消息在kafka看来就正式变为”已提交”消息了。 为什么是若干个Broker?这取决于”已提交”的定义,你可以选择只有一个broker成功保存该消息就算已提交,也可以令所有broker都保存才算已提交. 有限度的持久化保证至少有一个Broker存活,只要这个条件成立,kafka就不会丢消息,但是一个都不会存活的情况是有可能出现的. 消息丢失的案例复盘”kafka消息丢失”案例。 生产者程序丢失数据kafka producer是异步发送消息的,所以说当我们调用完producer.send(msg)这个api后,他通过会立即返回,但是并不代表我们消息发送成功. 以上发送消息的方式是不靠谱的,建议不要这样去搞,因为这种方式以下原因可能造成消息发送失败: 网络抖动 消息本身不合格,Broker不接受 解决以上问题其实有比较好的办法,就是我们Producer永远使用带有回调通知的发送API,也就是说不要使用producer.send(msg),而要使用producer.send(msg,callback),callback会告诉你消息是否处理成功,然后你再根据具体情况进行相应的处理。 如果因为某些瞬间错误,可以让producer继续重试,总之发送消息失败的责任是producer而不是在broker,当然broker宕机断网除外。 消费者程序丢失数据在kafka消费消息的时候有个”位移”的概念,我们可以把消费消息当做我们读书,而”位移”就相当于”书签”。 什么情况下消费者程序会存在丢数据的情况哪??? 我们把上面的类比分成两个部分:1.读书 2.移动书签位置 加入我们先移动书签,再读书就有可能造成消费者丢数据的情况,比如:我们计划读书到100页,然后我们把书签放到100页,当我们读到96页的时候突然有急事出去了,下次继续读的时候就从100页开始了,中间的页我们就没读到。 针对以上情况,我们应该是先读书然后移动书签的位置。 但是先读书再移动书签会不会造成消息重复消费的情况。 还一种多线程消费的情况,以前我们是一个人读书,现在把一本书10章分给10个人一起读,然后大家读完宣布这本书读完。 以上这种情况有可能这种异常情况,有部分线程没有读完就更新了位移,这就导致部分消息没有消费,但是响应的确实已经消费了的情况。 解决以上问题的办法就是:多线程处理消费消息,Consumer程序不要开启自动提交位移,而是要应用程序手动提交位移。 最佳实践 使用掉回调的生产消息的方法 设置 acks = all。acks 是 Producer的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。 设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。 设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。 设置 replication.factor &gt;= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。 设置 min.insync.replicas &gt; 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。 确保 replication.factor&gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。 确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false ，并采用手动提交位移的方式。 就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。 开发讨论特别隐秘丢消息的场景: 当增加主题分区后，在某段“不凑巧”的时间间隔后，Producer 先于 Consumer 感知到新增加的分区，而 Consumer 设置的是“从最新位移处”开始读取消息，因此在 Consumer 感知到新分区前，Producer 发送的这些消息就全部“丢失”了，或者说 Consumer 无法读取到这些消息。Kafka 设计上的一个小缺陷，你有什么解决的办法吗？ cricket1981：consumer改用”从最早位置”读解决新加分区造成的问题 明翼：这个问题我想个办法就是程序停止再增加分区，如果不能停止那就找个通知机制了。请教一个问题min.insync.replicas这个参数如果设置成3，假设副本数设置为4，那岂不是只支持一台broker坏掉的情况？ 作者：能想到的一个简单方法是让consumer端缓存订阅信息，如果发现新的订阅分区出现，手动调整位移到最开始处执行（比如consumer.seekToBeginning） 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"kafka核心技术与实战-胡夕","slug":"kafka核心技术与实战-胡夕","permalink":"https://lywlefan.github.io/tags/kafka核心技术与实战-胡夕/"}]},{"title":"","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/后端/中间件/消息中间件/kafka/读书笔记/kafka核心技术与实战-胡夕/09.生产者消息分区机制原理剖析/","text":"阅读笔记生产者消息分区机制原理剖析 如何将大的数据均匀的分配到Kafka的各个Broker上？ 为什么分区？ 为什么分区？ 三级结构：主题-分区-消息 主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份 疑问:为什么kafka要这样设计？有什么好处？ 回答:我们设想一个问题，我们在学校找一个学生，如果我们直接把学生集中在一起去找是不是很麻烦，很低效。换种方式，每50个学生一组，配置一个负责人，然后通知这些负责人去找某个同学，是不是很快就可以找到了，这也就是分区的意义所在。如果，我们把这种思想放到我们的系统中，就可以提高我们系统的负载均衡能力，实现了系统的高伸缩性(Scalability) 不同的分区能够被放置到不同节点的机器上 疑问：同一个topic下不同的分区是保存到相同机器的不同磁盘上的吗？ 回答: 在 MongoDB 和 Elasticsearch 中就叫分Shard，而在HBase中则叫Region,在Cassandra中又被称作vnode。 实现业务级别的消息顺序的问题 都有哪些分区策略？所谓分区策略是决定生产者将消息发送到那个分区的算法。提供了默认的分区策略，同时支持自定义分区策略。 自定义分区 配置partitioner.class参数 实现Partitioner接口 1int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster); 这里的topic、key、keyBytes、value和valueBytes都属于消息数据，cluster则是集群信息(比如当前Kafka集群有多少主题，多少Broker等)。 策略 轮询策略(Round-robin) 轮询是kafka默认的消息存储策略，新增的消息会依次进入1/2/3/4/….对应的分区。轮询策略有非常优秀的负载均衡表现，它总能保证消息最大限度地平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们常用的分区策略之一。 随机策略(Randomness) 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return ThreadLocalRandom.current().nextInt(partitions.size()); 实现比较简单，先计算出该主题总的分区数，然后随机地返回一个小于它的正整数。 该策略是kafka老版本的策略，追求数据均匀分布还是轮询策略比较好。 按消息键保序策略 同一个消息key的消息进入同一个分区 一个分区只能被同一个消费组（ConsumerGroup）内的一个消费者消费 这里我们可以给我们的消息以时间的维度定义key，如此同一时间的消息就进入了同一个分区，同一个分区下的消息也有了顺序性。 每个分区消息都是有顺序的 代码实现 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return Math.abs(key.hashCode()) % partitions.size(); 其他分区策略(比如：基于地理位置的分区策略) 场景 公司有两个机房，一个在广州，一个在北京，在每个机房里面抽取部分机器组成kafka集群。现在公司app搞活动，北京新注册的用户送北京烤鸭一只，广州注册的用户送一次大保健，我们如何用kafka实现这一需求？ 解决方案一 解决方案二 提出问题自己提问问题1 通过kafka创建一个topic，默认分几个区？ 回答：创建topic的时候就需要指定需要创建的分区个数. 问题2 基于地理位置的分区策略可以通过按消息键保序策略实现，这样做有什么意义？ 其他人的问题问题1 老师能不能有空能不能讲讲kafka和rocketMQ的对比, 我用下来感觉整体挺像的但是具体使用场景和性能优劣方面还是有点不知道该使用选择, 谢谢. 回答：在我看来RocketMQ与Kafka的主要区别 ：1. Kafka吞吐量大，多是面向大数据场景。RocketMQ吞吐量也很强， 不过它号称是金融业务级的消息中间件，也就是说可以用于实际的业务系统；2. RocketMQ毕竟是阿里出品，在国内技术支持力度要比Kafka强；3. Kafka现在主要发力Streaming，RocketMQ在流处理这块表现如何我不太清楚，至少streaming不是它现阶段的主要卖点。 问题2 kafka的主题只有一级、像mq可以进行主题分层：一级主题、二级主题。kafka为何这样设计？ 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"kafka核心技术与实战-胡夕","slug":"kafka核心技术与实战-胡夕","permalink":"https://lywlefan.github.io/tags/kafka核心技术与实战-胡夕/"}]},{"title":"10.生产者压缩算法面面观","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/后端/中间件/消息中间件/kafka/读书笔记/kafka核心技术与实战-胡夕/10.生产者压缩算法面面观/","text":"阅读笔记 消息压缩 GZIP Snappy Zero Copy(零拷贝技术) 何时压缩 笔记压缩算法笔记 GZIP Snappy LZ4 Zstandard(zstd):2.1.0开始，facebook开源的压缩算法，能够提高超高性能压缩比。 如何压缩 v1（kafka 0.11.0之前）:message set, message ,v2（kafka 0.11.0以后）:record batch,record 我看了三遍老师的课，得到了我要的答案：1.如果生产者使用了压缩，broker为了crc校验，会启动解压，这个解压过程不可避免；2.v2的broker为了低版本的消费者，会把消息再次解压并进行协议转换。 CRC校验（每条消息执行CRC校验） 消息集合 消息 日志项 看一个压缩算法的指标 压缩比 原来占100份空间的东西压缩成20，那么压缩比就是5，显然压缩比越高越好。 吞吐量(压缩/解压缩) 每秒能压缩或者解压多少MB数据,同样吞吐量也是越高越好。 facebook各个压缩算法性能测试 1.png 如何选择压缩算法 启用压缩的一个条件就是Producer程序运行机器上的CPU要充足。 带宽资源有限建议开启压缩(带宽比cpu和内存还要珍贵) cpu资源富于，建议开启zstd压缩，这样能极大节省网络资源消耗。 规避意料之外的解压缩，比如：兼容老版本而引入解压缩 有条件尽量保证不要出现消息格式转换的情况 浓缩精华 Producer端压缩/Broker端保持/Consumer端解压 注意问题producer和broker端的压缩算法尽量保持一致建议京东小哥建议 去掉因为做消息校验而引入解压缩,据他们称，去掉解压缩后，Broker端CPU使用率至少降低了50%。 社区未采纳建议，原因是消息校验特别重要，不能盲目去掉。 应用实践实时日志收集系统 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://lywlefan.github.io/tags/读书笔记/"},{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"kafka核心技术与实战-胡夕","slug":"kafka核心技术与实战-胡夕","permalink":"https://lywlefan.github.io/tags/kafka核心技术与实战-胡夕/"}]},{"title":"09.生产者消息分区机制原理剖析","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/后端/中间件/消息中间件/kafka/实践问题/kafka如何处理消息重复的问题/","text":"背景kafka没有重试机制不支持消息重试，也没有死信队列，因此使用kafka做消息队列时，如果遇到了消息在业务处理时出现异常，就会很难进行下一步处理。应对这种场景，需要自己实现消息重试的功能。 如果不想自己实现消息重试机制，建议使用RocketMQ作为消息队列，RocketMQ的消息重试机制相当完善，对于开发者使用也非常友好，详见https://help.aliyun.com/document_detail/43490.html。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"kafka","slug":"kafka","permalink":"https://lywlefan.github.io/tags/kafka/"},{"name":"实践问题","slug":"实践问题","permalink":"https://lywlefan.github.io/tags/实践问题/"}]},{"title":"redis的FAQ","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/后端/数据存储/NOSQL/redis/FAQ/","text":"问题整理 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"redis的VERSION","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/后端/数据存储/NOSQL/redis/VERSION/","text":"问题整理 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"数据存储","slug":"数据存储","permalink":"https://lywlefan.github.io/tags/数据存储/"},{"name":"NOSQL","slug":"NOSQL","permalink":"https://lywlefan.github.io/tags/NOSQL/"}]},{"title":"es的VERSION","date":"2019-06-27T16:00:00.000Z","path":"2019/06/28/后端/搜索引擎/es/VERSION(ES)/","text":"问题整理 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】redis官网 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"redis","slug":"redis","permalink":"https://lywlefan.github.io/tags/redis/"},{"name":"学习笔记","slug":"学习笔记","permalink":"https://lywlefan.github.io/tags/学习笔记/"}]},{"title":"关于支付宝用户信息获取的总结","date":"2019-06-26T16:00:00.000Z","path":"2019/06/27/后端/第三方对接/支付宝/关于支付宝用户信息获取的总结/","text":"需求需求分析随着互联网的快速发展,巨头互联网公司占据了互联网的半壁江山,几乎大一点的互联网巨头公司都要搞个小程序或者生活号,方便其他公司的接入自己的生态。 随着互联网的快速发展,巨头互联网公司占据了互联网的半壁江山,几乎大一点的互联网巨头公司都要搞个小程序或者生活号,方便其他公司的接入自己的生态。 我最近这段时间就在对接支付宝的相关生态,给我最大的感触就是支付宝的对接确实要比微信麻烦,文档太难找了,一会跳着,一会跳哪,搞的我是好不难受。 接下来我会接受如何对接支付宝的生活号获取用户的信息。 后端存储支付宝用户信息(用户授权后在回调的时候存储) 前端在本地存储一个用户唯一标识,通过唯一标识进行后续业务 流程梳理获取用户信息后端交互 image 在生活号菜单上配置跳转地址为:https://openauth.alipay.com/oauth2/publicAppAuthorize.htm?app_id=APPID&amp;scope=SCOPE&amp;redirect_uri=ENCODED_URL ,其中redirect_uri为后台的回调地址,我们可以在该回调地址上传自定义的参数,要注意的是需要对redirect_url进行转码,转码后进行拼接。 当用户点击后,会去请求支付宝的认证服务,支付宝返回一个授权页面,用户确认后,该页面带着auth_code去回调后台地址。 后台接受到请求后,通过auth_code调用支付宝相关API获取token,然后再通过token获取用户信息。代码如下: controller123456789101112131415161718@RequestMapping(value = \"aliAuth\", method = RequestMethod.GET)@ResponseBodypublic void aliAuth( @RequestParam(value = \"auth_code\",required = false) String authCode, @RequestParam(value =\"app_id\",required = false) String appId, @RequestParam(value =\"scope\",required = false) String scope, @RequestParam(value =\"authUrl\",required = false) String authUrl, HttpServletResponse response) throws AlipayApiException, IOException &#123; //1.通过auth_code换token String accessToken = authLifeService.getToken(authCode); //2.获取用户基本信息 AlipayUserInfoShareResponse userInfo = authLifeService.getUserInfo(accessToken); //3.获取用户信息成功,跳转到第三方首页 log.info(JSON.toJSONString(userInfo)); //TODO:这里可以保存用户信息,生成自己平台的用户唯一标识,可以把参数拼接到页面跳转到指定的页面 response.sendRedirect(\"http://www.baidu.com\");&#125; service123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class AuthLifeService &#123; AlipayClient alipayClient; /** * 获取token * @param authCode code * @return 返回token */ public String getToken(String authCode) throws AlipayApiException &#123; String accessToken = null; try &#123; AlipaySystemOauthTokenRequest request = new AlipaySystemOauthTokenRequest(); request.setGrantType(\"authorization_code\"); request.setCode(authCode); request.setRefreshToken(\"201208134b203fe6c11548bcabd8da5bb087a83b\"); AlipaySystemOauthTokenResponse response = alipayClient.execute(request); accessToken = response.getAccessToken(); String userId = response.getUserId(); &#125; catch (AlipayApiException e) &#123; e.printStackTrace(); &#125; return accessToken; &#125; /** * 获取用户信息 * @param accessToken 用户token * @return 用户信息 */ public AlipayUserInfoShareResponse getUserInfo(String accessToken)&#123; UserInfo userInfo = null; AlipayUserInfoShareResponse userInfoShareResponse = null; try &#123; AlipayUserInfoShareRequest requestUser = new AlipayUserInfoShareRequest(); userInfoShareResponse = alipayClient.execute(requestUser, accessToken); if(userInfoShareResponse.isSuccess())&#123; userInfo = JSON.parseObject(JSON.toJSONString(userInfoShareResponse), UserInfo.class); &#125; else &#123; System.out.println(\"调用失败\"); &#125; &#125; catch (AlipayApiException e) &#123; e.printStackTrace(); &#125; return userInfoShareResponse; &#125; 配置文件12345678910111213141516171819202122@Configuration@ConfigurationProperties(prefix = \"ali\")@PropertySource(\"classpath:config/ali.properties\")@Data@Componentpublic class AliProperties &#123; private String publicKey; //支付宝公钥 private String appId; //appId private String format; //数据格式 private String charset; //字符编码 private String signType; //签名方式 private String privateKey; //商户私钥 private String url; //url&#125; 经过如上操作,我们顺利的获取到了用户的基本信息,但是这样每次都的依赖支付宝,每次都得回调。 如何让获取用户信息不依赖支付宝?如何让下面的业务根据后台的用户标识走? 前后端交互(缓存用户唯一标识到本地) 这个验证页面其实相当于一个路由页面,作用如下: 缓存用户唯一标识:openCode 路由转发,可以配置多个不同菜单 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"第三方对接","slug":"第三方对接","permalink":"https://lywlefan.github.io/tags/第三方对接/"},{"name":"支付宝","slug":"支付宝","permalink":"https://lywlefan.github.io/tags/支付宝/"}]},{"title":"Java并发编程：CountDownLatch、CyclicBarrier和Semaphore","date":"2019-06-26T16:00:00.000Z","path":"2019/06/27/后端/高并发/java/并发基础/Java并发编程：CountDownLatch、CyclicBarrier和Semaphore/","text":"面向对象的语言最好的学习方法就是在实际生活中找一个列子类比。 CountDownLatch(计数器) CyclicBarrier(回环栅栏) Semaphore(信号量) CountDownLatchCountDownLatch类位于java.util.concurrent包下，利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。 基础构造方法123456//count代表计数的个数public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count);&#125; 方法123456//调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行public void await() throws InterruptedException &#123; &#125;; //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //将count值减1public void countDown() &#123; &#125;; 类比理解大家在考科目一的时候是如何考的？我们知道车管所的考试机器比考试人数要少很多，假如机器有50个，每次考官让50个人进去，然后再宣布考试开始，其他人继续等待。 CountDownLatch就可以实现这个效果，我们可以这样做： CountDownLatch latch=new CountDownLatch(50) 进入考场一个学员，我们就latch.countDown()减一 到latch为0的时候，考官宣布考试开始，如此而已 12345678910111213141516171819202122232425262728293031323334353637383940public class Test &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); new Thread()&#123; public void run() &#123; try &#123; System.out.println(\"子线程\"+Thread.currentThread().getName()+\"正在执行\"); Thread.sleep(3000); System.out.println(\"子线程\"+Thread.currentThread().getName()+\"执行完毕\"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; try &#123; System.out.println(\"子线程\"+Thread.currentThread().getName()+\"正在执行\"); Thread.sleep(3000); System.out.println(\"子线程\"+Thread.currentThread().getName()+\"执行完毕\"); latch.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); try &#123; System.out.println(\"等待2个子线程执行完毕...\"); latch.await(); System.out.println(\"2个子线程已经执行完毕\"); System.out.println(\"继续执行主线程\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果： 1234567线程Thread-0正在执行线程Thread-1正在执行等待2个子线程执行完毕...线程Thread-0执行完毕线程Thread-1执行完毕2个子线程已经执行完毕继续执行主线程 CyclicBarrier基础字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。我们暂且把这个状态就叫做barrier，当调用await()方法之后，线程就处于barrier了。 CyclicBarrier类位于java.util.concurrent包下，CyclicBarrier提供2个构造器： 构造方法12345public CyclicBarrier(int parties, Runnable barrierAction) &#123;&#125; public CyclicBarrier(int parties) &#123;&#125; 参数parties指让多少个线程或者任务等待至barrier状态；参数barrierAction为当这些线程都达到barrier状态时会执行的内容。 方法然后CyclicBarrier中最重要的方法就是await方法，它有2个重载版本： 12public int await() throws InterruptedException, BrokenBarrierException &#123; &#125;;public int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException &#123; &#125;; 第一个版本比较常用，用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任务； 第二个版本是让这些线程等待至一定的时间，如果还有线程没有到达barrier状态就直接让到达barrier的线程执行后续任务。 类比理解例1假若有若干个线程都要进行写数据操作，并且只有所有线程都完成写数据操作之后，这些线程才能继续做后面的事情，此时就可以利用CyclicBarrier了： 1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) new Writer(barrier).start(); &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果： 123456789101112线程Thread-0正在写入数据...线程Thread-3正在写入数据...线程Thread-2正在写入数据...线程Thread-1正在写入数据...线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务... 从上面输出结果可以看出，每个写入线程执行完写数据操作之后，就在等待其他线程写入操作完毕。 当所有线程线程写入操作完毕之后，所有线程就继续进行后续的操作了。 例2如果说想在所有线程写入操作完之后，进行额外的其他操作可以为CyclicBarrier提供Runnable参数： 1234567891011121314151617181920212223242526272829303132333435public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N,new Runnable() &#123; @Override public void run() &#123; System.out.println(\"当前线程\"+Thread.currentThread().getName()); &#125; &#125;); for(int i=0;i&lt;N;i++) new Writer(barrier).start(); &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 运行结果: 1234567891011121314线程Thread-0正在写入数据...线程Thread-1正在写入数据...线程Thread-2正在写入数据...线程Thread-3正在写入数据...线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕当前线程Thread-3所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务... 从结果可以看出，当四个线程都到达barrier状态后，会从四个线程中选择一个线程去执行Runnable。 例3下面看一下为await指定时间的效果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) &#123; if(i&lt;N-1) new Writer(barrier).start(); else &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Writer(barrier).start(); &#125; &#125; &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); try &#123; cyclicBarrier.await(2000, TimeUnit.MILLISECONDS); &#125; catch (TimeoutException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果： 12345678910111213141516171819202122232425262728线程Thread-0正在写入数据...线程Thread-2正在写入数据...线程Thread-1正在写入数据...线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-3正在写入数据...java.util.concurrent.TimeoutExceptionThread-1所有线程写入完毕，继续处理其他任务...Thread-0所有线程写入完毕，继续处理其他任务... at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58)java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58)java.util.concurrent.BrokenBarrierException at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58)Thread-2所有线程写入完毕，继续处理其他任务...java.util.concurrent.BrokenBarrierException线程Thread-3写入数据完毕，等待其他线程写入完毕 at java.util.concurrent.CyclicBarrier.dowait(Unknown Source) at java.util.concurrent.CyclicBarrier.await(Unknown Source) at com.cxh.test1.Test$Writer.run(Test.java:58)Thread-3所有线程写入完毕，继续处理其他任务... 上面的代码在main方法的for循环中，故意让最后一个线程启动延迟，因为在前面三个线程都达到barrier之后，等待了指定的时间发现第四个线程还没有达到barrier，就抛出异常并继续执行后面的任务。 例5另外CyclicBarrier是可以重用的，看下面这个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Test &#123; public static void main(String[] args) &#123; int N = 4; CyclicBarrier barrier = new CyclicBarrier(N); for(int i=0;i&lt;N;i++) &#123; new Writer(barrier).start(); &#125; try &#123; Thread.sleep(25000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"CyclicBarrier重用\"); for(int i=0;i&lt;N;i++) &#123; new Writer(barrier).start(); &#125; &#125; static class Writer extends Thread&#123; private CyclicBarrier cyclicBarrier; public Writer(CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName()+\"正在写入数据...\"); try &#123; Thread.sleep(5000); //以睡眠来模拟写入数据操作 System.out.println(\"线程\"+Thread.currentThread().getName()+\"写入数据完毕，等待其他线程写入完毕\"); cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;catch(BrokenBarrierException e)&#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+\"所有线程写入完毕，继续处理其他任务...\"); &#125; &#125;&#125; 执行结果： 12345678910111213141516171819202122232425线程Thread-0正在写入数据...线程Thread-1正在写入数据...线程Thread-3正在写入数据...线程Thread-2正在写入数据...线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕Thread-0所有线程写入完毕，继续处理其他任务...Thread-3所有线程写入完毕，继续处理其他任务...Thread-1所有线程写入完毕，继续处理其他任务...Thread-2所有线程写入完毕，继续处理其他任务...CyclicBarrier重用线程Thread-4正在写入数据...线程Thread-5正在写入数据...线程Thread-6正在写入数据...线程Thread-7正在写入数据...线程Thread-7写入数据完毕，等待其他线程写入完毕线程Thread-5写入数据完毕，等待其他线程写入完毕线程Thread-6写入数据完毕，等待其他线程写入完毕线程Thread-4写入数据完毕，等待其他线程写入完毕Thread-4所有线程写入完毕，继续处理其他任务...Thread-5所有线程写入完毕，继续处理其他任务...Thread-6所有线程写入完毕，继续处理其他任务...Thread-7所有线程写入完毕，继续处理其他任务... 从执行结果可以看出，在初次的4个线程越过barrier状态后，又可以用来进行新一轮的使用。而CountDownLatch无法进行重复使用。 SemaphoreSemaphore翻译成字面意思为 信号量，Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。 基础Semaphore类位于java.util.concurrent包下，它提供了2个构造器： 构造方法123456public Semaphore(int permits) &#123; //参数permits表示许可数目，即同时可以允许多少线程进行访问 sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; //这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可 sync = (fair)? new FairSync(permits) : new NonfairSync(permits);&#125; 方法下面说一下Semaphore类中比较重要的几个方法，首先是acquire()、release()方法： 1234public void acquire() throws InterruptedException &#123; &#125; //获取一个许可public void acquire(int permits) throws InterruptedException &#123; &#125; //获取permits个许可public void release() &#123; &#125; //释放一个许可public void release(int permits) &#123; &#125; //释放permits个许可 acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。 release()用来释放许可。注意，在释放许可之前，必须先获获得许可。 这4个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法： 1234public boolean tryAcquire() &#123; &#125;; //尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回falsepublic boolean tryAcquire(int permits) &#123; &#125;; //尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false 另外还可以通过availablePermits()方法得到可用的许可数目。 类比理解下面通过一个例子来看一下Semaphore的具体使用： 假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现： 123456789101112131415161718192021222324252627282930public class Test &#123; public static void main(String[] args) &#123; int N = 8; //工人数 Semaphore semaphore = new Semaphore(5); //机器数目 for(int i=0;i&lt;N;i++) new Worker(i,semaphore).start(); &#125; static class Worker extends Thread&#123; private int num; private Semaphore semaphore; public Worker(int num,Semaphore semaphore)&#123; this.num = num; this.semaphore = semaphore; &#125; @Override public void run() &#123; try &#123; semaphore.acquire(); System.out.println(\"工人\"+this.num+\"占用一个机器在生产...\"); Thread.sleep(2000); System.out.println(\"工人\"+this.num+\"释放出机器\"); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 执行结果： 12345678910111213141516工人0占用一个机器在生产...工人1占用一个机器在生产...工人2占用一个机器在生产...工人4占用一个机器在生产...工人5占用一个机器在生产...工人0释放出机器工人2释放出机器工人3占用一个机器在生产...工人7占用一个机器在生产...工人4释放出机器工人5释放出机器工人1释放出机器工人6占用一个机器在生产...工人3释放出机器工人7释放出机器工人6释放出机器 FAQ总结下面对上面说的三个辅助类进行一个总结： 1）CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行； 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行； 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。 2）Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】disruptor官网 【4】JAVA CAS原理深度分析 【5】并发框架Disruptor译文 【6】从构建分布式秒杀系统聊聊Disruptor高性能队列 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"并发基础","slug":"并发基础","permalink":"https://lywlefan.github.io/tags/并发基础/"}]},{"title":"2.disruptor应用","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/后端/高并发/java/并发框架/disruptor/2.disruptor应用/","text":"disruptor号称能够在一个线程里每秒处理6百万订单,业务逻辑处理器完全是运行在内存中，使用事件源驱动方式。 本节导航 Disruptor核心链路场景应用讲解 并行计算- 串行操作 并行计算- 并行操作 并行计算- 多遍形高端操作 并行计算- 多生产者消费模型 并行计算- 多消费者消费模型 Disruptor核心链路场景应用讲解概念啥是核心链路?就拿京东来说,下单支付就是核心链路,物流也是核心链路. 核心链路特点 代码复杂 业务逻辑复杂 如何实现 传统完全解耦的方式 模板模式 使用框架 有限状态机框架：Spring-StateMachine 使用Disruptor 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】disruptor官网 【4】JAVA CAS原理深度分析 【5】并发框架Disruptor译文 【6】从构建分布式秒杀系统聊聊Disruptor高性能队列 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"disruptor","slug":"disruptor","permalink":"https://lywlefan.github.io/tags/disruptor/"}]},{"title":"自定义线程池","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/后端/基础巩固/java/线程/自定义线程池/","text":"万丈高楼平地起的前提是地基好. 为什么要定义线程池??如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？在Java中可以通过线程池来达到这样的效果。首先我们从最核心的ThreadPoolExecutor类中的方法讲起。 进一步学习实现原理java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法： 1234567891011121314151617181920212223242526272829public class ThreadPoolExecutor extends AbstractExecutorService &#123; ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125; 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 下面解释下一下构造器中各个参数的含义： corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： ArrayBlockingQueue; LinkedBlockingQueue; SynchronousQueue; threadFactory：线程工厂，主要用来创建线程； handler：表示当拒绝处理任务时的策略，默认有以下四种取值： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 线程池执行的流程当任务提交给ThreadPoolExecutor 线程池中，先检查核心线程数是否已经全部使用，如果没有交由核心线程去执行任务，如果核心线程数已经全部占用，则将任务添加到队列里面，如果队列已经占满，比较当前线程池的中线程的数量是不是与超过maximumPoolSize，如果没有查过则创建线程去执行，也就是说线程池最多可以接受多少任务呢？就是maximumPoolSize+队列的大小。当线程池中的线程的数量大于corePoolSize数量有空闲线程则执行回收，回收时间是keepAliveTime，单位是unit，都是初始化的时候设置的。 下面通过代码来说明： 定义一个实现了Runnable接口的类，当作任务类； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class MyTask implements Runnable &#123; private int taskId; private String taskName; public int getTaskId() &#123; return taskId; &#125; public void setTaskId(int taskId) &#123; this.taskId = taskId; &#125; public String getTaskName() &#123; return taskName; &#125; public void setTaskName(String taskName) &#123; this.taskName = taskName; &#125; public MyTask(int taskId, String taskName) &#123; this.taskId = taskId; this.taskName = taskName; &#125; @Override public void run() &#123; System.out.println(\"taskId:\" + taskId + \",taskName:\" + taskName); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"架构导航","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/架构/架构导航/","text":"万丈高楼平地起的前提是地基好. 技术选型网关 Nginx Kong Zuul GateWay 缓存 Redis MemCached OsCache EhCache 搜索 ElasticSearch Solr 熔断 Hystrix resilience4j 负载均衡 DNS F5 LVS Nginx OpenResty HAproxy 注册中心 Eureka Zookeeper Redis Etcd Consul 认证鉴权 JWT 消费队列 RabbitMQ ZeroMQ Redis ActiveMQ Kafka 系统监控 Grafana Prometheus Influxdb Telegraf Lepus Istio 文件系统 OSS NFS FastDFS MogileFS RPC框架 Dubbo Motan Thrift grpc 构建工具 Maven Gradle 集成部署 Docker Jenkins Git Maven 分布式配置 Disconf Apollo Spring Cloud Config Diamond Diamond是淘宝研发的分布式配置管理系统。使用Diamond可以让集群中的服务进程动态感知数据的变化，无需重启服务就可以实现配置数据的更新。 具有简单、可靠、易用等特点 压测 LoadRunner JMeter AB webbench ab.exe 数据库 MySql Redis MongoDB PostgreSQL Memcache HBase MPP数据库(Greenplum、TiDB、Postgresql XC、HAWQ等) 网络 专用网络VPC 弹性公网IP CDN CDN就可以理解为分布在每个县城的火车票代售点，用户在浏览网站的时候，CDN会选择一个离用户最近的CDN边缘节点来响应用户的请求，这样海南移动用户的请求就不会千里迢迢跑到北京电信机房的服务器（假设源站部署在北京电信机房）上了。 数据库中间件 DRDS Mycat 360 Atlas Cobar (不维护了) 分布式框架 Dubbo Motan Spring-Could 分布式任务 XXL JOB Elastic-Job Saturn Quartz 分布式追踪 Pinpoint CAT zipkin 分布式日志 elasticsearch logstash Kibana redis kafka 版本发布 蓝绿部署 A/B测试 灰度发布／金丝雀发布 持续交付 链路监控 监控架构四层监控 前端监控：IP、PV、运营商、系统、性能、状态码 业务监控：登录、注册、下单、支付 应用层监控：service、sql、cache、相应时间 系统监控：物理机、虚拟机、容器，CPU、内存、IO、硬盘 基础监控：网络、交换机、路由器 监控分类 日志监控 调用链监控 告警系统 Metrics监控 监控检查 Docker、Grafana、Prometheus、Telegraf、Influxdb、Lepus、Elasticsearch、Logstash、Kibana、kafka、node插件、dashboards仪表盘、钉钉、邮件、微信。 服务框架和治理 架构必备 负载均衡（负载均衡算法） 反向代理 服务隔离 服务限流 sentinel 1.限流文章 服务降级（自动优雅降级） 失效转移 超时重试（代理超时、容器超时、前端超时、中间件超时、数据库超时、NoSql超时） 回滚机制（上线回滚、数据库版本回滚、事务回滚） 高并发 应用缓存 HTTP缓存 多级缓存 分布式缓存 连接池 异步并发 分布式事务 二阶段提交(强一致) 三阶段提交(强一致) 消息中间件(最终一致性)，推荐阿里的RocketMQ 队列 任务队列 消息队列 请求队列 扩容 单体垂直扩容 单体水平扩容 应用拆分 数据库拆分 数据库分库分表 sharding-jdbc(当当/京东) mycat(民间组织) TDDL(CLIENT模式)，DRDS和cobar(PROXY模式)(阿里) Atlas(360) zebra(美团) 数据异构 数据同步 canal(binlog日志同步) 分布式任务 网络安全 SQL注入 XSS攻击 CSRF攻击 拒绝服务（DoS，Denial of Service）攻击 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】LMAX架构简介·汤雪华 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"架构导航","slug":"架构导航","permalink":"https://lywlefan.github.io/tags/架构导航/"}]},{"title":"1.disruptor初识","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/后端/高并发/java/并发框架/disruptor/1.disruptor初识/","text":"disruptor号称能够在一个线程里每秒处理6百万订单,业务逻辑处理器完全是运行在内存中，使用事件源驱动方式。 要学的概念乐观锁打个比方理解乐观锁就是到桥头再看有没有车来过此桥,没有的话快速过桥. 悲观锁打个比方理解悲观锁说白了就是先发制人,我的车要过桥,但是我担心桥上有其他车,所以我提前把桥口加一个锁,我到桥头了在开锁过桥,过去了再把锁子接触了. 死锁打个比方理解简单的比方,两俩车同时过一个桥,不能倒车,如果两辆车同时在桥上就会造成死锁,车就相当于我们的线程,桥就相当于资源. CASCAS简介谷歌翻译CAS是比较并转换,java.util.concurrent包中借助CAS实现了区别于synchronouse同步锁的一种乐观锁。 CAS应用CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 非阻塞算法 （nonblocking algorithms） 一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。 CAS原理CAS通过调用JNI的代码实现的。JNI:Java Native Interface为JAVA本地调用，允许java调用其他语言而compareAndSwapInt就是借助C来调用CPU底层指令实现的。 CAS缺点 ABA问题 循环时间长开销大 只能保证一个共享变量的原子操作 缓存行初识性能 一个线程每秒处理6百万订单 内存中运行 ,使用事件源驱动方式 业务逻辑处理核心Disruptor hello world 建立一个event类,用于创建Event类实例对象 需要有一个监听事件类,用于处理数据(Event类) 实例化Disruptor实例,配置一系列参数,编写Disruptor核心组件 编写生产者组件,向Disruptor容器中去投递数据 核心讲解 RingBuffer基于数组的缓存实现,也是创建sequencer与定义WaitStrategy的入口 RingBuffer拥有一个序号,这个需要指向数组中下一个可用的元素 收尾相接的环 (环状数组) 假如缓存区芝麻满了,芝麻扔到哪里? 假如缓存区没芝麻了,如何取芝麻? 2的n次方更利于计算 Disruptor持有RingBuffer、消费者线程池Executor、消费者集合ConsumerRepository等引用. Sequence 通顺序递增的序号来编号,管理进行交换的数据(事件) 对数据(事件)的处理过程总是沿着序号逐个递增处理 一个Sequence用于跟踪标识某个特定的事件处理者(RingBuffer/Producer/Consumer)的处理进度 Sequence可以看成是一个AtomicLong用于标识进度 还有另外一个目的就是防止不同Sequence之间CPU缓存伪共享(Flase Sharing)的问题 Sequencer Sequencer是Disruptor的真正核心,包含Sequence 此接口有两个实现类 SingleProducerSequencer MultiProducerSequencer 主要实现生产者和消费者之间快速、正确的传递数据并发算法 Sequence Barrier 用于保持RingBuffer的Main Published Sequence(Producer)和Consumer之间平衡关系; 决定Consumer是否还有可处理事件逻辑 WaitStrategy 决定一个消费者将如何等待生产者将Event置入Disruptor 主要策略 BlockWaitStrategy 最低效策略 cpu消耗最小 在各种不同部署环境中提供更加一致性能表现 SleepingWaitStrategy 和上面性能差不多 cpu性能和上面差不多 对生产者线程影响最小,适合用于异步日志类似的场景 YieldingWaitStrategy 性能最好 适用低延迟系统 要求极高性能 要求极高性能且事件处理线数小于CPU逻辑核心数场景,列如:CPU开启超线程的特性 Event 从生产者到消费者过程中所处理的数据单元 Disruptor中没有代码表示Event,因为它完全是由用户定义的 EventProcessor 主要事件循环,处理Disruptor中的Event,拥有消费者Sequence 他是一个实现类是BatchEventProcessor,包含了event loop有效的实现,并且将回调一个EventHandler接口的实现对象. EventHandler 由用户并且代表了Disruptor中的一个消费者接口,也就是我们消费者逻辑都要写到这里. WorkProcessor 确保每个sequence只被一个processor消费,在同一个WorkPool中处理多个WorkProcessor不会消费同样的sequence 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】disruptor官网 【4】JAVA CAS原理深度分析 【5】并发框架Disruptor译文 【6】从构建分布式秒杀系统聊聊Disruptor高性能队列 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"高并发","slug":"高并发","permalink":"https://lywlefan.github.io/tags/高并发/"},{"name":"disruptor","slug":"disruptor","permalink":"https://lywlefan.github.io/tags/disruptor/"}]},{"title":"撮合系统设计","date":"2019-06-25T16:00:00.000Z","path":"2019/06/26/业务/交易所/撮合系统设计/","text":"摘要：撮合技术主要是从数据库撮合技术向内存撮合技术发展，这是因为数据库撮合技术越来越无法满足金融交易对于高可靠性、高性能、强安全性、可扩展性以及易维护性的需求。本文来自中生代技术群的34期分享，将和大家讨论基于内存的撮合的系统设计。李伟山，毕业于国防科技大学，曾就职于华为、阿里巴巴，目前人江苏大圆银泰技术总监，对于高并发、大数据架构设计有深刻的了解。1.概述 随着信息技术的日新月异和金融业务的快速发展,金融交易领域对于核心技术的求也在不断增强,国内外金融交易模式已经从传统的人工叫价的方式变成了由高度电子化交易系统撮合订单的方式。传统的金融交易主要发生在有型金融市场中,金融交易的买卖双方通过叫价进行价格协商等方式最终达成一致,从而形成一笔交易,同时按照交易订单到指定的交割地点进行实物交割的交易方式。由于交易的整个过程主要依靠人来执行,传统的金融交易缺点主要有:效率低速度慢、交易时间限制大、交易空间限制大、交易成本非常髙、容易有内幕交易、交易扩展性差、交易容易出错、资金安全性差等一系列的缺点。 时代不断变迁,金融交易通过与计算机技术的结合,走上了电子化交易的道路,通过将金融交易市场电子化,电子交易不仅消除了传统金融交易的种种弊端,也促进了现代金融业的快速发展。电子金融交易的主要优点有:交易效率高速度快、交易透明度高、交易成本低、系统安全性高、不受交易时间的限制、不受交易空间的限制、可以进行多方位的扩展、大力推动现代金融业发展等。 因此现在电子交易己经成为了金融交易市场的主流交易方式。随着交易人数、笔数的不断增加,系统承受着越来越大的压力,如果在交易时间内系统发生故障,造成的损失往往不可估量。因此发出更可靠更高效的电子交易系统己经成为了金融交易领域的当务之急。 撮合交易在金融交易系统中扮演者非常重要的角色。了解撮合交易的本质以及业务对于设计撮合系统至关重要。江苏大泰技术有限公司，致力于互联网金融平台的开发，目前已经在运行的平台有大宗交易、普洱茶交易系统，后期会发布连续现货和发售交易平台，接下来为大家介绍基于内存的撮合交易系统设计概要。 2.系统总体设计2.1 层次设计一般而言,金融交易撮合系统中包括以下几个核心模块: 用户:终端用户委托报价与数量,生成订单发送至交易平台。 网关:负责收集用户订单,并将其派发给撮合引擎。 撮合引擎:交易系统中的核心部分,用于接收订单并根据业务逻辑实现订单 撮合同时生成交易记录,随后给予用户交易结果反馈。 数据库:用来存放交易过程中的订单和交易记录,实现数据持久化。 此外,本文根据不同类型的金融交易展品将撮合模块划分为若干业务分区,每个分区独立进行撮合,彼此不受影响。对于单个业务分区而言,撮合系统整体架构设计如图1.2所示,本章的总体设计围绕撮合引擎层以及撮合引擎与网关层、数据库层的交互方式的总体设计。 2.2 撮合交易算法如图2.1所示,撮合引擎的核心业务模块就是撮合交易算法撮合交易算法的任务一方面是完成对客户所下订单进行公平合理的排列和撮合功能,也要保证撮合算法的公平性、高效性以及扩展性等。由于不同金融交易系统的撮合业务各有不同,因此本节对通用的撮合交易算法进行概括性描述。 2.2.1订单队列撮合交易的重要组成部分就是买卖订单,通过对买卖订单进行撮合最后形成交易记录。所以对无法立刻完成撮合的订单,需要有买入队列和卖出队列保存订单。队列按照“价格优先、同价格下时间优先”的原则。买入队列按照委托价格从低到高的顺序,卖出队列则按照委托价格从低到高的顺序排列,如图 2.2.2撮合顺序撮合引擎接收到新的买入订单,则会到卖出队列的头部查找是否存在符合价格规则的卖出订单,如果存在卖出价格小于或等于买入价格的订单,则从队列中取出此订单并撮合成一笔交易;如果卖出队列为空或队列头部不满足价格关系,则将买入订单插入买入队列中,由于买入队列是按照价格与时间先后进行排序,所以新插入的订单会经过一次排序插入到买入队列的相应位置。 相同的,当撮合引擎接收到新的卖出订单,则会到买入队列的头部査找是否存在符合价格规则的买入订单,如果存在买入价格大于或等于卖出价格的订单,则从订单队列中取出此订单并撮合成一笔交易;如果买入队列为空或队列头部不满足价格关系,则将卖出订单插入到卖出队列中,由于卖出队列也是按照价格与时间先后进行排序的所以新插入的订单会经过一次排序插入到卖出队列的相应位置[23]。 结合买卖订单情况,撮合算法流程如图2.3所示。从图2.3所示的撮合顺序可知,买卖队列的有序性是保证撮合顺序的确定性的基础,并且撮合过程中每笔订单都可以撮合出当前最优交易。 2.3 内存撮合当前的数据库撮合技术的性能低下的原因在于过多与数据库交互,使得I/O很多,系统整体处理速度同时受数据库事务逻辑约束。 本文釆用内存撮合技术,通过最大程度去除与数据库的交互过程,将整个错和逻辑放在内存中进行(如图2.4所示)。因此比数据库撮合技术少了许多I/O交S间,在性能上可以大幅提升撮合速度;例是内存撮合的弊端就是由于内存的易失性,.?服务器出现故障停机时,所有的交易数据将会丢失,系统的可靠性以及一致性都相应人幅降低。因此本文在提高内存撮合技术可靠性的方面采用丫多机热备份及分布式一致性技术作为补充,从而获得内存撮合技术的高性能以及数据库撮合技术的数据持久性。 2.4 多机热备份由于内存撮合技术在撮合引攀出现异常时的可靠性和一致性非常差,而金融交场系统因为其业务特性,对服务小断以及数据丢失的容忍度非常低,提高容错性,一般多采取的是多机热条份技术。本文采用多机热备份技术,将一组撮合引樂部署成互为备份的撮合引擎集群,并且在同一时间内只有一台撮合引擎提供服务。当-其中运行这的一台撮六引擎出现故障无法继续正常工作 ,撮合引擎集群会迅速检测到这个故障,并选举出一个备份撮合引擎接管故障撮合引舉的任务从而保证整个撮合系统的正常运行多机热备份技术的本质就足针对服务器临时故障所做的一种备份技术,本文迎过采用多机热备份技术,来避免长 间的撮合服务中断,保证撮合系统长期、可靠的服务。如阁2.5所示,通过将多台撮合引擎进行热格份,从而保证在撮合引擎出现故障时,会在可以接受的时间内完成主机和备机之间的切换,由备份机提供无缝连续服务。 通过釆用多机热备份技术,降低了单一内存撮合引擎故障时系统不可用的问题,但仍旧无法提供100%的可用性,因为当出现大规模服务器集群故障时,仍旧存在服务不可用的可能性,但在实际生产环境中,三台互为备份的服务器就可以提供较高的可以用于生产环境的可靠性。 2.5 内存状态机复制由于多机热备份技术引入了多台互为热备份的撮合引擎,根据撮合系统设计以及撮合逻辑要求,需要保证服务器之间的数据一致,这就需要保证多服务器之间一致性,这也是本文难点之一。 本文提出一种内存状态机复制方案,即将撮合算法视作一个确定性状态机,将其复制多份并部署到撮合系统中的多台撮合引擎中。每个撮合引擎副本从相同的初始状态开始运行,当撮合系统收到网关发来的订单时,系统中的每个撮合引擎都会撮合这个订单,并依次产生交易记录,同时更新确定性撮合算法状态机的独立状态。通过这样的方式,当撮合系统正常运转时,每个撮合引擎副本都会具有相同的结果状态;当撮合系统出现故障或异常时,撮合引擎就会出现状态的不一致情况,换句话说一旦撮合系统的结果或状态出现了不一致的情况就可以断定系统出现了异常。 2.5.1关键技术点本文为了实现这样的内存状态机复制撮合系统,将撮合系统划分为以下组成关键技术点： 将确定性撮合算法状态机服务部署到多个独立撮合引擎 接收网关订单,并作为确定性撮合算法状态机的输入 根据撮合算法需求,选择一种订单排序方式 每个撮合引擎对按照排序方式排序过的订单进行撮合 将确定性撮合算法状态机输出的交易记录作为给用户或数据库的响应 监控撮合引擎副本的状态或输出的差别 2.5.2实现方案为实现基于内存状态机复制的撮合系统,本文主要通过以下方案实现状态机复制的关键技术点: 采用原子多播解决撮合引擎订单的可靠多播与全局有序性 采用基于无锁订单队列的流水线撮合技术提供快速的订单撮合 采用异步一致性持久化技术实现与数据库的交互 采用失效备援技术对撮合引擎集群进行状态监控并保证系统的容错能; 采用进度追赶技术解决将故障撮合引擎的恢复或新撮合引擎的加入 2.6 系统架构2.6.1系统硬件体系架构典型的高可靠高性能撮合模型硬件架构如图2.6所示,系统由n台客户端、N台网关、X个产品集群(每个集群由2至3台撮合引擎组成,负责响应产品订单的处理)、一个交易记录数据库和可选的监视系统组成。其中客户端连接到相应网关,网关负责接收客户端提交的订单,并根据订单相关的金融产品类别,转发到相对应的产品集群。产品集群中所有撮合引擎均接收网关发送的订单,根据撮合业务规则,将其撮合并回馈消息给网关和客户端,同时将撮合生成的交易记录持久化到交易记录数据库中。 通过对产品集群进行扩充,增加撮合引擎数量,可以增强产品集群的可靠性。将不同金融产品转发到不同的撮合产品集群中可以实现多产品高效并行撮合。 2.6.2 系统软件体系架构 如图2.7所示,高可靠高性能撮合模型主要由表示层、转发层、业务层和数据层组成。其核心部分业务层主要由撮合引擎集群组成,每个撮合引擎采用原子多播将订单定序后进行撮合处理,并结合无锁订单队列实现高效流水线撮合,最后结果写入本地日志。整个业务流程由消息传递总线将消息反馈给转发层。转发层则根据产品转发规则将订单转发给相应撮合引擎集群;而撮合引擎将本地日志中的交易记录读取到异步持久化代理进程中,并进而与数据层的异步持久化写入进程通信,并最终持久化到数据库中。本地日志增强了撮合系统数据的可靠性,在出现故障后,数据仍就可以从本地日志中恢复;而界步的持久化机制则提高了数据的持久化吞吐率。 2.6.3撮合引擎架构 为了使系统可扩展易维护,撮合引擎由原子多播订单定序模块、撮合处理器模块、交易记录日志模块和内存数据组成,每个模块根据功能业务划分。其中各部分主要有以下功能:交易订单接收线程:负责从网关接收订单,并完成原子多播定序流程。交易订单发送线程:将定序完成的订单发送给相关撮合业务线程。交易信息发送线程:将订单交易状态反馈给网关。外围业务逻辑线程:进行撮合数据的准备处理,更新内存订单数据。撮合业务逻辑线程:根据确定性撮合算法撮合接收的订单。交易行情发布线程:处理内存行情信息并发布给网关。同步日志写线程:将订单撮合产生的交易记录同步持久化到本地日志文件。异步持久化代理进程:异步将日志文件中的数据读取并持久化到数据库。订单信息:存储订单的相关价格、数量、用户、限制、类型和状态等信息交易行情信息:撮合交易过程中的交易行情信息。 2.6.4系统接口撮合系统主要为使用者提供订单的下单和查询服务、交易行情的实时反馈功能以及系统状态的监控查看服务。因此系统需要实现预留的接口主要包括:下单接口、订单查询接口、行情查询接口、系统控制接口和运行状态查询接口等。 2.7 小节从总体设计入手,将撮合业务处理从数据库迁移至内存中,同时釆用多机热备份技术解决内存撮合技术的易失性问题,最终提出内存状态机复制方案作为高可靠髙性能撮合系统的实现路线。撮合技术的具体实现将在下一章进行详细论述。 ###FAQ Q：热备的机制上。多个机器内存上的状态如何保证强一致性的？ A： 是热备机器都是无状态，普洱茶按照不同品种产生不同撮合序列，只要保证单品种有序，其他撮合机和本机没有关系。 Q: 如果新加入一台撮合引擎，怎么判断所有的撮合数据都同步到了这台新的引擎上？ A: 委托单先要写raid文件系统，新增撮合引擎，也可以拿到数据。 Q: 根据你的描述，一个集群中为了判断撮合引擎是否有故障，至少应该有3台撮合引擎吧? A: zk来管理，并且有风控进程监控撮合进度。 Q: 内存状态机的复制究竟是结果还是数据？ A: 数据，就是把处理到某个状态的数据复制出来。 Q: 如果只有两台撮合引擎，如果对一个买入订单，发现结果不一致，如何判断是哪一台的故障？ A: 撮合只有一台进行撮合，撮合结束才回写数据库产生行情和分发个个终端，用户就可以看到自己委托单是否成交。 【1】简书主页·share猿【2】掘金主页·share猿【3】撮合系统· 李伟山【4】撮合系统·技术方舟【5】交易所视角下的套利指令撮合机制 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"交易所","slug":"交易所","permalink":"https://lywlefan.github.io/tags/交易所/"},{"name":"撮合","slug":"撮合","permalink":"https://lywlefan.github.io/tags/撮合/"}]},{"title":"环形缓冲区","date":"2019-06-24T16:00:00.000Z","path":"2019/06/25/后端/基础巩固/java/数据结构/环形缓冲区/","text":"万丈高楼平地起的前提是地基好. 环形缓冲区介绍圆形缓冲区（circular buffer），也称作圆形队列（circular queue），循环缓冲区（cyclic buffer），环形缓冲区（ring buffer），是一种数据结构用于表示一个固定尺寸、头尾相连的缓冲区，适合缓存数据流。 用法圆形缓冲区的一个有用特性是：当一个数据元素被用掉后，其余数据元素不需要移动其存储位置。相反，一个非圆形缓冲区（例如一个普通的队列）在用掉一个数据元素后，其余数据元素需要向前搬移。换句话说，圆形缓冲区适合实现先进先出缓冲区，而非圆形缓冲区适合后进先出缓冲区。 圆形缓冲区适合于事先明确了缓冲区的最大容量的情形。扩展一个圆形缓冲区的容量，需要搬移其中的数据。因此一个缓冲区如果需要经常调整其容量，用链表实现更为合适。 写操作覆盖圆形缓冲区中未被处理的数据在某些情况下是允许的。特别是在多媒体处理时。例如，音频的生产者可以覆盖掉声卡尚未来得及处理的音频数据。 工作过程一个圆形缓冲区最初为空并有预定的长度。例如，这是一个具有七个元素空间的圆形缓冲区，其中底部的单线与箭头表示“头尾相接”形成一个圆形地址空间： 假定1被写入缓冲区中部（对于圆形缓冲区来说，最初的写入位置在哪里是无关紧要的）： 再写入2个元素，分别是2 &amp; 3 — 被追加在1之后： 如果两个元素被处理，那么是缓冲区中最老的两个元素被卸载。在本例中，1 &amp; 2被卸载，缓冲区中只剩下3: 如果缓冲区中有7个元素，则是满的： 如果缓冲区是满的，又要写入新的数据，一种策略是覆盖掉最老的数据。此例中，2个新数据— A &amp; B — 写入，覆盖了3 &amp; 4: 也可以采取其他策略，禁止覆盖缓冲区的数据，采取返回一个错误码或者抛出异常。 最终，如果从缓冲区中卸载2个数据，不是3 &amp; 4 而是 5 &amp; 6 。因为 A &amp; B 已经覆盖了3 &amp; 4： 圆形缓冲区工作机制由于计算机内存是线性地址空间，因此圆形缓冲区需要特别的设计才可以从逻辑上实现。 读指针与写指针一般的，圆形缓冲区需要4个指针： 在内存中实际开始位置； 在内存中实际结束位置，也可以用缓冲区长度代替； 存储在缓冲区中的有效数据的开始位置（读指针）； 存储在缓冲区中的有效数据的结尾位置（写指针）。 读指针、写指针可以用整型值来表示。 下例为一个未满的缓冲区的读写指针： 下例为一个满的缓冲区的读写指针： 区分缓冲区满或者空缓冲区是满、或是空，都有可能出现读指针与写指针指向同一位置： 250px有多种策略用于检测缓冲区是满、或是空. 总是保持一个存储单元为空缓冲区中总是有一个存储单元保持未使用状态。缓冲区最多存入个数据。如果读写指针指向同一位置，则缓冲区为空。如果写指针位于读指针的相邻后一个位置，则缓冲区为满。这种策略的优点是简单、鲁棒；缺点是语义上实际可存数据量与缓冲区容量不一致，测试缓冲区是否满需要做取余数计算。 使用数据计数这种策略不使用显式的写指针，而是保持着缓冲区内存储的数据的计数。因此测试缓冲区是空是满非常简单；对性能影响可以忽略。缺点是读写操作都需要修改这个存储数据计数，对于多线程访问缓冲区需要并发控制。 镜像指示位缓冲区的长度如果是n，逻辑地址空间则为0至n-1；那么，规定n至2n-1为镜像逻辑地址空间。本策略规定读写指针的地址空间为0至2n-1，其 中低半部分对应于常规的逻辑地址空间，高半部分对应于镜像逻辑地址空间。当指针值大于等于2n时，使其折返（wrapped）到ptr-2n。使用一位表 示写指针或读指针是否进入了虚拟的镜像存储区：置位表示进入，不置位表示没进入还在基本存储区。 在读写指针的值相同情况下，如果二者的指示位相同，说明缓冲区为空；如果二者的指示位不同，说明缓冲区为满。这种方法优点是测试缓冲区满/空很简 单；不需要做取余数操作；读写线程可以分别设计专用算法策略，能实现精致的并发控制。 缺点是读写指针各需要额外的一位作为指示位。 如果缓冲区长度是2的幂，则本方法可以省略镜像指示位。如果读写指针的值相等，则缓冲区为空；如果读写指针相差n，则缓冲区为满，这可以用条件表达式（写指针 == (读指针 异或 缓冲区长度)）来判断。 读/写 计数用两个有符号整型变量分别保存写入、读出缓冲区的数据数量。其差值就是缓冲区中尚未被处理的有效数据的数量。这种方法的优点是读线程、写线程互不干扰；缺点是需要额外两个变量。 记录最后的操作使用一位记录最后一次操作是读还是写。读写指针值相等情况下，如果最后一次操作为写入，那么缓冲区是满的；如果最后一次操作为读出，那么缓冲区是空。 这种策略的缺点是读写操作共享一个标志位，多线程时需要并发控制。 POSIX优化实现Linux内核的kfifo在Linux内核文件kfifo.h和kfifo.c中，定义了一个先进先出圆形缓冲区实现。如果只有一个读线程、一个写线程，二者没有共享的被修改的控制变量，那么可以证明这种情况下不需要并发控制。kfifo就满足上述条件。kfifo要求缓冲区长度必须为2的幂。读、写指针分别是无符号整型变量。把读写指针变换为缓冲区内的索引值，仅需要“按位与”操作：（指针值 按位与 （缓冲区长度-1））。这避免了计算代价高昂的“求余”操作。且下述关系总是成立： 读指针 + 缓冲区存储的数据长度 == 写指针即使在写指针达到了无符号整型的上界，上溢出后写指针的值小于读指针的值，上述关系仍然保持成立（这是因为无符号整型加法的性质）。 kfifo的写操作，首先计算缓冲区中当前可写入存储空间的数据长度：len = min[待写入数据长度, 缓冲区长度 - （写指针 - 读指针）]然后，分两段写入数据。第一段是从写指针开始向缓冲区末尾方向；第二段是从缓冲区起始处写入余下的可写入数据，这部分可能数据长度为0即并无实际数据写入。 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"LMAX架构","date":"2019-06-20T16:00:00.000Z","path":"2019/06/21/架构/LMAX架构/LMAX架构/","text":"万丈高楼平地起的前提是地基好. LMAX架构简介 该架构主要基于：Disruptor + In Memory DDD + Event Sourcing 通过高并发框架（Disruptor）实现用户事件的输入和Domain Event的输出； 一个常驻内存的Business Logic Processor（DDD领域模型），它负责在纯内存中处理业务逻辑；关键点：首先确保用户输入事件被持久化到数据库，并定时创建快照，然后在内存中响应事件更改业务对象的状态；因为一切都是在内存中处理，所以没有IO，也不需要数据库事务，非常快； 机器down了怎么办？因为我们首先确保了业务对象的任何状态改变之前先持久化用户输入事件，所以在down机的时候通过事件回溯重新得到最新的业务对象。因为有了快照的保存，所以重建对象也非常快； 该架构的主要观点： 肯定了In-Memory内存模式 + 异步输入与输出事件（Disruptor） + Event Sourcing 架构，LMAX实践也验证了这个架构。这个架构降低复杂性。 LMAX的核心是新型并发框架Disruptor，其核心是根据现代CPU硬件缓存特点发明不同于通用LinkedList或Queue的新型数据结构RingBuffer。 号称并发未来的Actor模型被LMAX团队验证是有瓶颈的。 提出新的并发模型，每个CPU一个线程，多个CPU多个线程并发模式，摒弃了锁模式。 ORM等Hibernate没有完全解决OO的目标，关系数据库的事务也不是最后救命的稻草。LMAX用自己的事件记录的方式实现事务，这也不同于所谓内存事务STM。 架构师要分离关注，一是通过DDD降低业务的复杂性；二是通过技术探索创新，降低技术平台的复杂性，让程序员更多精力投入业务问题解决上。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】LMAX架构简介·汤雪华 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"LMAX","slug":"LMAX","permalink":"https://lywlefan.github.io/tags/LMAX/"}]},{"title":"使用Java8新的时间API使用","date":"2019-06-20T16:00:00.000Z","path":"2019/06/21/后端/基础巩固/java/工具类/使用 Java8 新的时间 API使用/","text":"使用Java8新的时间API使用 【1】简书主页·share猿【2】掘金主页·share猿【3】使用 Java8 新的时间 API·吾辈 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"LMAX架构","date":"2019-06-20T16:00:00.000Z","path":"2019/06/21/架构/从100到1000万高并发的架构演进之路/","text":"万丈高楼平地起的前提是地基好. 基本概念在介绍架构之前，为了避免部分读者对架构设计中的一些概念不了解，下面对几个最基础的概念进行介绍。 什么是分布式？系统中的多个模块在不同服务器上部署，即可称为分布式系统，如Tomcat和数据库分别部署在不同的服务器上，或两个相同功能的Tomcat分别部署在不同服务器上。 什么是高可用？系统中部分节点失效时，其他节点能够接替它继续提供服务，则可认为系统具有高可用性。 什么是集群？一个特定领域的软件部署在多台服务器上并作为一个整体提供一类服务，这个整体称为集群。 如Zookeeper中的Master和Slave分别部署在多台服务器上，共同组成一个整体提供集中配置服务。 在常见的集群中，客户端往往能够连接任意一个节点获得服务，并且当集群中一个节点掉线时，其他节点往往能够自动的接替它继续提供服务，这时候说明集群具有高可用性。 什么是负载均衡？请求发送到系统时，通过某些方式把请求均匀分发到多个节点上，使系统中每个节点能够均匀的处理请求负载，则可认为系统是负载均衡的。 什么是正向代理和反向代理？系统内部要访问外部网络时，统一通过一个代理服务器把请求转发出去，在外部网络看来就是代理服务器发起的访问，此时代理服务器实现的是正向代理； 当外部请求进入系统时，代理服务器把该请求转发到系统中的某台服务器上，对外部请求来说，与之交互的只有代理服务器，此时代理服务器实现的是反向代理。 简单来说，正向代理是代理服务器代替系统内部来访问外部网络的过程，反向代理是外部请求访问系统时通过代理服务器转发到内部服务器的过程。 架构演讲纯真年代：单机架构 以淘宝作为例子：在网站最初时，应用数量与用户数都较少，可以把Tomcat和数据库部署在同一台服务器上。浏览器往www.taobao.com发起请求时，首先经过DNS服务器（域名系统）把域名转换为实际IP地址10.102.4.1，浏览器转而访问该IP对应的Tomcat。 架构瓶颈：随着用户数的增长，Tomcat和数据库之间竞争资源，单机性能不足以支撑业务。 第一次演进：Tomcat与数据库分开部署 Tomcat和数据库分别独占服务器资源，显著提高两者各自性能。 架构瓶颈：随着用户数的增长，并发读写数据库成为瓶颈。 第二次演进：引入本地缓存和分布式缓存 在Tomcat同服务器上或同JVM中增加本地缓存，并在外部增加分布式缓存，缓存热门商品信息或热门商品的html页面等。通过缓存能把绝大多数请求在读写数据库前拦截掉，大大降低数据库压力。其中涉及的技术包括：使用memcached作为本地缓存，使用Redis作为分布式缓存，还会涉及缓存一致性、缓存穿透/击穿、缓存雪崩、热点数据集中失效等问题。 架构瓶颈：缓存抗住了大部分的访问请求，随着用户数的增长，并发压力主要落在单机的Tomcat上，响应逐渐变慢。 第三次演进：引入反向代理实现负载均衡 在多台服务器上分别部署Tomcat，使用反向代理软件（Nginx）把请求均匀分发到每个Tomcat中。此处假设Tomcat最多支持100个并发，Nginx最多支持50000个并发，那么理论上Nginx把请求分发到500个Tomcat上，就能抗住50000个并发。 其中涉及的技术包括：Nginx、HAProxy，两者都是工作在网络第七层的反向代理软件，主要支持http协议，还会涉及session共享、文件上传下载的问题。 架构瓶颈：反向代理使应用服务器可支持的并发量大大增加，但并发量的增长也意味着更多请求穿透到数据库，单机的数据库最终成为瓶颈。 第四次演进：数据库读写分离 把数据库划分为读库和写库，读库可以有多个，通过同步机制把写库的数据同步到读库，对于需要查询最新写入数据场景，可通过在缓存中多写一份，通过缓存获得最新数据。其中涉及的技术包括：Mycat，它是数据库中间件，可通过它来组织数据库的分离读写和分库分表，客户端通过它来访问下层数据库，还会涉及数据同步，数据一致性的问题。 架构瓶颈：业务逐渐变多，不同业务之间的访问量差距较大，不同业务直接竞争数据库，相互影响性能。 第五次演进：数据库按业务分库 把不同业务的数据保存到不同的数据库中，使业务之间的资源竞争降低，对于访问量大的业务，可以部署更多的服务器来支撑。这样同时导致跨业务的表无法直接做关联分析，需要通过其他途径来解决，但这不是本文讨论的重点，有兴趣的可以自行搜索解决方案。 架构瓶颈：随着用户数的增长，单机的写库会逐渐会达到性能瓶颈。 第六次演进：把大表拆分为小表 比如针对评论数据，可按照商品ID进行hash，路由到对应的表中存储；针对支付记录，可按照小时创建表，每个小时表继续拆分为小表，使用用户ID或记录编号来路由数据。只要实时操作的表数据量足够小，请求能够足够均匀的分发到多台服务器上的小表，那数据库就能通过水平扩展的方式来提高性能。其中前面提到的Mycat也支持在大表拆分为小表情况下的访问控制。 这种做法显著的增加了数据库运维的难度，对DBA的要求较高。数据库设计到这种结构时，已经可以称为分布式数据库，但是这只是一个逻辑的数据库整体，数据库里不同的组成部分是由不同的组件单独来实现的，如分库分表的管理和请求分发，由Mycat实现，SQL的解析由单机的数据库实现，读写分离可能由网关和消息队列来实现，查询结果的汇总可能由数据库接口层来实现等等，这种架构其实是MPP（大规模并行处理）架构的一类实现。 目前开源和商用都已经有不少MPP数据库，开源中比较流行的有Greenplum、TiDB、Postgresql XC、HAWQ等，商用的如南大通用的GBase、睿帆科技的雪球DB、华为的LibrA等等，不同的MPP数据库的侧重点也不一样，如TiDB更侧重于分布式OLTP场景，Greenplum更侧重于分布式OLAP场景，这些MPP数据库基本都提供了类似Postgresql、Oracle、MySQL那样的SQL标准支持能力，能把一个查询解析为分布式的执行计划分发到每台机器上并行执行，最终由数据库本身汇总数据进行返回，也提供了诸如权限管理、分库分表、事务、数据副本等能力，并且大多能够支持100个节点以上的集群，大大降低了数据库运维的成本，并且使数据库也能够实现水平扩展。 架构瓶颈：数据库和Tomcat都能够水平扩展，可支撑的并发大幅提高，随着用户数的增长，最终单机的Nginx会成为瓶颈。 第七次演进：使用LVS或F5来使多个Nginx负载均衡 由于瓶颈在Nginx，因此无法通过两层的Nginx来实现多个Nginx的负载均衡。图中的LVS和F5是工作在网络第四层的负载均衡解决方案，其中LVS是软件，运行在操作系统内核态，可对TCP请求或更高层级的网络协议进行转发，因此支持的协议更丰富，并且性能也远高于Nginx，可假设单机的LVS可支持几十万个并发的请求转发；F5是一种负载均衡硬件，与LVS提供的能力类似，性能比LVS更高，但价格昂贵。由于LVS是单机版的软件，若LVS所在服务器宕机则会导致整个后端系统都无法访问，因此需要有备用节点。可使用keepalived软件模拟出虚拟IP，然后把虚拟IP绑定到多台LVS服务器上，浏览器访问虚拟IP时，会被路由器重定向到真实的LVS服务器，当主LVS服务器宕机时，keepalived软件会自动更新路由器中的路由表，把虚拟IP重定向到另外一台正常的LVS服务器，从而达到LVS服务器高可用的效果。 此处需要注意的是，上图中从Nginx层到Tomcat层这样画并不代表全部Nginx都转发请求到全部的Tomcat，在实际使用时，可能会是几个Nginx下面接一部分的Tomcat，这些Nginx之间通过keepalived实现高可用，其他的Nginx接另外的Tomcat，这样可接入的Tomcat数量就能成倍的增加。 架构瓶颈：由于LVS也是单机的，随着并发数增长到几十万时，LVS服务器最终会达到瓶颈，此时用户数达到千万甚至上亿级别，用户分布在不同的地区，与服务器机房距离不同，导致了访问的延迟会明显不同。 第八次演进：通过DNS轮询实现机房间的负载均衡 在DNS服务器中可配置一个域名对应多个IP地址，每个IP地址对应到不同的机房里的虚拟IP。当用户访问www.taobao.com时，DNS服务器会使用轮询策略或其他策略，来选择某个IP供用户访问。此方式能实现机房间的负载均衡，至此，系统可做到机房级别的水平扩展，千万级到亿级的并发量都可通过增加机房来解决，系统入口处的请求并发量不再是问题。 架构瓶颈：随着数据的丰富程度和业务的发展，检索、分析等需求越来越丰富，单单依靠数据库无法解决如此丰富的需求。 第九次演进：引入NoSQL数据库和搜索引擎等技术 当数据库中的数据多到一定规模时，数据库就不适用于复杂的查询了，往往只能满足普通查询的场景。对于统计报表场景，在数据量大时不一定能跑出结果，而且在跑复杂查询时会导致其他查询变慢，对于全文检索、可变数据结构等场景，数据库天生不适用。因此需要针对特定的场景，引入合适的解决方案。如对于海量文件存储，可通过分布式文件系统HDFS解决，对于key value类型的数据，可通过HBase和Redis等方案解决，对于全文检索场景，可通过搜索引擎如ElasticSearch解决，对于多维分析场景，可通过Kylin或Druid等方案解决。 当然，引入更多组件同时会提高系统的复杂度，不同的组件保存的数据需要同步，需要考虑一致性的问题，需要有更多的运维手段来管理这些组件等。 架构瓶颈：引入更多组件解决了丰富的需求，业务维度能够极大扩充，随之而来的是一个应用中包含了太多的业务代码，业务的升级迭代变得困难。 第十次演进：大应用拆分为小应用 按照业务板块来划分应用代码，使单个应用的职责更清晰，相互之间可以做到独立升级迭代。这时候应用之间可能会涉及到一些公共配置，可以通过分布式配置中心Zookeeper来解决。 架构瓶颈：不同应用之间存在共用的模块，由应用单独管理会导致相同代码存在多份，导致公共功能升级时全部应用代码都要跟着升级。 第十一次演进：复用的功能抽离成微服务 如用户管理、订单、支付、鉴权等功能在多个应用中都存在，那么可以把这些功能的代码单独抽取出来形成一个单独的服务来管理，这样的服务就是所谓的微服务，应用和服务之间通过HTTP、TCP或RPC请求等多种方式来访问公共服务，每个单独的服务都可以由单独的团队来管理。此外，可以通过Dubbo、SpringCloud等框架实现服务治理、限流、熔断、降级等功能，提高服务的稳定性和可用性。 架构瓶颈：不同服务的接口访问方式不同，应用代码需要适配多种访问方式才能使用服务，此外，应用访问服务，服务之间也可能相互访问，调用链将会变得非常复杂，逻辑变得混乱。 第十二次演进：引入企业服务总线ESB屏蔽服务接口的访问差异 通过ESB统一进行访问协议转换，应用统一通过ESB来访问后端服务，服务与服务之间也通过ESB来相互调用，以此降低系统的耦合程度。 这种单个应用拆分为多个应用，公共服务单独抽取出来来管理，并使用企业消息总线来解除服务之间耦合问题的架构，就是所谓的SOA（面向服务）架构，这种架构与微服务架构容易混淆，因为表现形式十分相似。 个人理解，微服务架构更多是指把系统里的公共服务抽取出来单独运维管理的思想，而SOA架构则是指一种拆分服务并使服务接口访问变得统一的架构思想，SOA架构中包含了微服务的思想。 架构瓶颈：业务不断发展，应用和服务都会不断变多，应用和服务的部署变得复杂，同一台服务器上部署多个服务还要解决运行环境冲突的问题，此外，对于如大促这类需要动态扩缩容的场景，需要水平扩展服务的性能，就需要在新增的服务上准备运行环境，部署服务等，运维将变得十分困难。 第十三次演进：引入容器化技术实现运行环境隔离与动态服务管理 目前最流行的容器化技术是Docker，最流行的容器管理服务是Kubernetes(K8S)，应用/服务可以打包为Docker镜像，通过K8S来动态分发和部署镜像。Docker镜像可理解为一个能运行你的应用/服务的最小的操作系统，里面放着应用/服务的运行代码，运行环境根据实际的需要设置好。把整个“操作系统”打包为一个镜像后，就可以分发到需要部署相关服务的机器上，直接启动Docker镜像就可以把服务起起来，使服务的部署和运维变得简单。 在大促的之前，可以在现有的机器集群上划分出服务器来启动Docker镜像，增强服务的性能，大促过后就可以关闭镜像，对机器上的其他服务不造成影响（在第18节之前，服务运行在新增机器上需要修改系统配置来适配服务，这会导致机器上其他服务需要的运行环境被破坏）。 架构瓶颈：使用容器化技术后服务动态扩缩容问题得以解决，但是机器还是需要公司自身来管理，在非大促的时候，还是需要闲置着大量的机器资源来应对大促，机器自身成本和运维成本都极高，资源利用率低。 第十四次演进：以云平台承载系统 系统可部署到公有云上，利用公有云的海量机器资源，解决动态硬件资源的问题，在大促的时间段里，在云平台中临时申请更多的资源，结合Docker和K8S来快速部署服务，在大促结束后释放资源，真正做到按需付费，资源利用率大大提高，同时大大降低了运维成本。 所谓的云平台，就是把海量机器资源，通过统一的资源管理，抽象为一个资源整体，在之上可按需动态申请硬件资源（如CPU、内存、网络等），并且之上提供通用的操作系统，提供常用的技术组件（如Hadoop技术栈，MPP数据库等）供用户使用，甚至提供开发好的应用，用户不需要关系应用内部使用了什么技术，就能够解决需求（如音视频转码服务、邮件服务、个人博客等）。 在云平台中会涉及如下几个概念： IaaS：基础设施即服务。对应于上面所说的机器资源统一为资源整体，可动态申请硬件资源的层面； PaaS：平台即服务。对应于上面所说的提供常用的技术组件方便系统的开发和维护； SaaS：软件即服务。对应于上面所说的提供开发好的应用或服务，按功能或性能要求付费。 至此：以上所提到的从高并发访问问题，到服务的架构和系统实施的层面都有了各自的解决方案。但同时也应该意识到，在上面的介绍中，其实是有意忽略了诸如跨机房数据同步、分布式事务实现等等的实际问题，这些问题以后有机会再拿出来单独讨论。 小结架构的调整是否必须按照上述演变路径进行？不是的，以上所说的架构演变顺序只是针对某个侧面进行单独的改进，在实际场景中，可能同一时间会有几个问题需要解决，或者可能先达到瓶颈的是另外的方面，这时候就应该按照实际问题实际解决。如在政府类的并发量可能不大，但业务可能很丰富的场景，高并发就不是重点解决的问题，此时优先需要的可能会是丰富需求的解决方案。 对于将要实施的系统，架构应该设计到什么程度？对于单次实施并且性能指标明确的系统，架构设计到能够支持系统的性能指标要求就足够了，但要留有扩展架构的接口以便不备之需。对于不断发展的系统，如电商平台，应设计到能满足下一阶段用户量和性能指标要求的程度，并根据业务的增长不断的迭代升级架构，以支持更高的并发和更丰富的业务。 服务端架构和大数据架构有什么区别？所谓的“大数据”其实是海量数据采集清洗转换、数据存储、数据分析、数据服务等场景解决方案的一个统称，在每一个场景都包含了多种可选的技术，如数据采集有Flume、Sqoop、Kettle等，数据存储有分布式文件系统HDFS、FastDFS，NoSQL数据库HBase、MongoDB等，数据分析有Spark技术栈、机器学习算法等。总的来说大数据架构就是根据业务的需求，整合各种大数据组件组合而成的架构，一般会提供分布式存储、分布式计算、多维分析、数据仓库、机器学习算法等能力。而服务端架构更多指的是应用组织层面的架构，底层能力往往是由大数据架构来提供。 有没有一些架构设计的原则？ a. N+1设计：系统中的每个组件都应做到没有单点故障； b. 回滚设计：确保系统可以向前兼容，在系统升级时应能有办法回滚版本； c. 禁用设计：应该提供控制具体功能是否可用的配置，在系统出现故障时能够快速下线功能； d. 监控设计：在设计阶段就要考虑监控的手段； e. 多活数据中心设计：若系统需要极高的高可用，应考虑在多地实施数据中心进行多活，至少在一个机房断电的情况下系统依然可用； f. 采用成熟的技术：刚开发的或开源的技术往往存在很多隐藏的bug，出了问题没有商业支持可能会是一个灾难； g. 资源隔离设计：应避免单一业务占用全部资源； h. 架构应能水平扩展：系统只有做到能水平扩展，才能有效避免瓶颈问题； i. 非核心则购买：非核心功能若需要占用大量的研发资源才能解决，则考虑购买成熟的产品； j. 使用商用硬件：商用硬件能有效降低硬件故障的机率； k. 快速迭代：系统应该快速开发小功能模块，尽快上线进行验证，早日发现问题大大降低系统交付的风险； l. 无状态设计：服务接口应该做成无状态的，当前接口的访问不依赖于接口上次访问的状态。 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 《新手入门：零基础理解大型分布式架构的演进历史、技术原理、最佳实践》 《腾讯资深架构师干货总结：一文读懂大型分布式系统设计的方方面面》 《一篇读懂分布式架构下的负载均衡技术：分类、原理、算法、常见方案等》 《快速理解高性能HTTP服务端的负载均衡技术原理》 《知乎技术分享：从单机到2000万QPS并发的Redis高性能缓存实践之路》 《达达O2O后台架构演进实践：从0到4000高并发请求背后的努力》 《小米技术分享：解密小米抢购系统千万高并发架构的演进和实践》 《通俗易懂：如何设计能支撑百万并发的数据库架构？》 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"总结","slug":"总结","permalink":"https://lywlefan.github.io/tags/总结/"}]},{"title":"java枚举的总结和学习","date":"2019-06-20T16:00:00.000Z","path":"2019/06/21/后端/基础巩固/java/枚举/java枚举的总结和学习/","text":"万丈高楼平地起的前提是地基好. 枚举基础规范 实例常量用大写 enum是个类(特别实用的特性,可以在switch语句中使用) 方法 toString:显示某个实例的名字 ordinal:显示常量的顺序 static values:按枚举常量顺序,产生常量构成的数组. 枚举类可以实现一个接口 使用常量123public enum Color &#123; RED, GREEN, BLANK, YELLOW &#125; switch12345678910111213141516171819enum Signal &#123; GREEN, YELLOW, RED &#125; public class TrafficLight &#123; Signal color = Signal.RED; public void change() &#123; switch (color) &#123; case RED: color = Signal.GREEN; break; case YELLOW: color = Signal.RED; break; case GREEN: color = Signal.YELLOW; break; &#125; &#125; &#125; 构造方法&emsp;&emsp;规定构造方法必须为private修饰符所修饰，也就是说只能在类的内部构造，不能在其他类中通过构造方法新增枚举类型。 在枚举类中创建一个构造函数 123456789@Getter@AllArgsConstructorpublic enum CommonEnum &#123; SUCCESS(\"交易成功\",\"SUCCESS\"); private String name; private String value; &#125; 枚举可以实现一个接口 123456789101112131415161718192021222324252627public interface Behaviour &#123; void print(); String getInfo(); &#125; public enum Color implements Behaviour&#123; RED(&quot;红色&quot;, 1), GREEN(&quot;绿色&quot;, 2), BLANK(&quot;白色&quot;, 3), YELLO(&quot;黄色&quot;, 4); // 成员变量 private String name; private int index; // 构造方法 private Color(String name, int index) &#123; this.name = name; this.index = index; &#125; //接口方法 @Override public String getInfo() &#123; return this.name; &#125; //接口方法 @Override public void print() &#123; System.out.println(this.index+&quot;:&quot;+this.name); &#125; &#125; 使用接口组织枚举12345678public interface Food &#123; enum Coffee implements Food&#123; BLACK_COFFEE,DECAF_COFFEE,LATTE,CAPPUCCINO &#125; enum Dessert implements Food&#123; FRUIT, CAKE, GELATO &#125; &#125; 关于枚举集合的使用&emsp;&emsp;java.util.EnumSet和java.util.EnumMap是两个枚举集合。EnumSet保证集合中的元素不重复；EnumMap中的 key是enum类型，而value则可以是任意类型。关于这个两个集合的使用就不在这里赘述，可以参考JDK文档。 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"基础","slug":"基础","permalink":"https://lywlefan.github.io/tags/基础/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"java整体脉络总结","date":"2019-06-04T16:00:00.000Z","path":"2019/06/05/后端/指导思想/java/java整体脉络总结/","text":"java学习指导战略。 基础 Java基础知识 阅读源代码 String Integer Long Enum BigDecimal ThreadLocal ClassLoader&amp;URLClassLoader ArrayList&amp;LinkedList HashMap&amp;LinkedHashMap&amp;TreeMap&amp;CouncurrentHashMap HashSet&amp;LinkedHashSet&amp;TreeSet Java中的各种变量类型 熟悉Java String的使用，熟悉String的各种函数 JDK6和JDK7中substring的原理及区别 replaceFirst、replaceAll、replace区别 String对“+”的重载 String.valueOf和Integer.toString的区别 字符串的不可变性 自动拆装箱 Integer的缓存机制 熟悉Java中各种关键字原理和用法 transient instanceof volatile synchronized final static const 集合类 常用集合类的使用 ArrayList和LinkedList和Vector的区别 SynchronizedList和Vector的区别 HashMap、HashTable、ConcurrentHashMap区别 Java 8中stream相关用法 apache集合处理工具类的使用 不同版本的JDK中HashMap的实现的区别以及原因 枚举 枚举的用法 枚举与单例 Enum类 Java IO&amp;Java NIO bio nio aio 三种IO的用法与原理 netty Java反射与javassist 反射与工厂模式 java.lang.reflect.* Java序列化 什么是序列化与反序列化、为什么序列化 序列化底层原理 序列化与单例模式 protobuf 为什么说序列化并不安全 注解 元注解 自定义注解 Java中常用注解使用 注解与反射的结合 JMS 什么是Java消息服务 JMS消息传送模型 JMX java.lang.management.* javax.management.* 泛型 泛型与继承 类型擦除 泛型中K T V E object等的含义、泛型各种用法 单元测试 junit mock mockito 内存数据库（h2） 正则表达式 java.lang.util.regex.* 常用的Java工具库 commons.lang commons.*… guava-libraries netty 什么是API&amp;SPI 异常 异常类型 正确处理异常 自定义异常 时间处理 时区 时令 Java中时间API 编码方式 解决乱码问题 常用编码方式 语法糖 Java中语法糖原理 解语法糖 Java并发编程 什么是线程，与进程的区别 阅读相关源代码，并学会使用 Thread Runnable Callable ReentrantLock、ReentrantReadWriteLock、Atomic*、Semaphore、CountDownLatch、、ConcurrentHashMap、Executors 线程池 自己设计线程池、submit() 和 execute() 线程安全 死锁、死锁如何排查、Java线程调度、线程安全和内存模型的关系 锁 CAS、乐观锁与悲观锁、数据库相关锁机制、分布式锁、偏向锁、轻量级锁、重量级锁、monitor、锁优化、锁消除、锁粗化、自旋锁、可重入锁、阻塞锁、死锁 死锁 volatile happens-before、编译器指令重排和CPU指令重 synchronized synchronized是如何实现的？ synchronized和lock之间关系，不使用synchronized如何实现一个线程安全的单例 sleep 和 wait wait 和 notify notify 和 notifyAll ThreadLocal 写一个死锁的程序 写代码来解决生产者消费者问题 守护线程 守护线程和非守护线程的区别以及用法 JVM JVM内存结构 堆 栈 方法区 直接内存 堆和栈的区别 Java内存模型 内存可见性 重排序 顺序一致性 volatile 锁 final 垃圾回收 内存分配策略 垃圾收集器 G1 GC算法 GC参数 对象存活的判定 JVM参数及调优 Java对象模型 oop-klass 对象头 HotSpot 即时编译器 编译优化 类加载机制 classLoader 类加载过程 双亲委派（破坏双亲委派） 模块化 jboss modules osgi jigsaw 虚拟机性能监控与故障处理工具 jps jstack jmap jstat jconsole jhat javap btrace TProfiler 编译与反编译 javac javap jad CRF 进阶 Java底层知识 字节码、class文件格式 CPU缓存，L1，L2，L3和伪共享 尾递归 位运算 位运算实现加、减、乘、除、取余 设计模式 了解23种设计模式 在软件工程中，设计模式（design pattern）是对软件设计中普遍存在的各种问题，所提出的解决方案。设计模式并不是固定的一套代码，而是针对某一特定问题的具体解决思路与方案。可以认为是一种最佳实践，因为他是无数软件开发人员经过长时间的实践总结出来的。 设计模式的六大原则 开闭原则 里氏代换原则 依赖倒转原则 接口隔离原则 迪米特法则（最少知道原则） 合成复用原则 设计模式分类 创建型模式 单例模式 保证一个类仅有一个实例，并提供一个访问它的全局访问点。 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如网站首页页面缓存）。 避免对资源的多重占用（比如写文件操作） 饿汉式 1234567891011public class Singleton &#123; //在类内部实例化一个实例 private static Singleton instance = new Singleton(); //私有的构造函数,外部无法访问 private Singleton() &#123; &#125; //对外提供获取实例的静态方法 public static Singleton getInstance() &#123; return instance; &#125; &#125; 饿汉式单例，在类被加载的时候对象就会实例化。这也许会造成不必要的消耗，因为有可能这个实例根本就不会被用到。而且，如果这个类被多次加载的话也会造成多次实例化。其实解决这个问题的方式有很多，下面提供两种解决方式，第一种是使用静态内部类的形式。第二种是使用懒汉式。 静态内部类式 饿汉式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果），而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance 想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比饿汉式更加合理。 12345678910111213public class StaticInnerClassSingleton &#123; //在静态内部类中初始化实例对象 private static class SingletonHolder &#123; private static final StaticInnerClassSingleton INSTANCE = new StaticInnerClassSingleton(); &#125; //私有的构造方法 private StaticInnerClassSingleton() &#123; &#125; //对外提供获取实例的静态方法 public static final StaticInnerClassSingleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125; 懒汉式 1234567891011121314public class Singleton &#123; //定义实例 private static Singleton instance; //私有构造方法 private Singleton()&#123;&#125; //对外提供获取实例的静态方法 public static Singleton getInstance() &#123; //在对象被使用的时候才实例化 if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 这种懒汉式单例其实还存在一个问题，那就是线程安全问题。在多线程情况下，有可能两个线程同时进入if语句中，这样，在两个线程都从if中退出的时候就创建了两个不一样的对象。 懒汉，就是不会提前把实例创建出来，将类对自己的实例化延迟到第一次被引用的时候。getInstance方法的作用是希望该对象在第一次被使用的时候被new出来。 线程安全的懒汉式 1234567891011121314public class SynchronizedSingleton &#123; //定义实例 private static SynchronizedSingleton instance; //私有构造方法 private SynchronizedSingleton()&#123;&#125; //对外提供获取实例的静态方法,对该方法加锁 public static synchronized SynchronizedSingleton getInstance() &#123; //在对象被使用的时候才实例化 if (instance == null) &#123; instance = new SynchronizedSingleton(); &#125; return instance; &#125; &#125; 遗憾的是，他效率很低，因为99%情况下不需要同步。（因为上面的synchronized的加锁范围是整个方法，该方法的所有操作都是同步进行的，但是对于非第一次创建对象的情况，也就是没有进入if语句中的情况，根本不需要同步操作，可以直接返回instance。） 双重校验锁 123456789101112131415161718public class Singleton &#123; private static Singleton singleton; private Singleton() &#123; &#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 线程A发现变量没有被初始化, 然后它获取锁并开始变量的初始化。 由于某些编程语言的语义，编译器生成的代码允许在线程A执行完变量的初始化之前，更新变量并将其指向部分初始化的对象。 线程B发现共享变量已经被初始化，并返回变量。由于线程B确信变量已被初始化，它没有获取锁。如果在A完成初始化之前共享变量对B可见（这是由于A没有完成初始化或者因为一些初始化的值还没有穿过B使用的内存(缓存一致性)），程序很可能会崩溃。 在J2SE 1.4或更早的版本中使用双重检查锁有潜在的危险，有时会正常工作（区分正确实现和有小问题的实现是很困难的。取决于编译器，线程的调度和其他并发系统活动，不正确的实现双重检查锁导致的异常结果可能会间歇性出现。重现异常是十分困难的。） 在J2SE 5.0中，这一问题被修正了。volatile关键字保证多个线程可以正确处理单件实例 子主题 双重校验锁优化 1234567891011121314151617public class VolatileSingleton &#123; private static volatile VolatileSingleton singleton; private VolatileSingleton() &#123; &#125; public static VolatileSingleton getSingleton() &#123; if (singleton == null) &#123; synchronized (VolatileSingleton.class) &#123; if (singleton == null) &#123; singleton = new VolatileSingleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 12345678910111213141516171819202122232425class FinalWrapper&lt;T&gt; &#123; public final T value; public FinalWrapper(T value) &#123; this.value = value; &#125; &#125; public class FinalSingleton &#123; private FinalWrapper&lt;FinalSingleton&gt; helperWrapper = null; public FinalSingleton getHelper() &#123; FinalWrapper&lt;FinalSingleton&gt; wrapper = helperWrapper; if (wrapper == null) &#123; synchronized (this) &#123; if (helperWrapper == null) &#123; helperWrapper = new FinalWrapper&lt;FinalSingleton&gt;(new FinalSingleton()); &#125; wrapper = helperWrapper; &#125; &#125; return wrapper.value; &#125; &#125; 防止序列化方式 123456789101112131415161718192021222324package com.hollis; import java.io.Serializable; /** * Created by hollis on 16/2/5. * 使用双重校验锁方式实现单例 */ public class Singleton implements Serializable&#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; private Object readResolve() &#123; return singleton; &#125; &#125; 抽象工厂模式 建造者模式 工厂模式 原型模式 结构型模式 适配器模式 桥接模式 组合模式 装饰模式 外观模式 享元模式 代理模式 行为型模式 模板方法模式 命令模式 迭代器模式 观察者模式 中介者模式 解析器模式（Interpreter模式） 状态模式 策略模式 责任链模式 访问者模式 使用常用设计模式 单例 策略 工厂 适配器 责任链 实现AOP 实现IOC 不用synchronized和lock，实现线程安全的单例模式 nio和reactor设计模式 网络编程 tcp、udp、http、https等常用协议 三次握手协议 四次关闭 流量控制和拥塞控制 OSI七层模型 tcp粘包和拆包 http/1.0 http/1.1 http/2 之间的区别 Java RMI Socket HttpClient cookie与session cookie被禁用，如何实现session 用Java写一个简单的静态文件的HTTP服务器 实现客户端缓存功能，支持返回304 实现可并发下载一个文件 使用线程池处理客户端请求 使用nio处理客户端请求 支持简单的rewrite规则 上述功能在实现的时候需要满足“开闭原则” 了解nginx和apache服务器特性并搭建一个对应的服务器 用Java实现FTP、SMTP协议 进程间通讯的方式 什么是CDN？如果实现 什么是DNS 反向代理 框架知识 Servlet线程安全问题 Servlet中的filter和listener Hibernate的缓存机制 Hibernate的懒加载 Spring Bean的初始化 Spring的AOP原理 自己实现Spring的IOC Spring MVC Spring Boot2.0 Spring Boot的starter原理，自己实现一个starter Spring Security 应用服务器 JBoss tomcat jetty Weblogic 工具 git&amp;svn maven&amp;gradle 高级 新技术 Java8 lambda表达式 Stream API Java9 Jigsaw Jshell Reactive Streams Java10 局部变量类型推断 G1的并行Full GC ThreadLocal握手机制 响应式编程 Spring Boot 2.0 线上问题分析 dump获取 线程Dump 内存Dump gc dump分析 分析死锁 分析内存泄漏 自己编写各种outofmemory,stackoverflow程序 HeapOutOfMemory、 Young OutOfMemory、MethodArea OutOfMemory、ConstantPool OutOfMemory、DirectMemory OutOfMemory、Stack OutOfMemory Stack OverFlow 常见问题解决思路 内存溢出 线程死锁 类加载冲突 使用工具尝试解决问题，并总结 当一个Java程序响应很慢时如何查找问题 当一个Java程序频繁FullGC时如何解决问题 如何查看垃圾回收日志 当一个Java应用发生OutOfMemory时如何解决 如何判断是否出现死锁 如何判断是否存在内存泄漏 性能优化 使用单例 使用Future模式 使用线程池 选择就绪 减少上下文切换 减小锁粒度 数据压缩 结果缓存 编译原理知识 编译与反编译 Java代码的编译与反编译 Java的反编译工具 词法分析，语法分析（LL算法，递归下降算法，LR算法），语义分析，运行时环境，中间代码，代码生成，代码优化 操作系统知识 Linux的常用命令 进程同步 缓冲区溢出 分段和分页 虚拟内存与主存 数据库知识 MySql执行引擎 数据库建模三范式 Mysql执行计划 如何查看执行计划 如何根据执行计划进行sql优化 SQL优化 事务 事务的隔离级别 事务能不能实现锁的功能 数据库锁 行锁 表锁 使用数据库实现乐观锁 数据库主备搭建 binlog 内存数据库 常用的nosql数据库 redis memcached 使用数据库锁、NoSql实现分布式锁 性能调优 数据结构和算法知识 简单的数据结构 栈 队列 链表 数组 哈希表 树 二叉树 字典树 平衡树 排序树 B树 B+树 R树 多路树 红黑树 排序算法 各种排序算法和时间复杂度 深度优先和广度优先搜索 全排列 贪心算法 KMP算法 hash算法 一致性hash算法 海量数据处理 大数据知识 Zookeeper Solr，Lucene，ElasticSearch Storm，流式计算，了解Spark，S4 Hadoop，离线计算 分布式日志收集flume，kafka，logstash 数据挖掘，mahout 网络安全 什么是XSS 什么是CSRF 什么是注入攻击 什么是文件上传漏洞 加密与解密 什么是DOS攻击和DDOS攻击 SSL，TLS，HTTPS 如何通过Hash碰撞进行DOS攻击 用openssl签一个证书部署到apache或nginx 架构 分布式 分布式事务 rpc 分布式数据库 分布式文件系统 分布式缓存 微服务 SOA 康威定律 ServiceMesh Docker &amp; Kubernets Spring Boot Spring Cloud 高并发 分库分表 CDN技术 消息队列 ActiveMQ 监控 监控什么 CPU 内存 磁盘IO 网络IO 服务监控 监控手段 进程监控 语义监控 机器资源监控 数据波动 监控数据采集 日志 埋点 Dapper 负载均衡 DNS CDN 数据一致性 扩展 云计算 IaaS SaaS PaaS 虚拟化技术 Serverlsess openstack 搜索引擎 Solr Lucene Nutch Elasticsearch 权限管理-必须的 Shiro 区块链 基础 哈希算法 Merkle树 公钥密码算法 共识算法 Raft协议 Paxos 算法与 Raft 算法 拜占庭问题与算法 消息认证码与数字签名 应用 比特币 以太坊 超级账本 人工智能 基础 数学基础 机器学习 人工神经网络 深度学习 应用场景 框架 TensorFlow DeepLearning4J 其他语言 Groovy Python Go NodeJs Swift Rust 书籍推荐 《深入理解Java虚拟机》 《Effective Java》 《深入分析Java Web技术内幕》 《大型网站技术架构》 《代码整洁之道》 《Head First设计模式》 《maven实战》 《区块链原理、设计与应用》 《Java并发编程实战》 《鸟哥的Linux私房菜》 《从Paxos到Zookeeper》 《架构即未来》 【1】简书主页·share猿【2】掘金主页·share猿【3】JavaGuide·Snailclimb 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"指导思想","slug":"指导思想","permalink":"https://lywlefan.github.io/tags/指导思想/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"微服务架构的理论基础 - 康威定律","date":"2019-06-04T16:00:00.000Z","path":"2019/06/05/后端/指导思想/java/微服务架构的理论基础 - 康威定律/","text":"概述&emsp;&emsp;关于微服务的介绍，可以参考微服务那点事。 &emsp;&emsp;微服务是最近非常火热的新概念，大家都在追，也都觉得很对，但是似乎没有很充足的理论基础说明这是正确的，给人的感觉是 不明觉厉 。前段时间看了Mike Amundsen 《远距离条件下的康威定律——分布式世界中实现团队构建》（是Design RESTful API的作者）在InfoQ上的一个分享，觉得很有帮助，结合自己的一些思考，整理了该演讲的内容。 &emsp;&emsp;可能出乎很多人意料之外的一个事实是，微服务很多核心理念其实在半个世纪前的一篇文章中就被阐述过了，而且这篇文章中的很多论点在软件开发飞速发展的这半个世纪中竟然一再被验证，这就是康威定律（Conway’s Law）。 &emsp;&emsp;在康威的这篇文章中，最有名的一句话就是： Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations. - Melvin Conway(1967) &emsp;&emsp;中文直译大概的意思就是：设计系统的组织，其产生的设计等同于组织之内、组织之间的沟通结构。看看下面的图片（来源于互联网，侵删），再想想Apple的产品、微软的产品设计，就能形象生动的理解这句话。 &emsp;&emsp;用通俗的说法就是：组织形式等同系统设计。 &emsp;&emsp;这里的系统按原作者的意思并不局限于软件系统。据说这篇文章最初投的哈佛商业评论，结果程序员屌丝的文章不入商业人士的法眼，无情被拒，康威就投到了一个编程相关的杂志，所以被误解为是针对软件开发的。最初这篇文章显然不敢自称定律（law），只是描述了作者自己的发现和总结。后来，在Brooks Law著名的人月神话中，引用这个论点，并将其“吹捧”成了现在我们熟知“康威定律”。 康威定律详细介绍&emsp;&emsp;Mike从他的角度归纳这篇论文中的其他一些核心观点，如下： 第一定律：Communication dictates design（组织沟通方式会通过系统设计表达出来） 第二定律：There is never enough time to do something right, but there is always enough time to do it over（时间再多一件事情也不可能做的完美，但总有时间做完一件事情） 第三定律：There is a homomorphism from the linear graph of a system to the linear graph of its design organization（线型系统和线型组织架构间有潜在的异质同态特性） 第四定律： The structures of large systems tend to disintegrate during development, qualitatively more so than with small systems（大的系统组织总是比小系统更倾向于分解） 一.人是复杂社会动物&emsp;&emsp;第一定律：Communication dictates design（组织沟通方式会通过系统设计表达出来） &emsp;&emsp;组织的沟通和系统设计之间的紧密联系，在很多别的领域有类似的阐述。对于复杂的系统，聊设计就离不开聊人与人的沟通，解决好人与人的沟通问题，才能有一个好的系统设计。相信几乎每个程序员都读过的《人月神话》（1975年，感觉都是老古董了，经典的就是经得起时间考验）里面许多观点都和这句话有异曲同工之妙。 &emsp;&emsp;比如《人月神话》中最著名的一句话就是 Adding manpower to a late software project makes it later –Fred Brooks, (1975) &emsp;&emsp;Boss们都听到了吗？为了赶进度加程序员就像用水去灭油锅里的火一样（无奈大家还是前赴后继）。 &emsp;&emsp;为什么？人月神话也给出了很简洁的答案：沟通成本 = n(n-1)/2，沟通成本随着项目或者组织的人员增加呈指数级增长。是的，项目管理这个算法的复杂度是O(n^2)。举个例子 5个人的项目组，需要沟通的渠道是 5*(5–1)/2 = 10 15个人的项目组，需要沟通的渠道是15*(15–1)/2 = 105 50个人的项目组，需要沟通的渠道是50*(50–1)/2 = 1,225 150个人的项目组，需要沟通的渠道是150*(150–1)/2 = 11,175 &emsp;&emsp;所以知道为什么互联网创业公司都这么小了吧，必须小啊，不然等CEO和所有人讲一遍创业的想法后，风投的钱都烧完了。 &emsp;&emsp;Mike还举了一个非常有意思的理论，叫“Dunbar Number”，这是一个叫Dunbar（废话）生物学家在1992年最早提出来的。最初，他发现灵长类的大脑容量和其对应的族群大小有一定关联，进而推断出人类的大脑能维系的关系的一些有趣估计。举例来说 亲密（intimate）朋友: 5 信任（trusted）朋友: 15 酒肉（close）朋友: 35 照面（casual）朋友: 150 &emsp;&emsp;是不是和上面的沟通成本的数字很貌似有关联？是的，我们的大脑智力只能支持我们维系这么多的关系。（大家都知道这不是程序猿擅长的领域，在开发团队里，这个值应该更小，估计和猿差不多 -_-凸 ） &emsp;&emsp;沟通的问题，会带来系统设计的问题，进而影响整个系统的开发效率和最终产品结果。 二.一口气吃不成胖子，先搞定能搞定的&emsp;&emsp;第二定律：There is never enough time to do something right, but there is always enough time to do it over（时间再多一件事情也不可能做的完美，但总有时间做完一件事情） Eric Hollnagel是敏捷开发社区的泰斗之一，在他《Efficiency-Effectiveness Trade Offs》 一书中解释了类似的论点。 &emsp;&emsp;系统越做越复杂，功能越来越多，外部市场的竞争越来越剧烈，投资人的期待越来越高。但人的智力是有上限的，即使再牛逼的人，融到钱再多也不一定招到足够多合适的人。对于一个巨复杂的系统，我们永远无法考虑周全。Eric认为，这个时候最好的解决办法竟然是——“破罐子破摔”。 &emsp;&emsp;其实我们在日常开发中也经常碰到。产品经理的需求太复杂了？适当忽略一些细节，先抓主线。产品经理的需求太多了？放弃一些功能。 &emsp;&emsp;据说Eric被一家航空公司请去做安全咨询顾问，复杂保证飞机飞行系统的稳定性和安全性。Eric认为做到安全有两种方式： 常规的安全指的是尽可能多的发现并消除错误的部分，达到绝对安全，这是理想。 另一种则是弹性安全，即使发生错误，只要及时恢复，也能正常工作，这是现实。 &emsp;&emsp;对于飞机这样的复杂系统，再牛逼的人也无法考虑到漏洞的方方面面，所以Eric建议放弃打造完美系统的想法，而是通过不断的试飞，发现问题，确保问题发生时，系统能自动复原即可，而不追求飞行系统的绝对正确和安全。 &emsp;&emsp;下面的图很好的解释了这个过程： &emsp;&emsp;听着很耳熟不是吗？这不就是 持续集成 和敏捷开发吗？的确就是。 &emsp;&emsp;另一方面，这和互联网公司维护的分布式系统的弹性设计也是一个道理。对于一个分布式系统，我们几乎永远不可能找到并修复所有的bug，单元测试覆盖1000%也没有用，错误流淌在分布式系统的血液里。解决方法不是消灭这些问题，而是容忍这些问题，在问题发生时，能自动回复，微服务组成的系统，每一个微服务都可能挂掉，这是常态，我们只有有足够的冗余和备份即可。即所谓的 弹性设计（Resilience） 或者叫高可用设计（High Availability）。 三.种瓜得瓜，做独立自治的字系统减少沟通成本&emsp;&emsp;第三定律：There is a homomorphism from the linear graph of a system to the linear graph of its design organization（线型系统和线型组织架构间有潜在的异质同态特性） &emsp;&emsp;这是康威第一定律组织和设计间内在关系的一个具体应用。更直白的说，你想要什么样的系统，就搭建什么样的团队。如果你的团队分成前端团队，Java后台开发团队，DBA团队，运维团队，你的系统就会长成下面的样子： &emsp;&emsp;相反，如果你的系统是按照业务边界划分的，大家按照一个业务目标去把自己的模块做出小系统，小产品的话，你的大系统就会长成下面的样子，即微服务的架构 &emsp;&emsp;微服务的理念团队间应该是 inter-operate, not integrate 。inter-operate是定义好系统的边界和接口，在一个团队内全栈，让团队自治，原因就是因为如果团队按照这样的方式组建，将沟通的成本维持在系统内部，每个子系统就会更加内聚，彼此的依赖耦合能变弱，跨系统的沟通成本也就能降低。 四.合久必分，分而治之&emsp;&emsp;第四定律： The structures of large systems tend to disintegrate during development, qualitatively more so than with small systems（大的系统组织总是比小系统更倾向于分解） &emsp;&emsp;前面说了，人是复杂的社会动物，人与人的通过非常复杂。但是当我们面对复杂系统时，又往往只能通过增加人力来解决。这时，我们的组织一般是如何解决这个沟通问题的呢？Divide and conquer,分而治之。大家看看自己的公司的组织，是不是一个一线经理一般都是管理15个人以下的？二线经理再管理更少的一线？三线再管理更少的，以此类推。（这里完全没有暗示开发经理比程序猿更难管理） &emsp;&emsp;所以，一个大的组织因为沟通成本/管理问题，总为被拆分成一个个小团队。 创业的想法太好了，反正风投钱多，多招点程序猿 人多管不过来啊，找几个经理帮我管，我管经理 最后， 康威定律 告诉我们组织沟通的方式会在系统设计上有所表达，每个经理都被赋予一定的职责去做大系统的某一小部分，他们和大系统便有了沟通的边界，所以大的系统也会因此被拆分成一个个小团队负责的小系统（微服务是一种好的模式） 康威定律如何解释微服务的合理性&emsp;&emsp;了解了康威定律是什么，再来看看他如何在半个世纪前就奠定了微服务架构的理论基础。 人与人的沟通是非常复杂的，一个人的沟通精力是有限的，所以当问题太复杂需要很多人解决的时候，我们需要做拆分组织来达成对沟通效率的管理 组织内人与人的沟通方式决定了他们参与的系统设计，管理者可以通过不同的拆分方式带来不同的团队间沟通方式，从而影响系统设计 如果子系统是内聚的，和外部的沟通边界是明确的，能降低沟通成本，对应的设计也会更合理高效 复杂的系统需要通过容错弹性的方式持续优化，不要指望一个大而全的设计或架构，好的架构和设计都是慢慢迭代出来的 &emsp;&emsp;带来的具体的实践建议是： 我们要用一切手段提升沟通效率，比如slack，github，wiki。能2个人讲清楚的事情，就不要拉更多人，每个人每个系统都有明确的分工，出了问题知道马上找谁，避免踢皮球的问题。 通过MVP的方式来设计系统，通过不断的迭代来验证优化，系统应该是弹性设计的。 你想要什么样的系统设计，就架构什么样的团队，能扁平化就扁平化。最好按业务来划分团队，这样能让团队自然的自治内聚，明确的业务边界会减少和外部的沟通成本，每个小团队都对自己的模块的整个生命周期负责，没有边界不清，没有无效的扯皮，inter-operate, not integrate。 做小而美的团队，人多会带来沟通的成本，让效率下降。亚马逊的Bezos有个逗趣的比喻，如果2个披萨不够一个团队吃的，那么这个团队就太大了。事实上一般一个互联网公司小产品的团队差不多就是7，8人左右（包含前后端测试交互用研等，可能身兼数职）。 &emsp;&emsp; 再对应下衡量微服务的标准，我们很容易会发现他们之间的密切关系： 分布式服务组成的系统 按照业务而不是技术来划分组织 做有生命的产品而不是项目 Smart endpoints and dumb pipes（我的理解是强服务个体和弱通信） 自动化运维（DevOps） 容错 快速演化 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"指导思想","slug":"指导思想","permalink":"https://lywlefan.github.io/tags/指导思想/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"}]},{"title":"常用工具收集","date":"2019-05-27T16:00:00.000Z","path":"2019/05/28/工具/开发工具/常用开发工具导航/","text":"工欲善其事，必先利器！ 前端工具IDE抓包工具 Charles 后端工具​ 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"工具","slug":"工具","permalink":"https://lywlefan.github.io/tags/工具/"},{"name":"收藏","slug":"收藏","permalink":"https://lywlefan.github.io/tags/收藏/"}]},{"title":"常用工具收集","date":"2019-05-27T16:00:00.000Z","path":"2019/05/28/工具/常用工具收集/","text":"工欲善其事，必先利器！ 常用工具总结windows必备神器解放双手神器 Wox-解放双手 文档编辑工具markdown typora-超级好用而且免费 inspire-收费好用 常用小工具GIF图生成 LICEcap(比较好用的生成gif的小工具) Mac文档编辑工具markdown Ulysses Linux文档编辑工具markdown typora-超级好用而且免费 ​ 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"工具","slug":"工具","permalink":"https://lywlefan.github.io/tags/工具/"},{"name":"收藏","slug":"收藏","permalink":"https://lywlefan.github.io/tags/收藏/"}]},{"title":"idea常用快捷键总结","date":"2019-05-16T16:00:00.000Z","path":"2019/05/17/后端/开发IDE/java/idea/idea常用快捷键总结/","text":"工欲善其事，必先利器！ 必需会的快捷键 提出选中内容为局部变量:Ctrl+Alt+V 选中代码的情况下,包裹代码(try):Ctrl+alt+T 删除类中无用的import包:Ctrl + Alt + O 格式化代码:Ctrl+Alt+L 抽取方法:Ctrl+Alt+m(该快捷键可以快速抽取方法) 界面相关快捷键 快速切换方案:Ctrl+~ 展开/折叠项目侧边栏:Alt+1 打开设置界面:Ctrl + Alt + S 扩展成一个窗口：shift+ctrl+f12 代码提示相关快捷键 代码提示:Ctrl+空格 代码插入:Alt+enter 基础代码补全:Ctrl + Space 智能代码提示:Ctrl + Shift + Space 代码浏览相关快捷键 折叠代码:Ctrl + - (Ctrl+Shift+-为所有) 展开代码:Ctrl + + 代码移动相关快捷键 移动方法顺序:Ctrl+Shift+↑/↓ 光标控制相关快捷键 光标定位到上个浏览处:Ctrl(shift)+alt+left 光标定位到下一个浏览出:Ctrl(shift)+Alt+right 光标移动到下一个方法开始处:alt+down 光标移动到上一个方法开始处:alt+up 光标移动到前一个单词处:Ctrl+left 光标移动到后一个单词处:Ctrl+right 光标在代码块之间移动:Ctrl+[/] 快速定位到下一个错误和警告处:F2(加Shift键，定位到上一个错误处) 光标跳出括号(单引号等其他的类似):shift+相应符号 选中相关的快捷键 连续选中文件中相同的内容:Alt+j 按语法选中代码:Ctrl+W (连续按会有其他效果，加Shift键，产生反向选中效果) 多行选择:Ctrl+Shift+← 新建相关快捷键 新建类文件:Alt+insert(光标放到文件夹) 文件切换 查看最近打开的文件:Ctrl+E 切换最近文件:Ctrl+Tab 编辑窗口的切换:Alt+left/right 查找相关快捷键 当前文件查找:Ctrl+F 当前文件替换:Ctrl+R 当前项目查找:Ctrl+shift+F 当前项目替换:Ctrl+Shift+R 查找文件:Ctrl+shift+N 查找类文件:ctrl+shift+alt+n 全局查找:shift+shift 删除和插入相关快捷键 删除当前行:Ctrl+Y 按单个单词删除:Ctrl+Backspace 复制光标所在的行:Ctrl+D 向下插入一行:shift+enter 向上插入一行:alt+shift+enter 当前行向上移动:ctrl+shift+up/down 大小写转换快捷键 大小写转换快捷键:Ctrl+shift+U 版本控制相关的快捷键 提交到本地仓库备注的快捷键:Ctrl+k 提交到本地仓库:Ctrl+Alt+K push的快捷键:Ctrl+shift+K（窗口处理的时候ctrl+enter可以快速提交） pull的快捷键:Ctrl+T 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"开发IDE","slug":"开发IDE","permalink":"https://lywlefan.github.io/tags/开发IDE/"}]},{"title":"JAR包如何取工程外部文件","date":"2019-05-14T16:00:00.000Z","path":"2019/05/15/后端/框架/java/spring/JAR包如何取工程外部文件/","text":"问题起源&emsp;&emsp;在开发支付stater的过程中会用到证书，而证书我们一般配置在工程项目中，那么我们自己开发的stater如何才能取到工程项目中的证书文件那？？？ 问题深究分解问题&emsp;&emsp;要想解决这个问题，我们要明确 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"RestTemplate常见问题的解决办法.md","date":"2019-05-14T16:00:00.000Z","path":"2019/05/15/后端/框架/java/spring/RestTemplate常见问题的解决办法/","text":"问题汇总 用restTemplate请求域名或着ip一直报No instances available的错 restTemplate的post请求报415错 问题处理用restTemplate请求域名或着ip一直报No instances available的错 错误描述 123java.lang.IllegalStateException: No instances available for www.baidu.comat org.springframework.cloud.netflix.ribbon.RibbonLoadBalancerClient.execute(RibbonLoadBalancerClient.java:79) ~[spring-cloud-netflix-core-1.1.0.RELEASE.jar:1.1.0.RELEASE] at org.springframework.cloud.client.loadbalancer.LoadBalancerInterceptor.intercept(LoadBalancerInterceptor.java:46) ~[spring-cloud-commons-1.1.0.RELEASE.jar:1.1.0.RELEASE] at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:86) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:70) ~[spring-web-4.3.10.RELEASE.jar:4.3.10.RELEASE] at ..... &emsp;&emsp;查看错误的跟踪链发现,自动注入的restTemplate中加入了cloud.netflix*包下面的interceptor, &emsp;&emsp;所以默认会通过RibbonLoadBalancerClient去查找注册中心的instances, &emsp;&emsp;如上面的代码，www.baidu.com肯定不存在，所以就报错了。 错误解决 &emsp;&emsp;重新实例化一个RestTemplate。 123456789101112131415@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate loadBalanced() &#123; return new RestTemplate(); &#125; @Primary @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; restTemplate的post请求报415错 错误描述 &emsp;&emsp;报错415 问具体解决 1234567HttpHeaders headers = new HttpHeaders();MediaType type = MediaType.parseMediaType(\"application/json;\");headers.setContentType(type);headers.add(\"Accept\", MediaType.APPLICATION_JSON.toString());JSONObject jsonObj = JSON.parseObject(JSON.toJSONString(payParams));HttpEntity&lt;String&gt; formEntity = new HttpEntity&lt;String&gt;(jsonObj.toString(), headers);restTemplate.postForObject(bestPayProperties.getBestPayUrl(),formEntity,String.class); 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"不用spring如何实例化一个bean","date":"2019-05-13T16:00:00.000Z","path":"2019/05/14/后端/框架/java/spring/不用spring如何实例化一个bean/","text":"问题源起&emsp;&emsp;为什么写这么一篇文章那？主要还是源自最近在写支付的starter的过程中遇到的一个问题，我们知道在支付的过程中需要去配置一些相关的参数，因为是starter我们一般是通过配置文件的方式进行配置，引用我们stater的工程会通过yml文件中配置的属性把这些值给我们。 &emsp;&emsp;那么我想在stater里面取到这些值该如何去做那？？我直接new一个配置类对象但是却取不到，因此我们就在思考spring到底是如何实例化bean的？？他对bean做了什么？？如果不用spring的注解我们又该如何去实例化我们的bean那？带着这些问题我开始了我的解惑之旅。。。 问题深究提出问题，分解问题12345678910111213141516@AllArgsConstructor@RestController@RequestMapping(\"/api/v1/app/\")public class AppController extends BaseController &#123; @Autowired AppBannerService appBannerService; @RequestMapping(value = \"index\", method = RequestMethod.POST) public Result index(HttpServletRequest request,@RequestBody @Valid AppBannerAreaCode appBannerAreaCode) &#123; Map&lt;String,Object&gt; appMessage=new HashMap&lt;&gt;(); String appId=CommonUtils.getAppIdFromHeader(request); List&lt;AppBanner&gt; banners=appBannerService.getBannersByAppIdAndCode(appId,appBannerAreaCode.getProvinceCode()); return new Result(banners); &#125;&#125; &emsp;&emsp;上面的controller是我用日常开发常用的，AppBannerService是我们定义的业务接口，接口有实现类，我们只需要简单的注解就可以直接调用接口的方法了。 spring如何实例化bean？？ spring实例化方式有那些？？ 容器是如何实例化的？？ 我们假如不用这个注解如何去调这个接口那？？&emsp;&emsp;接下来我们就围绕以上两个问题进行展开。 解决各个问题spring实例化方式有那些？？&emsp;&emsp;软件开发到最后的最高境界就是制定标准，然后严格安装标准去开发和迭代。我个人认为spring也是如此，spring给自己定义了标准的四种实例化方式，我们在日常开发中就可以通过这四种实例化方式进行实例化，下面让我们一起细究一下这四种实例化方式： setter方法实例化 主类 1234567891011121314151617181920212223242526public interface IUserDao &#123; void addUser(); void delUser(); void updateUser(); &#125; public class UserDaoImpl implements IUserDao &#123; public void addUser() &#123; System.out.println(\"addUser方法被调用了\"); &#125; public void delUser() &#123; System.out.println(\"delUser方法被调用了\"); &#125; public void updateUser() &#123; System.out.println(\"updateUser方法被调用了\"); &#125; &#125; public class UserAction &#123; private IUserDao dao; //dao是一个依赖对象,要由springg进行管理,要生成 get set 方法 public void execute()&#123; dao.addUser(); dao.updateUser(); dao.delUser(); &#125; &#125; 配置文件 12345//配置文件&lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt;&lt;property name=\"dao\" ref=\"userDao_name\" /&gt; //引用的是下面的名称&lt;/bean&gt; &lt;bean name=\"userDao_name\" class=\"cat.dao.UserDaoImpl\" /&gt; 测试 1234 //测试ClassPathXmlApplicationContext ctx=new ClassPathXmlApplicationContext(\"beans.xml\");UserAction action=(UserAction)ctx.getBean(\"userAction_name\");action.execute(); 构造函数 主类 123456789101112131415161718192021222324public class UserAction &#123; //public UserAction()&#123;&#125; 可以保保留一个无参的构造函数 //这是几个依赖对象,不用生成get set方法了 private UserInfo user; private String school; private IUserDao dao; //希望Spring 由构造函数注入依赖对象 public UserAction(IUserDao dao,UserInfo user,String school)&#123; this.dao=dao; this.school=school; this.user=user; &#125; public void execute()&#123; dao.addUser(); dao.updateUser(); dao.delUser(); System.out.println(user); System.out.println(school);&#125; 配置文件 123456789101112131415161718192021222324//配置文件&lt;bean name=\"userInfo_name\" class=\"cat.beans.UserInfo\" &gt; &lt;property name=\"id\" value=\"1\" /&gt; &lt;property name=\"userName\" value=\"周周\" /&gt; &lt;property name=\"password\" value=\"123\" /&gt; &lt;property name=\"note\" value=\"这是备注\" /&gt;&lt;/bean&gt; &lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt; &lt;constructor-arg ref=\"userDao_name\" /&gt; &lt;constructor-arg ref=\"userInfo_name\" /&gt; &lt;constructor-arg value=\"哈尔滨师范大学\" /&gt;&lt;/bean&gt; /*也可以指定 索引和 type 属性 , 索引和type 都可以不指定&lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt;&lt;constructor-arg index=\"0\" ref=\"userDao_name\" type=\"cat.dao.IUserDao\" /&gt; 如果是接口,就不能指定是实现类的类型&lt;constructor-arg index=\"1\" ref=\"userInfo_name\" type=\"cat.beans.UserInfo\" /&gt;&lt;constructor-arg index=\"2\" value=\"哈尔滨师范大学\" /&gt;&lt;/bean&gt;*/ &lt;bean name=\"userDao_name\" class=\"cat.dao.UserDaoImpl\" /&gt; 测试 1234//测试ClassPathXmlApplicationContext ctx=new ClassPathXmlApplicationContext(\"beans.xml\");UserAction action=(UserAction)ctx.getBean(\"userAction_name\");action.execute(); 静态工厂方式 主类 123456789101112131415161718192021//工厂,用来生成dao的实现类public class UserDaoFactory &#123;public static IUserDao createUserDaoInstance()&#123; return new UserDaoOracleImpl(); &#125;&#125; public class UserAction &#123; private IUserDao dao;//使用工厂方式注值,也要生成set方法 public void execute()&#123; dao.addUser(); dao.updateUser(); dao.delUser();&#125; public void setDao(IUserDao dao) &#123; this.dao = dao;&#125; &#125; 配置文件 123456//配置文件 &lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt;&lt;property name=\"dao\" ref=\"userDao_name\" /&gt;&lt;/bean&gt; &lt;bean name=\"userDao_name\" class=\"cat.dao.UserDaoFactory\" factory-method=\"createUserDaoInstance\" /&gt; 测试 1234//测试ClassPathXmlApplicationContext ctx=new ClassPathXmlApplicationContext(\"beans.xml\");UserAction action=(UserAction)ctx.getBean(\"userAction_name\");action.execute(); 实例工厂 主类 1234567//工厂 =&gt;public class UserDaoFactory &#123;//这个方法不是静态的public IUserDao createUserDaoInstance()&#123; return new UserDaoOracleImpl(); &#125;&#125; 配置文件 1234567//配置文件 &lt;bean name=\"userAction_name\" class=\"cat.action.UserAction\" &gt;&lt;property name=\"dao\" ref=\"userDao_name\" /&gt;&lt;/bean&gt; &lt;bean name=\"userDaoFactory_name\" class=\"cat.dao.UserDaoFactory\" /&gt;&lt;bean name=\"userDao_name\" factory-bean=\"userDaoFactory_name\" factory-method=\"createUserDaoInstance\" /&gt; 测试 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"自定义SPEL的注解","date":"2019-05-12T16:00:00.000Z","path":"2019/05/13/后端/框架/java/spring/自定义SPEL的注解/","text":"目标刻在岩石上，方法写在沙滩上. 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"如何写一个stater","date":"2019-05-12T16:00:00.000Z","path":"2019/05/13/后端/框架/java/spring/如何写一个stater/","text":"目标刻在岩石上，方法写在沙滩上. 命名规范&emsp;&emsp;不要使用spring-boot开头的，以避免将来spring-boot官方使用你的starter而重名。 正例：xxxx-spring-boot-starter 反例：spring-boot-starter-xxxx 定功能&emsp;&emsp;你所定义的starter需要有自己的独特功能，比如spring-boot-starter-web 提供的springmvc相关的自动装配，内嵌tomcat以及相关依赖，那们你自己定义的starter也是需要界定好自己的功能。举个列子，比如要写一个支付的stater： 支付 支付通知 支付查询 退款 退款查询 退款通知 项目依赖 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"初始Docker","date":"2018-07-18T16:00:00.000Z","path":"2018/07/19/后端/容器管理/Kubernetes/初始Kubernetes/","text":"【1】简书主页·share猿 【2】掘金主页·share猿 【3】Kubernetes官方文档 【4】Kubernetes官方文档APi 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"容器管理","slug":"容器管理","permalink":"https://lywlefan.github.io/tags/容器管理/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://lywlefan.github.io/tags/Kubernetes/"}]},{"title":"初始Docker","date":"2018-07-18T16:00:00.000Z","path":"2018/07/19/后端/容器管理/docker/初始Docker/","text":"【1】简书主页·share猿 【2】掘金主页·share猿 【3】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"容器管理","slug":"容器管理","permalink":"https://lywlefan.github.io/tags/容器管理/"},{"name":"Docker","slug":"Docker","permalink":"https://lywlefan.github.io/tags/Docker/"}]},{"title":"Spring Boot配置FastJson报错","date":"2018-05-29T16:00:00.000Z","path":"2018/05/30/后端/bug收集桶/java/Lombok初次使用启动项目报错解决/","text":"错误描述123456789101112131415161718192021222324252627282930313233343536373839404142434445464748org.springframework.web.util.NestedServletException: Request processing failed; nested exception is java.lang.IllegalArgumentException: Content-Type cannot contain wildcard type '*' at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1013) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:908) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:665) ~[javax.servlet-api-4.0.1.jar:4.0.1] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:882) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:750) ~[javax.servlet-api-4.0.1.jar:4.0.1] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:81) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.19.Final.jar:2.0.19.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:274) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchToPath(ServletInitialHandler.java:209) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:502) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.spec.RequestDispatcherImpl.error(RequestDispatcherImpl.java:428) ~[undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:331) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:81) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:138) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:135) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:272) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:81) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:104) [undertow-servlet-2.0.19.Final.jar:2.0.19.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:364) [undertow-core-2.0.19.Final.jar:2.0.19.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) [undertow-core-2.0.19.Final.jar:2.0.19.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_181] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_181] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_181]Caused by: java.lang.IllegalArgumentException: Content-Type cannot contain wildcard type '*' at org.springframework.util.Assert.isTrue(Assert.java:118) ~[spring-core-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.http.HttpHeaders.setContentType(HttpHeaders.java:915) ~[spring-web-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.http.converter.AbstractHttpMessageConverter.addDefaultHeaders(AbstractHttpMessageConverter.java:256) ~[spring-web-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.http.converter.AbstractHttpMessageConverter.write(AbstractHttpMessageConverter.java:211) ~[spring-web-5.1.6.RELEASE.jar:5.1.6.RELEASE] at com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter.write(FastJsonHttpMessageConverter.java:184) ~[fastjson-1.2.49.jar:na] at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:290) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:223) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) ~[spring-web-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:119) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:892) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:797) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1005) ~[spring-webmvc-5.1.6.RELEASE.jar:5.1.6.RELEASE] ... 29 common frames omitted 错误分析idea设置有问题 错误解决下载idea的lombok插件让idea支持lombok编译勾选idea的Enable annotation processing选项，该选项在Preference——Build,Execution,Deployment——Compiler——Annotation Processors中 学习总结lombok常用的注解学习@Data：注解在类上，将类提供的所有属性都添加get、set方法，并添加、equals、canEquals、hashCode、toString方法@Setter：注解在类上，为所有属性添加set方法、注解在属性上为该属性提供set方法@Getter：注解在类上，为所有的属性添加get方法、注解在属性上为该属性提供get方法@NotNull：在参数中使用时，如果调用时传了null值，就会抛出空指针异常@Synchronized 用于方法，可以锁定指定的对象，如果不指定，则默认创建一个对象锁定@Log作用于类，创建一个log属性@Builder：使用builder模式创建对象@NoArgsConstructor：创建一个无参构造函数@AllArgsConstructor：创建一个全参构造函数@ToStirng：创建一个toString方法@Accessors(chain = true)使用链式设置属性，set方法返回的是this对象。@RequiredArgsConstructor：创建对象@UtilityClass:工具类@ExtensionMethod:设置父类@FieldDefaults：设置属性的使用范围，如private、public等，也可以设置属性是否被final修饰。@Cleanup: 关闭流、连接点。@EqualsAndHashCode：重写equals和hashcode方法。@toString：创建toString方法。 【1】简书主页·share猿 【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"bug","slug":"bug","permalink":"https://lywlefan.github.io/tags/bug/"}]},{"title":"spring的核心jar","date":"2018-05-29T16:00:00.000Z","path":"2018/05/30/后端/框架/java/spring/spring的核心jar/","text":"&emsp;&emsp;实践一门技术的最好方式就是深入理解它的思想，然后造一个出来！ Spring AOP：Spring的面向切面编程，提供AOP（面向切面编程）的实现 Spring Aspects：Spring提供的对AspectJ框架的整合 Spring Beans：Spring IOC的基础实现，包含访问配置文件、创建和管理bean等。 Spring Context：在基础IOC功能上提供扩展服务，此外还提供许多企业级服务的支持，有邮件服务、任务调度、JNDI定位，EJB集成、远程访问、缓存以及多种视图层框架的支持。 Spring Context Support：Spring context的扩展支持，用于MVC方面。 Spring Core：Spring的核心工具包 Spring expression：Spring表达式语言 Spring Framework Bom： Spring Instrument：Spring对服务器的代理接口 Spring Instrument Tomcat：Spring对tomcat连接池的集成 Spring JDBC：对JDBC 的简单封装 Spring JMS：为简化jms api的使用而做的简单封装 Spring Messaging： Spring orm：整合第三方的orm实现，如hibernate，ibatis，jdo以及spring 的jpa实现 Spring oxm：Spring对于object/xml映射的支持，可以让JAVA与XML之间来回切换 Spring test：对JUNIT等测试框架的简单封装 Spring tx：为JDBC、Hibernate、JDO、JPA等提供的一致的声明式和编程式事务管理。 Spring web：包含Web应用开发时，用到Spring框架时所需的核心类，包括自动载入WebApplicationContext特性的类、Struts与JSF集成类、文件上传的支持类、Filter类和大量工具辅助类。 Spring webmvc：包含SpringMVC框架相关的所有类。包含国际化、标签、Theme、视图展现的FreeMarker、JasperReports、Tiles、Velocity、XSLT相关类。当然，如果你的应用使用了独立的MVC框架，则无需这个JAR文件里的任何类。 Spring webmvc portlet：Spring MVC的增强 【1】简书主页·share猿 【2】掘金主页·share猿 — 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"spring","slug":"spring","permalink":"https://lywlefan.github.io/tags/spring/"},{"name":"java","slug":"java","permalink":"https://lywlefan.github.io/tags/java/"},{"name":"框架","slug":"框架","permalink":"https://lywlefan.github.io/tags/框架/"}]},{"title":"MySQL优化总结","date":"2018-05-26T16:00:00.000Z","path":"2018/05/27/后端/数据存储/关系型数据库/mysql/MySQL优化总结/","text":"&emsp;&emsp;实践一门技术的最好方式就是深入理解它的思想，然后造一个出来！ 数据库设计 适当冗余 冗余长时间不变更的字段 冗余数据增量较小的表的字段,衡量好得失 适当建立索引 可是天下没有免费的午餐，查询速度的提高是以插入、更新、删除的速度为代价的，这些写操作，增加了大量的I/O。 一个表的索引所占空间比数据所占空间还大的情况经常发生. 我们建立一个索引，必须保证这个索引不会“亏本”,一般需要遵守这样的规则： 索引的字段必须是经常作为查询条件的字段 如果索引多个字段，第一个字段要是经常作为查询条件的。如果只有第二个字段作为查询条件，这个索引不会起到作用; 索引的字段必须有足够的区分度; Mysql 对于长字段支持前缀索引(所谓的前缀索引就是某些字段只过长,可以取部分值进行检索); 对表进行水平划分 记录数太多了,上千万条 可以取一个维度对表进行拆分,比如地域/月份 对表进行垂直划分 记录不多,但是字段很长的情况 选择适当的字段类型，特别是主键 保小不保大，能用占用字节小的字段就不用大字段(比如主键，我们强烈建议用自增类型) 值得一提的是，datetime和timestamp，datetime占用8个字节，而timestamp占用4个字节 文件、图片等大文件用文件系统存储，不用数据库外键表示清楚，方便建立索引&emsp;&emsp;我们都知道，在powerdesigner里为两个实体建立关系，生成物理模型时会自动给外键建立索引。所以我们不要怕建立关系把线拉乱，建立个ShortCut就好了。 掌握表的写入时机 同样是写入一个表，先写和后写对后续的操作会产生很大影响 宁可集中批量操作，避免频繁读写&emsp;&emsp;系统里包含了积分部分，学生和老师通过系统做了操作都可以获得积分，而且积分规则很复杂，限制每类操作获得积分不同，每人每天每类积分都有上限。比如登录，一次登录就可以获得1分，但是不管你登录多少次，一天只能累积一个登录积分。这个还是简单的，有的积分很变态，比如老师积分中有一类是看老师判作业的情况，规则是：老师判了作业，发现学生有错的，学生改过了，老师再判，如果这时候学生都对了，就给老师加分，如果学生还是错的，那就接着改，知道学生都改对了，老师都判完了，才能给老师加分。如果用程序来处理，很可能每个功能都会额外的写一堆代码来处理这个鸡肋似的积分。不仅编程的同事干活找不到重点，还平白给数据库带来了很大的压力。经过和需求人员的讨论，确定积分没有必要实时累积，于是我们采取后台脚本批量处理的方式。夜深人静的时候，让机器自己玩去吧。 选择合适的引擎&emsp;&emsp;Mysql提供了很多种引擎，我们用的最多的是myisam，innodb，memory这三类。官方手册上说道myisqm比innodb的读速度要快，大概是3倍。不过书不能尽信啊，《OreIlly.High.Performance.Mysql》这本书里提到了myisam和innodb的比较，在测试中myisam的表现还不及innodb。至于memory，哈哈，还是比较好用的。在批处理种作临时表是个不错的选择(如果内存够大)。在我的一个批处理中，速度比近乎1：10。 Sql语句优化 Sql语句优化工具 慢日志 &emsp;&emsp;配置很简单，参数文件里配置： 12slow_query_log=d:/slow.txtlong_query_time = 2 &amp;emsp;&amp;emsp;慢日志文件可能会很大，让人去看是很难受的事。这时候我们可以通过mysql自带的工具来分析。 【1】简书主页·share猿 【2】掘金主页·share猿 【3】MySQL优化总结·周长亮 — 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"关系型数据库","slug":"关系型数据库","permalink":"https://lywlefan.github.io/tags/关系型数据库/"},{"name":"mysql","slug":"mysql","permalink":"https://lywlefan.github.io/tags/mysql/"}]},{"title":"MySQL优化总结","date":"2017-05-26T16:00:00.000Z","path":"2017/05/27/运维/Linux/常用命令总结/","text":"​ 系统命令系统属性查询系统内存使用情况 【1】简书主页·share猿 【2】掘金主页·share猿 【3】MySQL优化总结·周长亮 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"Linux","slug":"Linux","permalink":"https://lywlefan.github.io/tags/Linux/"}]},{"title":"微服务架构导航","date":"2017-05-05T16:00:00.000Z","path":"2017/05/06/架构/微服务架构/微服务架构导航/","text":"技术总结服务服务管理部署kubernetes服务通讯治理Istio数据关系数据库分库分表技术简单易用的组件： 当当sharding-jdbc 蘑菇街TSharding 强悍重量级的中间件： sharding TDDL Smart Client的方式（淘宝） Atlas(Qihoo 360) alibaba.cobar(是阿里巴巴（B2B）部门开发) MyCAT（基于阿里开源的Cobar产品而研发） Oceanus(58同城数据库中间件) OneProxy(支付宝首席架构师楼方鑫开发) vitess（谷歌开发的数据库中间件） 文档总结 参考文档 【1】简书主页·share猿 【2】掘金主页·share猿 【3】LMAX架构简介·汤雪华 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"微服务","slug":"微服务","permalink":"https://lywlefan.github.io/tags/微服务/"}]},{"title":"Slack","date":"2011-12-31T16:00:00.000Z","path":"2012/01/01/工具/团队协作工具/Slack/","text":"工欲善其事，必先利器！ 【1】简书主页·share猿【2】掘金主页·share猿 扫描以下公众号关注小猿↓↓↓↓↓↓↓↓ 更多资讯请在简书、微博、今日头条、掘金、CSDN都可以通过搜索“Share猿”找到小猿哦！！！","tags":[{"name":"协作","slug":"协作","permalink":"https://lywlefan.github.io/tags/协作/"}]}]